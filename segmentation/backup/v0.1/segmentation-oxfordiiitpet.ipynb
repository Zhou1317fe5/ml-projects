{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65302967",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T08:09:25.719763Z",
     "iopub.status.busy": "2025-07-22T08:09:25.719508Z",
     "iopub.status.idle": "2025-07-22T08:09:36.430960Z",
     "shell.execute_reply": "2025-07-22T08:09:36.430210Z"
    },
    "papermill": {
     "duration": 10.717166,
     "end_time": "2025-07-22T08:09:36.432466",
     "exception": false,
     "start_time": "2025-07-22T08:09:25.715300",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10254355",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T08:09:36.439274Z",
     "iopub.status.busy": "2025-07-22T08:09:36.438906Z",
     "iopub.status.idle": "2025-07-22T08:09:36.444393Z",
     "shell.execute_reply": "2025-07-22T08:09:36.443873Z"
    },
    "papermill": {
     "duration": 0.009948,
     "end_time": "2025-07-22T08:09:36.445555",
     "exception": false,
     "start_time": "2025-07-22T08:09:36.435607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PetDatasetWrapper(Dataset):\n",
    "    def __init__(self, root, split='trainval', augmentations=None, download=True):\n",
    "        # 1. 在内部加载 torchvision 的原始数据集\n",
    "        self.base_dataset = torchvision.datasets.OxfordIIITPet(\n",
    "            root=root,\n",
    "            split=split,\n",
    "            target_types='segmentation',\n",
    "            download=download\n",
    "        )\n",
    "        self.augmentations = augmentations\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.base_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        image, mask = self.base_dataset[idx]\n",
    "        \n",
    "        image = np.array(image)\n",
    "        mask = np.array(mask)\n",
    "        \n",
    "        # 2. 对掩码进行重映射 (这是核心步骤!)\n",
    "        # 原: 1=Pet, 2=Background, 3=Border\n",
    "        # 新: 1=Pet, 0=Background, 255=Ignore\n",
    "        mask[mask == 2] = 0  # 背景: 2 -> 0\n",
    "        mask[mask == 3] = 255 # 边界: 3 -> 255 (忽略)\n",
    "        # 宠物类别 1 保持不变\n",
    "\n",
    "        # 3. 应用 Albumentations 增强\n",
    "        if self.augmentations:\n",
    "            augmented = self.augmentations(image=image, mask=mask)\n",
    "            image = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "            \n",
    "        return image, mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0632421",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T08:09:36.451879Z",
     "iopub.status.busy": "2025-07-22T08:09:36.451419Z",
     "iopub.status.idle": "2025-07-22T08:10:22.135282Z",
     "shell.execute_reply": "2025-07-22T08:10:22.134212Z"
    },
    "papermill": {
     "duration": 45.688316,
     "end_time": "2025-07-22T08:10:22.136568",
     "exception": false,
     "start_time": "2025-07-22T08:09:36.448252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 792M/792M [00:28<00:00, 28.0MB/s]\n",
      "100%|██████████| 19.2M/19.2M [00:02<00:00, 8.69MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集样本数: 3680\n",
      "验证集样本数: 3669\n",
      "图像张量尺寸: torch.Size([3, 256, 256]), 类型: torch.float32\n",
      "掩码张量尺寸: torch.Size([256, 256]), 类型: torch.uint8\n",
      "掩码中的唯一值: tensor([  0,   1, 255], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SIZE = (256, 256)\n",
    "BATCH_SIZE = 8\n",
    "DATA_ROOT = '/kaggle/working/input'\n",
    "\n",
    "# 数据增强\n",
    "train_augs = A.Compose([\n",
    "    # 首先将图像缩放到一个稍大的尺寸，再进行随机裁剪\n",
    "    A.Resize(int(IMAGE_SIZE[0] * 1.25), int(IMAGE_SIZE[1] * 1.25)),\n",
    "    A.RandomCrop(width=IMAGE_SIZE[0], height=IMAGE_SIZE[1]),\n",
    "    \n",
    "    # 几何变换\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.Rotate(limit=35, p=0.5),\n",
    "    \n",
    "    # 像素/颜色变换 (只会作用于 image)\n",
    "    A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2, p=0.5),\n",
    "    A.Blur(blur_limit=3, p=0.3),\n",
    "\n",
    "    # 归一化和转换为Tensor\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "val_augs = A.Compose([\n",
    "    A.Resize(width=IMAGE_SIZE[0], height=IMAGE_SIZE[1]),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# --- 关键变更：实例化新的数据集和加载器 ---\n",
    "# OxfordIIITPet 默认分为 'trainval' 和 'test'\n",
    "train_dataset = PetDatasetWrapper(root=DATA_ROOT, split='trainval', augmentations=train_augs,download=True)\n",
    "val_dataset = PetDatasetWrapper(root=DATA_ROOT, split='test', augmentations=val_augs,download=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"训练集样本数: {len(train_dataset)}\")\n",
    "print(f\"验证集样本数: {len(val_dataset)}\")\n",
    "# 检查一个样本的输出\n",
    "img, msk = train_dataset[0]\n",
    "print(f\"图像张量尺寸: {img.shape}, 类型: {img.dtype}\")\n",
    "print(f\"掩码张量尺寸: {msk.shape}, 类型: {msk.dtype}\")\n",
    "print(f\"掩码中的唯一值: {torch.unique(msk)}\") # 应该会看到 0, 1, 和可能的 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c95b9f",
   "metadata": {
    "papermill": {
     "duration": 0.011848,
     "end_time": "2025-07-22T08:10:22.160033",
     "exception": false,
     "start_time": "2025-07-22T08:10:22.148185",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f97c98ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T08:10:22.183480Z",
     "iopub.status.busy": "2025-07-22T08:10:22.183087Z",
     "iopub.status.idle": "2025-07-22T08:10:22.444626Z",
     "shell.execute_reply": "2025-07-22T08:10:22.443815Z"
    },
    "id": "1BFB88X9xCT-",
    "papermill": {
     "duration": 0.275209,
     "end_time": "2025-07-22T08:10:22.446187",
     "exception": false,
     "start_time": "2025-07-22T08:10:22.170978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 构建网络模型\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class FCN(nn.Module):\n",
    "    def __init__(self, num_classes=21):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 256 -> 128 -> 64 -> 32 -> 16 -> 8\n",
    "        \n",
    "        # Block 1: 256 -> 128\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        # Block 2: 128 -> 64\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        # Block 3: 64 -> 32\n",
    "        self.conv_block3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        # Block 4: 32 -> 16\n",
    "        self.conv_block4 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        # Block 5: 16 -> 8\n",
    "        self.conv_block5 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        # ==================== 分类器 (1x1 Conv) ====================\n",
    "        self.classifier = nn.Conv2d(512, num_classes, kernel_size=1)\n",
    "        \n",
    "        # ==================== 上采样路径 ====================\n",
    "        # 我们需要从 8x8 恢复到 256x256，需要上采样 32 倍\n",
    "        self.upsample = nn.ConvTranspose2d(num_classes, num_classes, kernel_size=64, stride=32, padding=16) # (kernel_size - stride) / 2\n",
    "    def forward(self, x):\n",
    "        # 记录原始尺寸，以防万一\n",
    "        input_size = x.shape[-2:]\n",
    "        \n",
    "        x = self.conv_block1(x)\n",
    "        x = self.conv_block2(x)\n",
    "        x = self.conv_block3(x)\n",
    "        x = self.conv_block4(x)\n",
    "        x = self.conv_block5(x)\n",
    "        \n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        x = self.upsample(x)\n",
    "        \n",
    "        # 如果因为计算精度导致尺寸差一点点，可以用插值来修正\n",
    "        x = F.interpolate(x, size=input_size, mode='bilinear', align_corners=False)\n",
    "        \n",
    "        return x\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# class FCN8s(nn.Module):\n",
    "#     def __init__(self, num_classes=21):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # --- 编码器路径 (和之前一样) ---\n",
    "#         # Block 1: 256 -> 128\n",
    "#         self.conv_block1 = nn.Sequential(...) # 保持不变\n",
    "#         # Block 2: 128 -> 64\n",
    "#         self.conv_block2 = nn.Sequential(...) # 保持不变\n",
    "#         # Block 3: 64 -> 32\n",
    "#         self.conv_block3 = nn.Sequential(...) # 保持不变\n",
    "#         # Block 4: 32 -> 16\n",
    "#         self.conv_block4 = nn.Sequential(...) # 保持不变\n",
    "#         # Block 5: 16 -> 8\n",
    "#         self.conv_block5 = nn.Sequential(...) # 保持不变\n",
    "\n",
    "#         # --- 分类器 (和之前一样) ---\n",
    "#         self.classifier = nn.Conv2d(512, num_classes, kernel_size=1)\n",
    "\n",
    "#         # ==================== 【核心修改】解码器路径 ====================\n",
    "#         # 1. 对编码器第4个池化层的输出进行1x1卷积\n",
    "#         self.score_pool4 = nn.Conv2d(512, num_classes, kernel_size=1)\n",
    "        \n",
    "#         # 2. 对编码器第3个池化层的输出进行1x1卷积\n",
    "#         self.score_pool3 = nn.Conv2d(256, num_classes, kernel_size=1)\n",
    "\n",
    "#         # 3. 上采样层\n",
    "#         # 第一次上采样 (2倍)\n",
    "#         self.upsample_2x_1 = nn.ConvTranspose2d(num_classes, num_classes, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "#         # 第二次上采样 (2倍)\n",
    "#         self.upsample_2x_2 = nn.ConvTranspose2d(num_classes, num_classes, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "#         # 第三次上采样 (8倍)\n",
    "#         self.upsample_8x = nn.ConvTranspose2d(num_classes, num_classes, kernel_size=16, stride=8, padding=4, bias=False)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         input_size = x.shape[-2:]\n",
    "\n",
    "#         # --- 编码器前向传播，并保存中间结果 ---\n",
    "#         h = self.conv_block1(x)\n",
    "#         h = self.conv_block2(h)\n",
    "#         pool3_out = self.conv_block3(h)   # 保存第3个池化后的输出 (H/8)\n",
    "#         pool4_out = self.conv_block4(pool3_out) # 保存第4个池化后的输出 (H/16)\n",
    "#         h = self.conv_block5(pool4_out) # (H/32)\n",
    "\n",
    "#         # --- 解码器前向传播 ---\n",
    "#         # 1. 对最深的特征图进行分类和2倍上采样\n",
    "#         h = self.classifier(h)\n",
    "#         h = self.upsample_2x_1(h) # -> H/16\n",
    "        \n",
    "#         # 2. 融合pool4的特征 (第一次跳跃连接)\n",
    "#         score4 = self.score_pool4(pool4_out)\n",
    "#         # 裁剪score4以匹配上采样后的h的尺寸 (FCN论文中的细节)\n",
    "#         c = (score4.shape[3] - h.shape[3]) // 2\n",
    "#         score4 = score4[:, :, c:c + h.shape[2], c:c + h.shape[3]]\n",
    "#         h = h + score4 # 融合\n",
    "        \n",
    "#         # 3. 再次2倍上采样\n",
    "#         h = self.upsample_2x_2(h) # -> H/8\n",
    "        \n",
    "#         # 4. 融合pool3的特征 (第二次跳跃连接)\n",
    "#         score3 = self.score_pool3(pool3_out)\n",
    "#         c = (score3.shape[3] - h.shape[3]) // 2\n",
    "#         score3 = score3[:, :, c:c + h.shape[2], c:c + h.shape[3]]\n",
    "#         h = h + score3 # 融合\n",
    "\n",
    "#         # 5. 最后进行8倍上采样，恢复到原始尺寸\n",
    "#         h = self.upsample_8x(h) # -> H\n",
    "        \n",
    "#         # 裁剪到原始输入尺寸\n",
    "#         c = (h.shape[3] - input_size[1]) // 2\n",
    "#         h = h[:, :, c:c + input_size[0], c:c + input_size[1]]\n",
    "        \n",
    "#         return h\n",
    "\n",
    "\n",
    "\n",
    "net = FCN(num_classes=2)\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2b92a07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T08:10:22.470430Z",
     "iopub.status.busy": "2025-07-22T08:10:22.469912Z",
     "iopub.status.idle": "2025-07-22T08:10:22.476974Z",
     "shell.execute_reply": "2025-07-22T08:10:22.476140Z"
    },
    "id": "1bicoqSIxCT-",
    "papermill": {
     "duration": 0.020092,
     "end_time": "2025-07-22T08:10:22.478145",
     "exception": false,
     "start_time": "2025-07-22T08:10:22.458053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "# 损失函数\n",
    "loss_function = nn.CrossEntropyLoss(ignore_index=255)  # PASCAL VOC中255是边界或忽略区域，使用 ignore_index=255 来忽略PASCAL VOC中的边界像素，边界像素(255)在计算损失时会被忽略\n",
    "# 优化器\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "# 学习率调度器\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    mode='min',      # 监控的指标越小越好 (我们的目标是降低loss)\n",
    "    factor=0.2,      # 当指标不再改善时，学习率乘以这个因子 (lr = lr * 0.2)\n",
    "    patience=5,      # 容忍指标连续5个epoch不改善，才降低学习率\n",
    "    verbose=True,    # 当学习率更新时，在控制台打印一条消息\n",
    "    min_lr=1e-6      # 学习率的下限，防止降得太低\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab097bf3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T08:10:22.501846Z",
     "iopub.status.busy": "2025-07-22T08:10:22.501194Z",
     "iopub.status.idle": "2025-07-22T13:12:14.431969Z",
     "shell.execute_reply": "2025-07-22T13:12:14.431070Z"
    },
    "id": "TPQDHvb1xCT_",
    "papermill": {
     "duration": 18111.944234,
     "end_time": "2025-07-22T13:12:14.433549",
     "exception": false,
     "start_time": "2025-07-22T08:10:22.489315",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-22 08:10:24.406722: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753171824.591055      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753171824.642758      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training...\n",
      "--- Epoch 1/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.52it/s, loss=0.5714]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.75it/s, loss=0.5262]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 Summary:\n",
      "  Train Loss: 0.6233, Train Pixel Accuracy: 64.57%\n",
      "  Validation Loss: 0.5248, Validation Pixel Accuracy: 74.12%\n",
      "  Current learning rate: 0.001000\n",
      "  ---> New best model saved to /kaggle/working/fcn_pet_best.pth (Validation Loss: 0.5248)\n",
      "------------------------------\n",
      "--- Epoch 2/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [00:59<00:00,  7.70it/s, loss=0.5066]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.80it/s, loss=0.5303]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 Summary:\n",
      "  Train Loss: 0.5555, Train Pixel Accuracy: 72.46%\n",
      "  Validation Loss: 0.4956, Validation Pixel Accuracy: 77.00%\n",
      "  Current learning rate: 0.001000\n",
      "  ---> New best model saved to /kaggle/working/fcn_pet_best.pth (Validation Loss: 0.4956)\n",
      "------------------------------\n",
      "--- Epoch 3/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [00:59<00:00,  7.72it/s, loss=0.5202]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.37it/s, loss=0.3858]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3 Summary:\n",
      "  Train Loss: 0.5135, Train Pixel Accuracy: 75.20%\n",
      "  Validation Loss: 0.3880, Validation Pixel Accuracy: 83.92%\n",
      "  Current learning rate: 0.001000\n",
      "  ---> New best model saved to /kaggle/working/fcn_pet_best.pth (Validation Loss: 0.3880)\n",
      "------------------------------\n",
      "--- Epoch 4/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [00:59<00:00,  7.76it/s, loss=0.4906]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.67it/s, loss=0.4255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4 Summary:\n",
      "  Train Loss: 0.4548, Train Pixel Accuracy: 78.99%\n",
      "  Validation Loss: 0.4165, Validation Pixel Accuracy: 80.86%\n",
      "  Current learning rate: 0.001000\n",
      "------------------------------\n",
      "--- Epoch 5/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [00:59<00:00,  7.74it/s, loss=0.4209]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:28<00:00, 15.98it/s, loss=0.3731]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5 Summary:\n",
      "  Train Loss: 0.4056, Train Pixel Accuracy: 81.74%\n",
      "  Validation Loss: 0.3467, Validation Pixel Accuracy: 85.33%\n",
      "  Current learning rate: 0.001000\n",
      "  ---> New best model saved to /kaggle/working/fcn_pet_best.pth (Validation Loss: 0.3467)\n",
      "------------------------------\n",
      "--- Epoch 6/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.60it/s, loss=0.3727]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.18it/s, loss=0.2741]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6 Summary:\n",
      "  Train Loss: 0.3776, Train Pixel Accuracy: 83.28%\n",
      "  Validation Loss: 0.2852, Validation Pixel Accuracy: 88.04%\n",
      "  Current learning rate: 0.001000\n",
      "  ---> New best model saved to /kaggle/working/fcn_pet_best.pth (Validation Loss: 0.2852)\n",
      "------------------------------\n",
      "--- Epoch 7/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.63it/s, loss=0.3307]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.52it/s, loss=0.2807]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7 Summary:\n",
      "  Train Loss: 0.3546, Train Pixel Accuracy: 84.51%\n",
      "  Validation Loss: 0.2629, Validation Pixel Accuracy: 89.34%\n",
      "  Current learning rate: 0.001000\n",
      "  ---> New best model saved to /kaggle/working/fcn_pet_best.pth (Validation Loss: 0.2629)\n",
      "------------------------------\n",
      "--- Epoch 8/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.62it/s, loss=0.3529]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.49it/s, loss=0.2283]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8 Summary:\n",
      "  Train Loss: 0.3332, Train Pixel Accuracy: 85.57%\n",
      "  Validation Loss: 0.2514, Validation Pixel Accuracy: 89.91%\n",
      "  Current learning rate: 0.001000\n",
      "  ---> New best model saved to /kaggle/working/fcn_pet_best.pth (Validation Loss: 0.2514)\n",
      "------------------------------\n",
      "--- Epoch 9/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.60it/s, loss=0.3267]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.55it/s, loss=0.3158]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9 Summary:\n",
      "  Train Loss: 0.3162, Train Pixel Accuracy: 86.47%\n",
      "  Validation Loss: 0.2526, Validation Pixel Accuracy: 89.62%\n",
      "  Current learning rate: 0.001000\n",
      "------------------------------\n",
      "--- Epoch 10/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.56it/s, loss=0.3611]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.29it/s, loss=0.2353]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10 Summary:\n",
      "  Train Loss: 0.2981, Train Pixel Accuracy: 87.30%\n",
      "  Validation Loss: 0.2407, Validation Pixel Accuracy: 91.28%\n",
      "  Current learning rate: 0.001000\n",
      "  ---> New best model saved to /kaggle/working/fcn_pet_best.pth (Validation Loss: 0.2407)\n",
      "------------------------------\n",
      "--- Epoch 11/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.64it/s, loss=0.2933]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.10it/s, loss=0.2552]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11 Summary:\n",
      "  Train Loss: 0.2916, Train Pixel Accuracy: 87.56%\n",
      "  Validation Loss: 0.2129, Validation Pixel Accuracy: 91.39%\n",
      "  Current learning rate: 0.001000\n",
      "  ---> New best model saved to /kaggle/working/fcn_pet_best.pth (Validation Loss: 0.2129)\n",
      "------------------------------\n",
      "--- Epoch 12/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.64it/s, loss=0.3321]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.30it/s, loss=0.1471]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12 Summary:\n",
      "  Train Loss: 0.2820, Train Pixel Accuracy: 88.09%\n",
      "  Validation Loss: 0.1950, Validation Pixel Accuracy: 92.21%\n",
      "  Current learning rate: 0.001000\n",
      "  ---> New best model saved to /kaggle/working/fcn_pet_best.pth (Validation Loss: 0.1950)\n",
      "------------------------------\n",
      "--- Epoch 13/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.57it/s, loss=0.1768]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.19it/s, loss=0.1635]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13 Summary:\n",
      "  Train Loss: 0.2661, Train Pixel Accuracy: 88.92%\n",
      "  Validation Loss: 0.1967, Validation Pixel Accuracy: 92.30%\n",
      "  Current learning rate: 0.001000\n",
      "------------------------------\n",
      "--- Epoch 14/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.57it/s, loss=0.1492]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.35it/s, loss=0.1485]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14 Summary:\n",
      "  Train Loss: 0.2623, Train Pixel Accuracy: 89.14%\n",
      "  Validation Loss: 0.2025, Validation Pixel Accuracy: 91.92%\n",
      "  Current learning rate: 0.001000\n",
      "------------------------------\n",
      "--- Epoch 15/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.57it/s, loss=0.1200]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.18it/s, loss=0.2002]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15 Summary:\n",
      "  Train Loss: 0.2551, Train Pixel Accuracy: 89.53%\n",
      "  Validation Loss: 0.2065, Validation Pixel Accuracy: 91.77%\n",
      "  Current learning rate: 0.001000\n",
      "------------------------------\n",
      "--- Epoch 16/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.56it/s, loss=0.3850]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.17it/s, loss=0.1566]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16 Summary:\n",
      "  Train Loss: 0.2551, Train Pixel Accuracy: 89.31%\n",
      "  Validation Loss: 0.1886, Validation Pixel Accuracy: 92.49%\n",
      "  Current learning rate: 0.001000\n",
      "  ---> New best model saved to /kaggle/working/fcn_pet_best.pth (Validation Loss: 0.1886)\n",
      "------------------------------\n",
      "--- Epoch 17/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.53it/s, loss=0.2490]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.27it/s, loss=0.1935]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 17 Summary:\n",
      "  Train Loss: 0.2437, Train Pixel Accuracy: 89.92%\n",
      "  Validation Loss: 0.2192, Validation Pixel Accuracy: 90.97%\n",
      "  Current learning rate: 0.001000\n",
      "------------------------------\n",
      "--- Epoch 18/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.57it/s, loss=0.2180]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.54it/s, loss=0.2286]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 18 Summary:\n",
      "  Train Loss: 0.2438, Train Pixel Accuracy: 89.96%\n",
      "  Validation Loss: 0.1946, Validation Pixel Accuracy: 92.29%\n",
      "  Current learning rate: 0.001000\n",
      "------------------------------\n",
      "--- Epoch 19/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [00:59<00:00,  7.69it/s, loss=0.2276]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.58it/s, loss=0.1828]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19 Summary:\n",
      "  Train Loss: 0.2376, Train Pixel Accuracy: 90.30%\n",
      "  Validation Loss: 0.1721, Validation Pixel Accuracy: 93.35%\n",
      "  Current learning rate: 0.001000\n",
      "  ---> New best model saved to /kaggle/working/fcn_pet_best.pth (Validation Loss: 0.1721)\n",
      "------------------------------\n",
      "--- Epoch 20/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.59it/s, loss=0.2073]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.49it/s, loss=0.1420]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20 Summary:\n",
      "  Train Loss: 0.2433, Train Pixel Accuracy: 90.01%\n",
      "  Validation Loss: 0.1715, Validation Pixel Accuracy: 93.36%\n",
      "  Current learning rate: 0.001000\n",
      "  ---> New best model saved to /kaggle/working/fcn_pet_best.pth (Validation Loss: 0.1715)\n",
      "------------------------------\n",
      "--- Epoch 21/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.62it/s, loss=0.1645]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.31it/s, loss=0.1907]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 21 Summary:\n",
      "  Train Loss: 0.2325, Train Pixel Accuracy: 90.44%\n",
      "  Validation Loss: 0.1950, Validation Pixel Accuracy: 92.25%\n",
      "  Current learning rate: 0.001000\n",
      "------------------------------\n",
      "--- Epoch 22/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.62it/s, loss=0.1449]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.39it/s, loss=0.1535]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 22 Summary:\n",
      "  Train Loss: 0.2303, Train Pixel Accuracy: 90.63%\n",
      "  Validation Loss: 0.1691, Validation Pixel Accuracy: 93.59%\n",
      "  Current learning rate: 0.001000\n",
      "  ---> New best model saved to /kaggle/working/fcn_pet_best.pth (Validation Loss: 0.1691)\n",
      "------------------------------\n",
      "--- Epoch 23/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.63it/s, loss=0.1735]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.46it/s, loss=0.1710]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 23 Summary:\n",
      "  Train Loss: 0.2241, Train Pixel Accuracy: 90.87%\n",
      "  Validation Loss: 0.1763, Validation Pixel Accuracy: 93.04%\n",
      "  Current learning rate: 0.001000\n",
      "------------------------------\n",
      "--- Epoch 24/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.62it/s, loss=0.1327]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.46it/s, loss=0.1670]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 24 Summary:\n",
      "  Train Loss: 0.2165, Train Pixel Accuracy: 91.22%\n",
      "  Validation Loss: 0.1750, Validation Pixel Accuracy: 93.18%\n",
      "  Current learning rate: 0.001000\n",
      "------------------------------\n",
      "--- Epoch 25/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.62it/s, loss=0.2107]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.47it/s, loss=0.3143]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 25 Summary:\n",
      "  Train Loss: 0.2179, Train Pixel Accuracy: 91.18%\n",
      "  Validation Loss: 0.2388, Validation Pixel Accuracy: 90.54%\n",
      "  Current learning rate: 0.001000\n",
      "------------------------------\n",
      "--- Epoch 26/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.63it/s, loss=0.1863]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:28<00:00, 16.16it/s, loss=0.1910]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 26 Summary:\n",
      "  Train Loss: 0.2134, Train Pixel Accuracy: 91.32%\n",
      "  Validation Loss: 0.1772, Validation Pixel Accuracy: 93.24%\n",
      "  Current learning rate: 0.001000\n",
      "------------------------------\n",
      "--- Epoch 27/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [00:58<00:00,  7.80it/s, loss=0.2143]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:28<00:00, 15.96it/s, loss=0.2717]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 27 Summary:\n",
      "  Train Loss: 0.2128, Train Pixel Accuracy: 91.41%\n",
      "  Validation Loss: 0.1703, Validation Pixel Accuracy: 93.45%\n",
      "  Current learning rate: 0.001000\n",
      "------------------------------\n",
      "--- Epoch 28/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [00:58<00:00,  7.80it/s, loss=0.1199]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:28<00:00, 16.23it/s, loss=0.2363]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 28 Summary:\n",
      "  Train Loss: 0.2051, Train Pixel Accuracy: 91.71%\n",
      "  Validation Loss: 0.2039, Validation Pixel Accuracy: 92.28%\n",
      "  Current learning rate: 0.000200\n",
      "------------------------------\n",
      "--- Epoch 29/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [00:59<00:00,  7.78it/s, loss=0.1434]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.70it/s, loss=0.1871]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 29 Summary:\n",
      "  Train Loss: 0.1763, Train Pixel Accuracy: 92.98%\n",
      "  Validation Loss: 0.1526, Validation Pixel Accuracy: 94.20%\n",
      "  Current learning rate: 0.000200\n",
      "  ---> New best model saved to /kaggle/working/fcn_pet_best.pth (Validation Loss: 0.1526)\n",
      "------------------------------\n",
      "--- Epoch 30/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [00:58<00:00,  7.81it/s, loss=0.1348]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:28<00:00, 15.88it/s, loss=0.1420]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 30 Summary:\n",
      "  Train Loss: 0.1690, Train Pixel Accuracy: 93.28%\n",
      "  Validation Loss: 0.1435, Validation Pixel Accuracy: 94.60%\n",
      "  Current learning rate: 0.000200\n",
      "  ---> New best model saved to /kaggle/working/fcn_pet_best.pth (Validation Loss: 0.1435)\n",
      "------------------------------\n",
      "--- Epoch 31/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [00:58<00:00,  7.81it/s, loss=0.2188]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.34it/s, loss=0.1497]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 31 Summary:\n",
      "  Train Loss: 0.1675, Train Pixel Accuracy: 93.35%\n",
      "  Validation Loss: 0.1396, Validation Pixel Accuracy: 94.73%\n",
      "  Current learning rate: 0.000200\n",
      "  ---> New best model saved to /kaggle/working/fcn_pet_best.pth (Validation Loss: 0.1396)\n",
      "------------------------------\n",
      "--- Epoch 32/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.58it/s, loss=0.2661]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.28it/s, loss=0.1798]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 32 Summary:\n",
      "  Train Loss: 0.1668, Train Pixel Accuracy: 93.37%\n",
      "  Validation Loss: 0.1547, Validation Pixel Accuracy: 94.20%\n",
      "  Current learning rate: 0.000200\n",
      "------------------------------\n",
      "--- Epoch 33/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.63it/s, loss=0.2326]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.28it/s, loss=0.1687]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 33 Summary:\n",
      "  Train Loss: 0.1636, Train Pixel Accuracy: 93.55%\n",
      "  Validation Loss: 0.1411, Validation Pixel Accuracy: 94.74%\n",
      "  Current learning rate: 0.000200\n",
      "------------------------------\n",
      "--- Epoch 34/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.53it/s, loss=0.1115]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.30it/s, loss=0.1623]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 34 Summary:\n",
      "  Train Loss: 0.1621, Train Pixel Accuracy: 93.58%\n",
      "  Validation Loss: 0.1416, Validation Pixel Accuracy: 94.70%\n",
      "  Current learning rate: 0.000200\n",
      "------------------------------\n",
      "--- Epoch 35/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.58it/s, loss=0.0922]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.38it/s, loss=0.1555]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 35 Summary:\n",
      "  Train Loss: 0.1593, Train Pixel Accuracy: 93.71%\n",
      "  Validation Loss: 0.1419, Validation Pixel Accuracy: 94.74%\n",
      "  Current learning rate: 0.000200\n",
      "------------------------------\n",
      "--- Epoch 36/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.47it/s, loss=0.1279]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.21it/s, loss=0.1452]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 36 Summary:\n",
      "  Train Loss: 0.1624, Train Pixel Accuracy: 93.58%\n",
      "  Validation Loss: 0.1354, Validation Pixel Accuracy: 94.97%\n",
      "  Current learning rate: 0.000200\n",
      "  ---> New best model saved to /kaggle/working/fcn_pet_best.pth (Validation Loss: 0.1354)\n",
      "------------------------------\n",
      "--- Epoch 37/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.50it/s, loss=0.1187]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.29it/s, loss=0.1587]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 37 Summary:\n",
      "  Train Loss: 0.1611, Train Pixel Accuracy: 93.59%\n",
      "  Validation Loss: 0.1444, Validation Pixel Accuracy: 94.60%\n",
      "  Current learning rate: 0.000200\n",
      "------------------------------\n",
      "--- Epoch 38/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.59it/s, loss=0.1806]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.34it/s, loss=0.2053]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 38 Summary:\n",
      "  Train Loss: 0.1602, Train Pixel Accuracy: 93.69%\n",
      "  Validation Loss: 0.1445, Validation Pixel Accuracy: 94.59%\n",
      "  Current learning rate: 0.000200\n",
      "------------------------------\n",
      "--- Epoch 39/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.54it/s, loss=0.1367]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.30it/s, loss=0.1775]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 39 Summary:\n",
      "  Train Loss: 0.1583, Train Pixel Accuracy: 93.76%\n",
      "  Validation Loss: 0.1375, Validation Pixel Accuracy: 94.85%\n",
      "  Current learning rate: 0.000200\n",
      "------------------------------\n",
      "--- Epoch 40/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.61it/s, loss=0.1327]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.10it/s, loss=0.1657]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 40 Summary:\n",
      "  Train Loss: 0.1543, Train Pixel Accuracy: 93.92%\n",
      "  Validation Loss: 0.1465, Validation Pixel Accuracy: 94.50%\n",
      "  Current learning rate: 0.000200\n",
      "------------------------------\n",
      "--- Epoch 41/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.52it/s, loss=0.4465]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.17it/s, loss=0.1608]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 41 Summary:\n",
      "  Train Loss: 0.1557, Train Pixel Accuracy: 93.86%\n",
      "  Validation Loss: 0.1368, Validation Pixel Accuracy: 94.97%\n",
      "  Current learning rate: 0.000200\n",
      "------------------------------\n",
      "--- Epoch 42/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.57it/s, loss=0.2052]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.37it/s, loss=0.1643]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 42 Summary:\n",
      "  Train Loss: 0.1548, Train Pixel Accuracy: 93.83%\n",
      "  Validation Loss: 0.1435, Validation Pixel Accuracy: 94.72%\n",
      "  Current learning rate: 0.000040\n",
      "------------------------------\n",
      "--- Epoch 43/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.54it/s, loss=0.2922]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.28it/s, loss=0.1544]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 43 Summary:\n",
      "  Train Loss: 0.1497, Train Pixel Accuracy: 94.14%\n",
      "  Validation Loss: 0.1371, Validation Pixel Accuracy: 94.97%\n",
      "  Current learning rate: 0.000040\n",
      "------------------------------\n",
      "--- Epoch 44/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.64it/s, loss=0.1069]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.28it/s, loss=0.1494]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 44 Summary:\n",
      "  Train Loss: 0.1445, Train Pixel Accuracy: 94.25%\n",
      "  Validation Loss: 0.1377, Validation Pixel Accuracy: 94.93%\n",
      "  Current learning rate: 0.000040\n",
      "------------------------------\n",
      "--- Epoch 45/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.58it/s, loss=0.1460]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.45it/s, loss=0.1549]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 45 Summary:\n",
      "  Train Loss: 0.1438, Train Pixel Accuracy: 94.37%\n",
      "  Validation Loss: 0.1370, Validation Pixel Accuracy: 94.97%\n",
      "  Current learning rate: 0.000040\n",
      "------------------------------\n",
      "--- Epoch 46/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.62it/s, loss=0.2246]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.37it/s, loss=0.1726]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 46 Summary:\n",
      "  Train Loss: 0.1426, Train Pixel Accuracy: 94.39%\n",
      "  Validation Loss: 0.1447, Validation Pixel Accuracy: 94.66%\n",
      "  Current learning rate: 0.000040\n",
      "------------------------------\n",
      "--- Epoch 47/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.59it/s, loss=0.0703]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.41it/s, loss=0.1622]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 47 Summary:\n",
      "  Train Loss: 0.1431, Train Pixel Accuracy: 94.33%\n",
      "  Validation Loss: 0.1380, Validation Pixel Accuracy: 94.91%\n",
      "  Current learning rate: 0.000040\n",
      "------------------------------\n",
      "--- Epoch 48/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.59it/s, loss=0.3115]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.34it/s, loss=0.1593]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 48 Summary:\n",
      "  Train Loss: 0.1413, Train Pixel Accuracy: 94.43%\n",
      "  Validation Loss: 0.1335, Validation Pixel Accuracy: 95.11%\n",
      "  Current learning rate: 0.000040\n",
      "  ---> New best model saved to /kaggle/working/fcn_pet_best.pth (Validation Loss: 0.1335)\n",
      "------------------------------\n",
      "--- Epoch 49/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.55it/s, loss=0.0998]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.32it/s, loss=0.1578]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 49 Summary:\n",
      "  Train Loss: 0.1434, Train Pixel Accuracy: 94.32%\n",
      "  Validation Loss: 0.1341, Validation Pixel Accuracy: 95.09%\n",
      "  Current learning rate: 0.000040\n",
      "------------------------------\n",
      "--- Epoch 50/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.63it/s, loss=0.1444]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.25it/s, loss=0.1410]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 50 Summary:\n",
      "  Train Loss: 0.1424, Train Pixel Accuracy: 94.41%\n",
      "  Validation Loss: 0.1327, Validation Pixel Accuracy: 95.12%\n",
      "  Current learning rate: 0.000040\n",
      "  ---> New best model saved to /kaggle/working/fcn_pet_best.pth (Validation Loss: 0.1327)\n",
      "------------------------------\n",
      "--- Epoch 51/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.60it/s, loss=0.0935]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.72it/s, loss=0.1469]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 51 Summary:\n",
      "  Train Loss: 0.1402, Train Pixel Accuracy: 94.51%\n",
      "  Validation Loss: 0.1280, Validation Pixel Accuracy: 95.33%\n",
      "  Current learning rate: 0.000040\n",
      "  ---> New best model saved to /kaggle/working/fcn_pet_best.pth (Validation Loss: 0.1280)\n",
      "------------------------------\n",
      "--- Epoch 52/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [00:58<00:00,  7.81it/s, loss=0.1724]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:28<00:00, 16.04it/s, loss=0.1718]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 52 Summary:\n",
      "  Train Loss: 0.1409, Train Pixel Accuracy: 94.44%\n",
      "  Validation Loss: 0.1382, Validation Pixel Accuracy: 94.97%\n",
      "  Current learning rate: 0.000040\n",
      "------------------------------\n",
      "--- Epoch 53/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [00:59<00:00,  7.74it/s, loss=0.1052]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.17it/s, loss=0.1612]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 53 Summary:\n",
      "  Train Loss: 0.1401, Train Pixel Accuracy: 94.50%\n",
      "  Validation Loss: 0.1345, Validation Pixel Accuracy: 95.09%\n",
      "  Current learning rate: 0.000040\n",
      "------------------------------\n",
      "--- Epoch 54/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.56it/s, loss=0.1550]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.35it/s, loss=0.1574]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 54 Summary:\n",
      "  Train Loss: 0.1382, Train Pixel Accuracy: 94.52%\n",
      "  Validation Loss: 0.1326, Validation Pixel Accuracy: 95.15%\n",
      "  Current learning rate: 0.000040\n",
      "------------------------------\n",
      "--- Epoch 55/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.63it/s, loss=0.0751]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.39it/s, loss=0.1539]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 55 Summary:\n",
      "  Train Loss: 0.1407, Train Pixel Accuracy: 94.45%\n",
      "  Validation Loss: 0.1350, Validation Pixel Accuracy: 95.06%\n",
      "  Current learning rate: 0.000040\n",
      "------------------------------\n",
      "--- Epoch 56/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.55it/s, loss=0.1323]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.27it/s, loss=0.1442]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 56 Summary:\n",
      "  Train Loss: 0.1399, Train Pixel Accuracy: 94.54%\n",
      "  Validation Loss: 0.1324, Validation Pixel Accuracy: 95.15%\n",
      "  Current learning rate: 0.000040\n",
      "------------------------------\n",
      "--- Epoch 57/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.65it/s, loss=0.1431]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.42it/s, loss=0.1237]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 57 Summary:\n",
      "  Train Loss: 0.1394, Train Pixel Accuracy: 94.56%\n",
      "  Validation Loss: 0.1288, Validation Pixel Accuracy: 95.29%\n",
      "  Current learning rate: 0.000008\n",
      "------------------------------\n",
      "--- Epoch 58/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.53it/s, loss=0.1450]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.28it/s, loss=0.1430]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 58 Summary:\n",
      "  Train Loss: 0.1379, Train Pixel Accuracy: 94.60%\n",
      "  Validation Loss: 0.1333, Validation Pixel Accuracy: 95.13%\n",
      "  Current learning rate: 0.000008\n",
      "------------------------------\n",
      "--- Epoch 59/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.56it/s, loss=0.1103]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.52it/s, loss=0.1392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 59 Summary:\n",
      "  Train Loss: 0.1368, Train Pixel Accuracy: 94.67%\n",
      "  Validation Loss: 0.1323, Validation Pixel Accuracy: 95.18%\n",
      "  Current learning rate: 0.000008\n",
      "------------------------------\n",
      "--- Epoch 60/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.57it/s, loss=0.1922]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.38it/s, loss=0.1424]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 60 Summary:\n",
      "  Train Loss: 0.1370, Train Pixel Accuracy: 94.64%\n",
      "  Validation Loss: 0.1321, Validation Pixel Accuracy: 95.19%\n",
      "  Current learning rate: 0.000008\n",
      "------------------------------\n",
      "--- Epoch 61/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.55it/s, loss=0.1168]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.01it/s, loss=0.1395]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 61 Summary:\n",
      "  Train Loss: 0.1364, Train Pixel Accuracy: 94.70%\n",
      "  Validation Loss: 0.1305, Validation Pixel Accuracy: 95.25%\n",
      "  Current learning rate: 0.000008\n",
      "------------------------------\n",
      "--- Epoch 62/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.58it/s, loss=0.1351]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.26it/s, loss=0.1383]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 62 Summary:\n",
      "  Train Loss: 0.1377, Train Pixel Accuracy: 94.54%\n",
      "  Validation Loss: 0.1307, Validation Pixel Accuracy: 95.25%\n",
      "  Current learning rate: 0.000008\n",
      "------------------------------\n",
      "--- Epoch 63/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.54it/s, loss=0.1710]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.31it/s, loss=0.1416]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 63 Summary:\n",
      "  Train Loss: 0.1362, Train Pixel Accuracy: 94.68%\n",
      "  Validation Loss: 0.1316, Validation Pixel Accuracy: 95.21%\n",
      "  Current learning rate: 0.000002\n",
      "------------------------------\n",
      "--- Epoch 64/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.56it/s, loss=0.1232]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 14.98it/s, loss=0.1413]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 64 Summary:\n",
      "  Train Loss: 0.1388, Train Pixel Accuracy: 94.56%\n",
      "  Validation Loss: 0.1313, Validation Pixel Accuracy: 95.22%\n",
      "  Current learning rate: 0.000002\n",
      "------------------------------\n",
      "--- Epoch 65/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.56it/s, loss=0.2569]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.21it/s, loss=0.1402]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 65 Summary:\n",
      "  Train Loss: 0.1381, Train Pixel Accuracy: 94.59%\n",
      "  Validation Loss: 0.1310, Validation Pixel Accuracy: 95.23%\n",
      "  Current learning rate: 0.000002\n",
      "------------------------------\n",
      "--- Epoch 66/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.65it/s, loss=0.0995]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.49it/s, loss=0.1426]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 66 Summary:\n",
      "  Train Loss: 0.1358, Train Pixel Accuracy: 94.65%\n",
      "  Validation Loss: 0.1317, Validation Pixel Accuracy: 95.21%\n",
      "  Current learning rate: 0.000002\n",
      "------------------------------\n",
      "--- Epoch 67/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.62it/s, loss=0.2178]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.48it/s, loss=0.1423]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 67 Summary:\n",
      "  Train Loss: 0.1354, Train Pixel Accuracy: 94.71%\n",
      "  Validation Loss: 0.1313, Validation Pixel Accuracy: 95.22%\n",
      "  Current learning rate: 0.000002\n",
      "------------------------------\n",
      "--- Epoch 68/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.59it/s, loss=0.1135]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.30it/s, loss=0.1405]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 68 Summary:\n",
      "  Train Loss: 0.1367, Train Pixel Accuracy: 94.58%\n",
      "  Validation Loss: 0.1309, Validation Pixel Accuracy: 95.24%\n",
      "  Current learning rate: 0.000002\n",
      "------------------------------\n",
      "--- Epoch 69/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.60it/s, loss=0.1863]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.44it/s, loss=0.1439]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 69 Summary:\n",
      "  Train Loss: 0.1366, Train Pixel Accuracy: 94.64%\n",
      "  Validation Loss: 0.1317, Validation Pixel Accuracy: 95.20%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 70/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.61it/s, loss=0.0942]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.30it/s, loss=0.1436]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 70 Summary:\n",
      "  Train Loss: 0.1373, Train Pixel Accuracy: 94.58%\n",
      "  Validation Loss: 0.1315, Validation Pixel Accuracy: 95.21%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 71/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.56it/s, loss=0.1416]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.64it/s, loss=0.1437]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 71 Summary:\n",
      "  Train Loss: 0.1354, Train Pixel Accuracy: 94.67%\n",
      "  Validation Loss: 0.1316, Validation Pixel Accuracy: 95.21%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 72/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.58it/s, loss=0.1269]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.46it/s, loss=0.1448]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 72 Summary:\n",
      "  Train Loss: 0.1360, Train Pixel Accuracy: 94.65%\n",
      "  Validation Loss: 0.1318, Validation Pixel Accuracy: 95.20%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 73/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [00:59<00:00,  7.67it/s, loss=0.1434]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:28<00:00, 15.92it/s, loss=0.1447]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 73 Summary:\n",
      "  Train Loss: 0.1395, Train Pixel Accuracy: 94.53%\n",
      "  Validation Loss: 0.1318, Validation Pixel Accuracy: 95.20%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 74/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [00:59<00:00,  7.71it/s, loss=0.0942]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:28<00:00, 15.92it/s, loss=0.1440]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 74 Summary:\n",
      "  Train Loss: 0.1374, Train Pixel Accuracy: 94.59%\n",
      "  Validation Loss: 0.1315, Validation Pixel Accuracy: 95.21%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 75/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.64it/s, loss=0.0860]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:28<00:00, 15.92it/s, loss=0.1437]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 75 Summary:\n",
      "  Train Loss: 0.1351, Train Pixel Accuracy: 94.70%\n",
      "  Validation Loss: 0.1314, Validation Pixel Accuracy: 95.21%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 76/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [00:59<00:00,  7.74it/s, loss=0.0851]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:28<00:00, 15.84it/s, loss=0.1443]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 76 Summary:\n",
      "  Train Loss: 0.1359, Train Pixel Accuracy: 94.66%\n",
      "  Validation Loss: 0.1318, Validation Pixel Accuracy: 95.20%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 77/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.64it/s, loss=0.1339]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:28<00:00, 15.89it/s, loss=0.1450]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 77 Summary:\n",
      "  Train Loss: 0.1333, Train Pixel Accuracy: 94.77%\n",
      "  Validation Loss: 0.1318, Validation Pixel Accuracy: 95.20%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 78/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [00:59<00:00,  7.69it/s, loss=0.1803]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:28<00:00, 15.86it/s, loss=0.1441]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 78 Summary:\n",
      "  Train Loss: 0.1359, Train Pixel Accuracy: 94.67%\n",
      "  Validation Loss: 0.1315, Validation Pixel Accuracy: 95.21%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 79/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.66it/s, loss=0.1136]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:28<00:00, 15.89it/s, loss=0.1440]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 79 Summary:\n",
      "  Train Loss: 0.1384, Train Pixel Accuracy: 94.58%\n",
      "  Validation Loss: 0.1313, Validation Pixel Accuracy: 95.22%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 80/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [00:59<00:00,  7.71it/s, loss=0.1297]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.71it/s, loss=0.1454]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 80 Summary:\n",
      "  Train Loss: 0.1387, Train Pixel Accuracy: 94.53%\n",
      "  Validation Loss: 0.1316, Validation Pixel Accuracy: 95.21%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 81/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [00:59<00:00,  7.73it/s, loss=0.1864]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.80it/s, loss=0.1447]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 81 Summary:\n",
      "  Train Loss: 0.1377, Train Pixel Accuracy: 94.60%\n",
      "  Validation Loss: 0.1315, Validation Pixel Accuracy: 95.21%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 82/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [00:59<00:00,  7.71it/s, loss=0.2061]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:28<00:00, 15.89it/s, loss=0.1450]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 82 Summary:\n",
      "  Train Loss: 0.1366, Train Pixel Accuracy: 94.64%\n",
      "  Validation Loss: 0.1317, Validation Pixel Accuracy: 95.21%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 83/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [00:59<00:00,  7.67it/s, loss=0.1906]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:28<00:00, 15.86it/s, loss=0.1458]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 83 Summary:\n",
      "  Train Loss: 0.1382, Train Pixel Accuracy: 94.56%\n",
      "  Validation Loss: 0.1317, Validation Pixel Accuracy: 95.20%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 84/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.65it/s, loss=0.0936]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:28<00:00, 15.89it/s, loss=0.1447]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 84 Summary:\n",
      "  Train Loss: 0.1347, Train Pixel Accuracy: 94.76%\n",
      "  Validation Loss: 0.1315, Validation Pixel Accuracy: 95.21%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 85/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [00:59<00:00,  7.71it/s, loss=0.1177]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:28<00:00, 15.84it/s, loss=0.1463]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 85 Summary:\n",
      "  Train Loss: 0.1353, Train Pixel Accuracy: 94.68%\n",
      "  Validation Loss: 0.1319, Validation Pixel Accuracy: 95.20%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 86/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.53it/s, loss=0.1270]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.11it/s, loss=0.1468]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 86 Summary:\n",
      "  Train Loss: 0.1370, Train Pixel Accuracy: 94.64%\n",
      "  Validation Loss: 0.1321, Validation Pixel Accuracy: 95.19%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 87/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.54it/s, loss=0.1340]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.30it/s, loss=0.1446]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 87 Summary:\n",
      "  Train Loss: 0.1369, Train Pixel Accuracy: 94.66%\n",
      "  Validation Loss: 0.1315, Validation Pixel Accuracy: 95.21%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 88/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.53it/s, loss=0.2928]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.23it/s, loss=0.1433]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 88 Summary:\n",
      "  Train Loss: 0.1371, Train Pixel Accuracy: 94.61%\n",
      "  Validation Loss: 0.1310, Validation Pixel Accuracy: 95.23%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 89/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.50it/s, loss=0.1213]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.33it/s, loss=0.1451]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 89 Summary:\n",
      "  Train Loss: 0.1367, Train Pixel Accuracy: 94.61%\n",
      "  Validation Loss: 0.1317, Validation Pixel Accuracy: 95.21%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 90/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.54it/s, loss=0.1640]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.25it/s, loss=0.1450]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 90 Summary:\n",
      "  Train Loss: 0.1364, Train Pixel Accuracy: 94.57%\n",
      "  Validation Loss: 0.1318, Validation Pixel Accuracy: 95.20%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 91/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.60it/s, loss=0.1042]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.12it/s, loss=0.1456]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 91 Summary:\n",
      "  Train Loss: 0.1382, Train Pixel Accuracy: 94.55%\n",
      "  Validation Loss: 0.1318, Validation Pixel Accuracy: 95.20%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 92/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.65it/s, loss=0.2530]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.10it/s, loss=0.1448]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 92 Summary:\n",
      "  Train Loss: 0.1356, Train Pixel Accuracy: 94.68%\n",
      "  Validation Loss: 0.1315, Validation Pixel Accuracy: 95.21%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 93/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.57it/s, loss=0.1796]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.14it/s, loss=0.1447]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 93 Summary:\n",
      "  Train Loss: 0.1344, Train Pixel Accuracy: 94.72%\n",
      "  Validation Loss: 0.1314, Validation Pixel Accuracy: 95.22%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 94/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.55it/s, loss=0.1000]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.18it/s, loss=0.1429]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 94 Summary:\n",
      "  Train Loss: 0.1362, Train Pixel Accuracy: 94.65%\n",
      "  Validation Loss: 0.1310, Validation Pixel Accuracy: 95.23%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 95/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.60it/s, loss=0.1520]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.11it/s, loss=0.1441]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 95 Summary:\n",
      "  Train Loss: 0.1368, Train Pixel Accuracy: 94.58%\n",
      "  Validation Loss: 0.1313, Validation Pixel Accuracy: 95.22%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 96/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.59it/s, loss=0.0776]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.22it/s, loss=0.1448]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 96 Summary:\n",
      "  Train Loss: 0.1346, Train Pixel Accuracy: 94.75%\n",
      "  Validation Loss: 0.1315, Validation Pixel Accuracy: 95.21%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 97/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.60it/s, loss=0.0934]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.16it/s, loss=0.1443]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 97 Summary:\n",
      "  Train Loss: 0.1358, Train Pixel Accuracy: 94.67%\n",
      "  Validation Loss: 0.1314, Validation Pixel Accuracy: 95.22%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 98/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.54it/s, loss=0.1770]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.38it/s, loss=0.1431]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 98 Summary:\n",
      "  Train Loss: 0.1388, Train Pixel Accuracy: 94.59%\n",
      "  Validation Loss: 0.1309, Validation Pixel Accuracy: 95.23%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 99/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.57it/s, loss=0.1292]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.29it/s, loss=0.1435]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 99 Summary:\n",
      "  Train Loss: 0.1387, Train Pixel Accuracy: 94.64%\n",
      "  Validation Loss: 0.1312, Validation Pixel Accuracy: 95.22%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 100/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.61it/s, loss=0.1570]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.19it/s, loss=0.1439]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 100 Summary:\n",
      "  Train Loss: 0.1368, Train Pixel Accuracy: 94.64%\n",
      "  Validation Loss: 0.1312, Validation Pixel Accuracy: 95.22%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 101/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.60it/s, loss=0.1345]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.35it/s, loss=0.1434]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 101 Summary:\n",
      "  Train Loss: 0.1363, Train Pixel Accuracy: 94.64%\n",
      "  Validation Loss: 0.1311, Validation Pixel Accuracy: 95.23%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 102/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.60it/s, loss=0.1039]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.29it/s, loss=0.1437]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 102 Summary:\n",
      "  Train Loss: 0.1386, Train Pixel Accuracy: 94.56%\n",
      "  Validation Loss: 0.1310, Validation Pixel Accuracy: 95.23%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 103/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.64it/s, loss=0.1725]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.26it/s, loss=0.1436]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 103 Summary:\n",
      "  Train Loss: 0.1371, Train Pixel Accuracy: 94.64%\n",
      "  Validation Loss: 0.1310, Validation Pixel Accuracy: 95.23%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 104/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.63it/s, loss=0.1473]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.28it/s, loss=0.1426]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 104 Summary:\n",
      "  Train Loss: 0.1352, Train Pixel Accuracy: 94.68%\n",
      "  Validation Loss: 0.1307, Validation Pixel Accuracy: 95.24%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 105/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.60it/s, loss=0.1480]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.38it/s, loss=0.1427]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 105 Summary:\n",
      "  Train Loss: 0.1351, Train Pixel Accuracy: 94.69%\n",
      "  Validation Loss: 0.1305, Validation Pixel Accuracy: 95.25%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 106/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [00:59<00:00,  7.74it/s, loss=0.1471]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:28<00:00, 16.00it/s, loss=0.1443]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 106 Summary:\n",
      "  Train Loss: 0.1370, Train Pixel Accuracy: 94.65%\n",
      "  Validation Loss: 0.1311, Validation Pixel Accuracy: 95.23%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 107/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [00:58<00:00,  7.85it/s, loss=0.1318]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:28<00:00, 16.06it/s, loss=0.1463]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 107 Summary:\n",
      "  Train Loss: 0.1347, Train Pixel Accuracy: 94.71%\n",
      "  Validation Loss: 0.1315, Validation Pixel Accuracy: 95.21%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 108/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [00:59<00:00,  7.72it/s, loss=0.1168]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.81it/s, loss=0.1451]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 108 Summary:\n",
      "  Train Loss: 0.1351, Train Pixel Accuracy: 94.69%\n",
      "  Validation Loss: 0.1313, Validation Pixel Accuracy: 95.22%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 109/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.66it/s, loss=0.3626]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.66it/s, loss=0.1457]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 109 Summary:\n",
      "  Train Loss: 0.1341, Train Pixel Accuracy: 94.72%\n",
      "  Validation Loss: 0.1315, Validation Pixel Accuracy: 95.22%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 110/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.60it/s, loss=0.1780]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.81it/s, loss=0.1473]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 110 Summary:\n",
      "  Train Loss: 0.1342, Train Pixel Accuracy: 94.72%\n",
      "  Validation Loss: 0.1319, Validation Pixel Accuracy: 95.20%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 111/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [00:59<00:00,  7.77it/s, loss=0.1186]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:28<00:00, 15.95it/s, loss=0.1458]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 111 Summary:\n",
      "  Train Loss: 0.1346, Train Pixel Accuracy: 94.69%\n",
      "  Validation Loss: 0.1314, Validation Pixel Accuracy: 95.22%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 112/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [00:58<00:00,  7.80it/s, loss=0.1939]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:28<00:00, 15.96it/s, loss=0.1448]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 112 Summary:\n",
      "  Train Loss: 0.1391, Train Pixel Accuracy: 94.56%\n",
      "  Validation Loss: 0.1313, Validation Pixel Accuracy: 95.22%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 113/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [00:59<00:00,  7.68it/s, loss=0.1261]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.50it/s, loss=0.1428]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 113 Summary:\n",
      "  Train Loss: 0.1368, Train Pixel Accuracy: 94.61%\n",
      "  Validation Loss: 0.1307, Validation Pixel Accuracy: 95.24%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 114/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.49it/s, loss=0.1332]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.20it/s, loss=0.1438]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 114 Summary:\n",
      "  Train Loss: 0.1337, Train Pixel Accuracy: 94.75%\n",
      "  Validation Loss: 0.1310, Validation Pixel Accuracy: 95.23%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 115/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.52it/s, loss=0.0542]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.30it/s, loss=0.1439]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 115 Summary:\n",
      "  Train Loss: 0.1398, Train Pixel Accuracy: 94.53%\n",
      "  Validation Loss: 0.1311, Validation Pixel Accuracy: 95.23%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 116/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.56it/s, loss=0.0629]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.41it/s, loss=0.1442]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 116 Summary:\n",
      "  Train Loss: 0.1356, Train Pixel Accuracy: 94.68%\n",
      "  Validation Loss: 0.1311, Validation Pixel Accuracy: 95.23%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 117/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.59it/s, loss=0.1246]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.35it/s, loss=0.1435]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 117 Summary:\n",
      "  Train Loss: 0.1372, Train Pixel Accuracy: 94.65%\n",
      "  Validation Loss: 0.1307, Validation Pixel Accuracy: 95.24%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 118/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.55it/s, loss=0.1375]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.64it/s, loss=0.1448]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 118 Summary:\n",
      "  Train Loss: 0.1374, Train Pixel Accuracy: 94.64%\n",
      "  Validation Loss: 0.1312, Validation Pixel Accuracy: 95.22%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 119/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.58it/s, loss=0.1862]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.36it/s, loss=0.1440]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 119 Summary:\n",
      "  Train Loss: 0.1375, Train Pixel Accuracy: 94.56%\n",
      "  Validation Loss: 0.1310, Validation Pixel Accuracy: 95.23%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 120/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.65it/s, loss=0.1328]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.75it/s, loss=0.1456]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 120 Summary:\n",
      "  Train Loss: 0.1360, Train Pixel Accuracy: 94.68%\n",
      "  Validation Loss: 0.1315, Validation Pixel Accuracy: 95.22%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 121/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [00:58<00:00,  7.82it/s, loss=0.2776]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.80it/s, loss=0.1437]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 121 Summary:\n",
      "  Train Loss: 0.1365, Train Pixel Accuracy: 94.63%\n",
      "  Validation Loss: 0.1311, Validation Pixel Accuracy: 95.23%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 122/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.67it/s, loss=0.1233]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:28<00:00, 15.83it/s, loss=0.1426]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 122 Summary:\n",
      "  Train Loss: 0.1355, Train Pixel Accuracy: 94.71%\n",
      "  Validation Loss: 0.1310, Validation Pixel Accuracy: 95.23%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 123/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [00:59<00:00,  7.70it/s, loss=0.1143]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.75it/s, loss=0.1432]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 123 Summary:\n",
      "  Train Loss: 0.1374, Train Pixel Accuracy: 94.61%\n",
      "  Validation Loss: 0.1310, Validation Pixel Accuracy: 95.23%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 124/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [00:59<00:00,  7.70it/s, loss=0.1088]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.60it/s, loss=0.1447]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 124 Summary:\n",
      "  Train Loss: 0.1371, Train Pixel Accuracy: 94.59%\n",
      "  Validation Loss: 0.1314, Validation Pixel Accuracy: 95.22%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 125/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [00:59<00:00,  7.70it/s, loss=0.1378]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.62it/s, loss=0.1439]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 125 Summary:\n",
      "  Train Loss: 0.1353, Train Pixel Accuracy: 94.73%\n",
      "  Validation Loss: 0.1311, Validation Pixel Accuracy: 95.23%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 126/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [00:59<00:00,  7.70it/s, loss=0.1604]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:28<00:00, 15.90it/s, loss=0.1431]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 126 Summary:\n",
      "  Train Loss: 0.1366, Train Pixel Accuracy: 94.63%\n",
      "  Validation Loss: 0.1309, Validation Pixel Accuracy: 95.24%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 127/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [00:59<00:00,  7.75it/s, loss=0.1023]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:28<00:00, 15.89it/s, loss=0.1442]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 127 Summary:\n",
      "  Train Loss: 0.1372, Train Pixel Accuracy: 94.58%\n",
      "  Validation Loss: 0.1312, Validation Pixel Accuracy: 95.22%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 128/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [00:58<00:00,  7.82it/s, loss=0.0917]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.80it/s, loss=0.1431]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 128 Summary:\n",
      "  Train Loss: 0.1388, Train Pixel Accuracy: 94.52%\n",
      "  Validation Loss: 0.1309, Validation Pixel Accuracy: 95.24%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 129/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [00:59<00:00,  7.67it/s, loss=0.1120]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.61it/s, loss=0.1453]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 129 Summary:\n",
      "  Train Loss: 0.1362, Train Pixel Accuracy: 94.67%\n",
      "  Validation Loss: 0.1314, Validation Pixel Accuracy: 95.22%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 130/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.64it/s, loss=0.1030]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.70it/s, loss=0.1454]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 130 Summary:\n",
      "  Train Loss: 0.1365, Train Pixel Accuracy: 94.65%\n",
      "  Validation Loss: 0.1314, Validation Pixel Accuracy: 95.22%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 131/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.66it/s, loss=0.1329]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.57it/s, loss=0.1438]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 131 Summary:\n",
      "  Train Loss: 0.1347, Train Pixel Accuracy: 94.67%\n",
      "  Validation Loss: 0.1309, Validation Pixel Accuracy: 95.24%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 132/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [00:59<00:00,  7.68it/s, loss=0.1290]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.70it/s, loss=0.1433]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 132 Summary:\n",
      "  Train Loss: 0.1364, Train Pixel Accuracy: 94.68%\n",
      "  Validation Loss: 0.1306, Validation Pixel Accuracy: 95.25%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 133/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.61it/s, loss=0.0906]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.63it/s, loss=0.1442]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 133 Summary:\n",
      "  Train Loss: 0.1363, Train Pixel Accuracy: 94.66%\n",
      "  Validation Loss: 0.1309, Validation Pixel Accuracy: 95.24%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 134/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [00:59<00:00,  7.68it/s, loss=0.2033]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.67it/s, loss=0.1444]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 134 Summary:\n",
      "  Train Loss: 0.1345, Train Pixel Accuracy: 94.69%\n",
      "  Validation Loss: 0.1312, Validation Pixel Accuracy: 95.23%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 135/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.66it/s, loss=0.1438]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.46it/s, loss=0.1445]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 135 Summary:\n",
      "  Train Loss: 0.1362, Train Pixel Accuracy: 94.62%\n",
      "  Validation Loss: 0.1311, Validation Pixel Accuracy: 95.23%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 136/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.63it/s, loss=0.2106]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.25it/s, loss=0.1436]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 136 Summary:\n",
      "  Train Loss: 0.1365, Train Pixel Accuracy: 94.62%\n",
      "  Validation Loss: 0.1309, Validation Pixel Accuracy: 95.24%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 137/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.50it/s, loss=0.0582]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.42it/s, loss=0.1442]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 137 Summary:\n",
      "  Train Loss: 0.1354, Train Pixel Accuracy: 94.68%\n",
      "  Validation Loss: 0.1313, Validation Pixel Accuracy: 95.23%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 138/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.58it/s, loss=0.1155]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.11it/s, loss=0.1447]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 138 Summary:\n",
      "  Train Loss: 0.1351, Train Pixel Accuracy: 94.72%\n",
      "  Validation Loss: 0.1312, Validation Pixel Accuracy: 95.23%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 139/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.58it/s, loss=0.0995]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.19it/s, loss=0.1447]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 139 Summary:\n",
      "  Train Loss: 0.1344, Train Pixel Accuracy: 94.74%\n",
      "  Validation Loss: 0.1313, Validation Pixel Accuracy: 95.23%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 140/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.51it/s, loss=0.0973]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.42it/s, loss=0.1453]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 140 Summary:\n",
      "  Train Loss: 0.1368, Train Pixel Accuracy: 94.63%\n",
      "  Validation Loss: 0.1315, Validation Pixel Accuracy: 95.22%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 141/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.46it/s, loss=0.2204]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.18it/s, loss=0.1439]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 141 Summary:\n",
      "  Train Loss: 0.1359, Train Pixel Accuracy: 94.66%\n",
      "  Validation Loss: 0.1310, Validation Pixel Accuracy: 95.24%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 142/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.50it/s, loss=0.1438]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.07it/s, loss=0.1426]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 142 Summary:\n",
      "  Train Loss: 0.1352, Train Pixel Accuracy: 94.68%\n",
      "  Validation Loss: 0.1308, Validation Pixel Accuracy: 95.24%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 143/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.48it/s, loss=0.1205]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.16it/s, loss=0.1431]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 143 Summary:\n",
      "  Train Loss: 0.1361, Train Pixel Accuracy: 94.58%\n",
      "  Validation Loss: 0.1312, Validation Pixel Accuracy: 95.23%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 144/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.47it/s, loss=0.1631]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.12it/s, loss=0.1421]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 144 Summary:\n",
      "  Train Loss: 0.1352, Train Pixel Accuracy: 94.69%\n",
      "  Validation Loss: 0.1307, Validation Pixel Accuracy: 95.25%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 145/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.49it/s, loss=0.1457]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.09it/s, loss=0.1436]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 145 Summary:\n",
      "  Train Loss: 0.1348, Train Pixel Accuracy: 94.69%\n",
      "  Validation Loss: 0.1310, Validation Pixel Accuracy: 95.24%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 146/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.53it/s, loss=0.1406]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 14.89it/s, loss=0.1454]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 146 Summary:\n",
      "  Train Loss: 0.1345, Train Pixel Accuracy: 94.75%\n",
      "  Validation Loss: 0.1314, Validation Pixel Accuracy: 95.22%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 147/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.52it/s, loss=0.1155]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.20it/s, loss=0.1441]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 147 Summary:\n",
      "  Train Loss: 0.1362, Train Pixel Accuracy: 94.62%\n",
      "  Validation Loss: 0.1310, Validation Pixel Accuracy: 95.24%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 148/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.51it/s, loss=0.2042]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.15it/s, loss=0.1452]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 148 Summary:\n",
      "  Train Loss: 0.1393, Train Pixel Accuracy: 94.56%\n",
      "  Validation Loss: 0.1315, Validation Pixel Accuracy: 95.22%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 149/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.50it/s, loss=0.1216]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.07it/s, loss=0.1443]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 149 Summary:\n",
      "  Train Loss: 0.1360, Train Pixel Accuracy: 94.72%\n",
      "  Validation Loss: 0.1312, Validation Pixel Accuracy: 95.23%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 150/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.54it/s, loss=0.2301]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.18it/s, loss=0.1452]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 150 Summary:\n",
      "  Train Loss: 0.1355, Train Pixel Accuracy: 94.70%\n",
      "  Validation Loss: 0.1316, Validation Pixel Accuracy: 95.22%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 151/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.48it/s, loss=0.1578]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.09it/s, loss=0.1443]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 151 Summary:\n",
      "  Train Loss: 0.1381, Train Pixel Accuracy: 94.54%\n",
      "  Validation Loss: 0.1313, Validation Pixel Accuracy: 95.23%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 152/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.47it/s, loss=0.1289]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.09it/s, loss=0.1427]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 152 Summary:\n",
      "  Train Loss: 0.1382, Train Pixel Accuracy: 94.60%\n",
      "  Validation Loss: 0.1309, Validation Pixel Accuracy: 95.24%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 153/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.52it/s, loss=0.1137]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 14.92it/s, loss=0.1437]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 153 Summary:\n",
      "  Train Loss: 0.1380, Train Pixel Accuracy: 94.57%\n",
      "  Validation Loss: 0.1313, Validation Pixel Accuracy: 95.23%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 154/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.48it/s, loss=0.1064]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.04it/s, loss=0.1429]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 154 Summary:\n",
      "  Train Loss: 0.1369, Train Pixel Accuracy: 94.64%\n",
      "  Validation Loss: 0.1310, Validation Pixel Accuracy: 95.24%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 155/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.45it/s, loss=0.1160]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.23it/s, loss=0.1431]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 155 Summary:\n",
      "  Train Loss: 0.1363, Train Pixel Accuracy: 94.66%\n",
      "  Validation Loss: 0.1311, Validation Pixel Accuracy: 95.23%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 156/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.51it/s, loss=0.1501]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.04it/s, loss=0.1418]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 156 Summary:\n",
      "  Train Loss: 0.1348, Train Pixel Accuracy: 94.70%\n",
      "  Validation Loss: 0.1310, Validation Pixel Accuracy: 95.24%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 157/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.49it/s, loss=0.0801]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 14.90it/s, loss=0.1422]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 157 Summary:\n",
      "  Train Loss: 0.1382, Train Pixel Accuracy: 94.56%\n",
      "  Validation Loss: 0.1309, Validation Pixel Accuracy: 95.24%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 158/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.46it/s, loss=0.1077]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.06it/s, loss=0.1433]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 158 Summary:\n",
      "  Train Loss: 0.1359, Train Pixel Accuracy: 94.63%\n",
      "  Validation Loss: 0.1310, Validation Pixel Accuracy: 95.23%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 159/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.52it/s, loss=0.0948]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.10it/s, loss=0.1441]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 159 Summary:\n",
      "  Train Loss: 0.1362, Train Pixel Accuracy: 94.66%\n",
      "  Validation Loss: 0.1313, Validation Pixel Accuracy: 95.22%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 160/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.49it/s, loss=0.0829]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 14.95it/s, loss=0.1435]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 160 Summary:\n",
      "  Train Loss: 0.1359, Train Pixel Accuracy: 94.62%\n",
      "  Validation Loss: 0.1310, Validation Pixel Accuracy: 95.23%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 161/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.54it/s, loss=0.0665]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.08it/s, loss=0.1429]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 161 Summary:\n",
      "  Train Loss: 0.1371, Train Pixel Accuracy: 94.58%\n",
      "  Validation Loss: 0.1309, Validation Pixel Accuracy: 95.24%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 162/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.51it/s, loss=0.1621]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.36it/s, loss=0.1444]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 162 Summary:\n",
      "  Train Loss: 0.1381, Train Pixel Accuracy: 94.60%\n",
      "  Validation Loss: 0.1311, Validation Pixel Accuracy: 95.23%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 163/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.55it/s, loss=0.1280]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.22it/s, loss=0.1431]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 163 Summary:\n",
      "  Train Loss: 0.1342, Train Pixel Accuracy: 94.70%\n",
      "  Validation Loss: 0.1308, Validation Pixel Accuracy: 95.25%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 164/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.54it/s, loss=0.1095]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.12it/s, loss=0.1446]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 164 Summary:\n",
      "  Train Loss: 0.1350, Train Pixel Accuracy: 94.68%\n",
      "  Validation Loss: 0.1312, Validation Pixel Accuracy: 95.23%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 165/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.57it/s, loss=0.0976]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 14.92it/s, loss=0.1454]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 165 Summary:\n",
      "  Train Loss: 0.1355, Train Pixel Accuracy: 94.68%\n",
      "  Validation Loss: 0.1314, Validation Pixel Accuracy: 95.22%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 166/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.52it/s, loss=0.1088]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.39it/s, loss=0.1447]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 166 Summary:\n",
      "  Train Loss: 0.1367, Train Pixel Accuracy: 94.65%\n",
      "  Validation Loss: 0.1311, Validation Pixel Accuracy: 95.23%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 167/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.55it/s, loss=0.0854]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.37it/s, loss=0.1436]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 167 Summary:\n",
      "  Train Loss: 0.1335, Train Pixel Accuracy: 94.76%\n",
      "  Validation Loss: 0.1310, Validation Pixel Accuracy: 95.24%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 168/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.53it/s, loss=0.0530]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.14it/s, loss=0.1432]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 168 Summary:\n",
      "  Train Loss: 0.1349, Train Pixel Accuracy: 94.74%\n",
      "  Validation Loss: 0.1309, Validation Pixel Accuracy: 95.24%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 169/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.55it/s, loss=0.0921]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.10it/s, loss=0.1437]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 169 Summary:\n",
      "  Train Loss: 0.1357, Train Pixel Accuracy: 94.68%\n",
      "  Validation Loss: 0.1309, Validation Pixel Accuracy: 95.24%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 170/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.51it/s, loss=0.1145]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.35it/s, loss=0.1427]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 170 Summary:\n",
      "  Train Loss: 0.1336, Train Pixel Accuracy: 94.76%\n",
      "  Validation Loss: 0.1307, Validation Pixel Accuracy: 95.25%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 171/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.52it/s, loss=0.1179]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 14.97it/s, loss=0.1426]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 171 Summary:\n",
      "  Train Loss: 0.1361, Train Pixel Accuracy: 94.65%\n",
      "  Validation Loss: 0.1308, Validation Pixel Accuracy: 95.25%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 172/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.50it/s, loss=0.1753]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 14.91it/s, loss=0.1440]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 172 Summary:\n",
      "  Train Loss: 0.1359, Train Pixel Accuracy: 94.74%\n",
      "  Validation Loss: 0.1311, Validation Pixel Accuracy: 95.23%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 173/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.52it/s, loss=0.2792]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.11it/s, loss=0.1429]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 173 Summary:\n",
      "  Train Loss: 0.1344, Train Pixel Accuracy: 94.76%\n",
      "  Validation Loss: 0.1309, Validation Pixel Accuracy: 95.24%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 174/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.49it/s, loss=0.0768]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.10it/s, loss=0.1429]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 174 Summary:\n",
      "  Train Loss: 0.1356, Train Pixel Accuracy: 94.68%\n",
      "  Validation Loss: 0.1308, Validation Pixel Accuracy: 95.25%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 175/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.47it/s, loss=0.1124]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.04it/s, loss=0.1425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 175 Summary:\n",
      "  Train Loss: 0.1358, Train Pixel Accuracy: 94.70%\n",
      "  Validation Loss: 0.1307, Validation Pixel Accuracy: 95.25%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 176/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.49it/s, loss=0.1243]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 14.99it/s, loss=0.1449]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 176 Summary:\n",
      "  Train Loss: 0.1377, Train Pixel Accuracy: 94.61%\n",
      "  Validation Loss: 0.1313, Validation Pixel Accuracy: 95.23%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 177/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.51it/s, loss=0.0950]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:31<00:00, 14.76it/s, loss=0.1441]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 177 Summary:\n",
      "  Train Loss: 0.1351, Train Pixel Accuracy: 94.70%\n",
      "  Validation Loss: 0.1311, Validation Pixel Accuracy: 95.23%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 178/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.47it/s, loss=0.1184]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.10it/s, loss=0.1444]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 178 Summary:\n",
      "  Train Loss: 0.1342, Train Pixel Accuracy: 94.72%\n",
      "  Validation Loss: 0.1312, Validation Pixel Accuracy: 95.23%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 179/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.46it/s, loss=0.1741]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.21it/s, loss=0.1437]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 179 Summary:\n",
      "  Train Loss: 0.1353, Train Pixel Accuracy: 94.72%\n",
      "  Validation Loss: 0.1308, Validation Pixel Accuracy: 95.25%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 180/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.46it/s, loss=0.0682]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 14.99it/s, loss=0.1439]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 180 Summary:\n",
      "  Train Loss: 0.1357, Train Pixel Accuracy: 94.70%\n",
      "  Validation Loss: 0.1311, Validation Pixel Accuracy: 95.24%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 181/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.50it/s, loss=0.1447]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.08it/s, loss=0.1425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 181 Summary:\n",
      "  Train Loss: 0.1376, Train Pixel Accuracy: 94.62%\n",
      "  Validation Loss: 0.1307, Validation Pixel Accuracy: 95.25%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 182/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.45it/s, loss=0.2155]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.09it/s, loss=0.1433]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 182 Summary:\n",
      "  Train Loss: 0.1363, Train Pixel Accuracy: 94.65%\n",
      "  Validation Loss: 0.1311, Validation Pixel Accuracy: 95.23%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 183/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.51it/s, loss=0.1494]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.05it/s, loss=0.1428]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 183 Summary:\n",
      "  Train Loss: 0.1369, Train Pixel Accuracy: 94.58%\n",
      "  Validation Loss: 0.1310, Validation Pixel Accuracy: 95.24%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 184/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.44it/s, loss=0.1681]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.18it/s, loss=0.1445]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 184 Summary:\n",
      "  Train Loss: 0.1365, Train Pixel Accuracy: 94.64%\n",
      "  Validation Loss: 0.1314, Validation Pixel Accuracy: 95.22%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 185/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.47it/s, loss=0.1047]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.17it/s, loss=0.1426]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 185 Summary:\n",
      "  Train Loss: 0.1374, Train Pixel Accuracy: 94.61%\n",
      "  Validation Loss: 0.1309, Validation Pixel Accuracy: 95.24%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 186/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.53it/s, loss=0.1199]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 14.92it/s, loss=0.1429]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 186 Summary:\n",
      "  Train Loss: 0.1347, Train Pixel Accuracy: 94.71%\n",
      "  Validation Loss: 0.1311, Validation Pixel Accuracy: 95.23%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 187/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.49it/s, loss=0.0976]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.14it/s, loss=0.1422]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 187 Summary:\n",
      "  Train Loss: 0.1348, Train Pixel Accuracy: 94.75%\n",
      "  Validation Loss: 0.1308, Validation Pixel Accuracy: 95.24%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 188/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.45it/s, loss=0.1729]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.10it/s, loss=0.1433]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 188 Summary:\n",
      "  Train Loss: 0.1356, Train Pixel Accuracy: 94.64%\n",
      "  Validation Loss: 0.1311, Validation Pixel Accuracy: 95.23%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 189/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.52it/s, loss=0.1330]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.18it/s, loss=0.1419]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 189 Summary:\n",
      "  Train Loss: 0.1343, Train Pixel Accuracy: 94.69%\n",
      "  Validation Loss: 0.1306, Validation Pixel Accuracy: 95.25%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 190/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.53it/s, loss=0.1552]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.17it/s, loss=0.1425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 190 Summary:\n",
      "  Train Loss: 0.1350, Train Pixel Accuracy: 94.70%\n",
      "  Validation Loss: 0.1309, Validation Pixel Accuracy: 95.24%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 191/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.49it/s, loss=0.2067]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.14it/s, loss=0.1437]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 191 Summary:\n",
      "  Train Loss: 0.1348, Train Pixel Accuracy: 94.69%\n",
      "  Validation Loss: 0.1311, Validation Pixel Accuracy: 95.24%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 192/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.55it/s, loss=0.3742]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.02it/s, loss=0.1431]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 192 Summary:\n",
      "  Train Loss: 0.1383, Train Pixel Accuracy: 94.58%\n",
      "  Validation Loss: 0.1308, Validation Pixel Accuracy: 95.24%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 193/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.61it/s, loss=0.1808]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.41it/s, loss=0.1434]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 193 Summary:\n",
      "  Train Loss: 0.1332, Train Pixel Accuracy: 94.80%\n",
      "  Validation Loss: 0.1310, Validation Pixel Accuracy: 95.24%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 194/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.50it/s, loss=0.1130]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.25it/s, loss=0.1424]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 194 Summary:\n",
      "  Train Loss: 0.1344, Train Pixel Accuracy: 94.72%\n",
      "  Validation Loss: 0.1308, Validation Pixel Accuracy: 95.25%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 195/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.58it/s, loss=0.1777]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.29it/s, loss=0.1420]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 195 Summary:\n",
      "  Train Loss: 0.1373, Train Pixel Accuracy: 94.60%\n",
      "  Validation Loss: 0.1307, Validation Pixel Accuracy: 95.25%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 196/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.58it/s, loss=0.1073]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.26it/s, loss=0.1433]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 196 Summary:\n",
      "  Train Loss: 0.1364, Train Pixel Accuracy: 94.64%\n",
      "  Validation Loss: 0.1310, Validation Pixel Accuracy: 95.23%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 197/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.53it/s, loss=0.1324]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.32it/s, loss=0.1423]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 197 Summary:\n",
      "  Train Loss: 0.1371, Train Pixel Accuracy: 94.61%\n",
      "  Validation Loss: 0.1306, Validation Pixel Accuracy: 95.25%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 198/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.63it/s, loss=0.2411]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.13it/s, loss=0.1413]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 198 Summary:\n",
      "  Train Loss: 0.1358, Train Pixel Accuracy: 94.68%\n",
      "  Validation Loss: 0.1304, Validation Pixel Accuracy: 95.26%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 199/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:00<00:00,  7.60it/s, loss=0.0731]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:29<00:00, 15.38it/s, loss=0.1428]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 199 Summary:\n",
      "  Train Loss: 0.1361, Train Pixel Accuracy: 94.63%\n",
      "  Validation Loss: 0.1306, Validation Pixel Accuracy: 95.25%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "--- Epoch 200/200 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|\u001b[32m██████████\u001b[0m| 460/460 [01:01<00:00,  7.52it/s, loss=0.2476]\n",
      "Validation: 100%|\u001b[31m██████████\u001b[0m| 459/459 [00:30<00:00, 15.27it/s, loss=0.1425]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 200 Summary:\n",
      "  Train Loss: 0.1352, Train Pixel Accuracy: 94.69%\n",
      "  Validation Loss: 0.1306, Validation Pixel Accuracy: 95.25%\n",
      "  Current learning rate: 0.000001\n",
      "------------------------------\n",
      "Finished Training\n",
      "Best model saved at /kaggle/working/fcn_pet_best.pth with validation loss: 0.1280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# --- 1. 初始化 ---\n",
    "epochs = 200\n",
    "writer = SummaryWriter(\"/kaggle/working/logs/pet\")\n",
    "best_val_loss = float('inf') # 用于保存最佳模型的变量\n",
    "MODEL_SAVE_PATH = '/kaggle/working/fcn_pet_best.pth'\n",
    "\n",
    "print('Starting Training...')\n",
    "# --- 2. 主训练循环 ---\n",
    "for epoch in range(epochs): \n",
    "    print(f\"--- Epoch {epoch + 1}/{epochs} ---\")\n",
    "    \n",
    "    # --- 训练阶段 ---\n",
    "    net.train() # 对于包含 Dropout 层或 Batch Normalization 层的模型需要调用 model.train() 和 model.eval() \n",
    "    train_loss = 0.0\n",
    "    train_correct_pixels = 0\n",
    "    train_total_pixels = 0\n",
    "    \n",
    "    # 使用tqdm包装训练数据加载器\n",
    "    train_progress_bar = tqdm(train_loader, desc=\"Training\", colour=\"green\")\n",
    "    \n",
    "    for inputs, masks in train_progress_bar:\n",
    "        inputs = inputs.to(device)\n",
    "        masks  = masks.to(device, dtype=torch.long) # 确保掩码是长整型张量，因为 CrossEntropyLoss 需要标签是整数类型\n",
    "        # 清除梯度->向前传播->计算损失->反向传播->优化参数\n",
    "        optimizer.zero_grad() # zero_grad() 必须在 loss.backward()前. 在当前训练批次开始时，首先清零所有参数的梯度。\n",
    "        outputs = net(inputs)\n",
    "        loss = loss_function(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "         # 累积损失\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # 计算像素准确率\n",
    "        with torch.no_grad():\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            # 只计算非忽略区域的像素\n",
    "            valid_pixels = (masks != 255)\n",
    "            train_correct_pixels += ((preds == masks) & valid_pixels).sum().item()\n",
    "            train_total_pixels += valid_pixels.sum().item()\n",
    "        \n",
    "        # 使用 set_postfix 在进度条上动态显示当前批次的损失\n",
    "        train_progress_bar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "    # --- 验证阶段 ---\n",
    "    net.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct_pixels = 0\n",
    "    val_total_pixels = 0\n",
    "\n",
    "    # 使用tqdm包装验证数据加载器\n",
    "    val_progress_bar = tqdm(val_loader, desc=\"Validation\", colour=\"red\")\n",
    "    \n",
    "    with torch.no_grad(): # 测试过程中不计算梯度\n",
    "        for inputs, masks in val_progress_bar:\n",
    "            inputs = inputs.to(device)\n",
    "            masks = masks.to(device, dtype=torch.long)\n",
    "            outputs = net(inputs)\n",
    "            loss = loss_function(outputs, masks)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            valid_pixels = (masks != 255)\n",
    "            val_correct_pixels += ((preds == masks) & valid_pixels).sum().item()\n",
    "            val_total_pixels += valid_pixels.sum().item()\n",
    "\n",
    "            val_progress_bar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "\n",
    "    # --- 3. 计算并记录每个Epoch的指标 ---\n",
    "    # 计算平均损失和准确率\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    train_pixel_acc = (train_correct_pixels / train_total_pixels) * 100 if train_total_pixels > 0 else 0\n",
    "    \n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_pixel_acc = (val_correct_pixels / val_total_pixels) * 100 if val_total_pixels > 0 else 0\n",
    "    # 打印本轮的最终结果\n",
    "    print(f\"\\nEpoch {epoch + 1} Summary:\")\n",
    "    print(f\"  Train Loss: {avg_train_loss:.4f}, Train Pixel Accuracy: {train_pixel_acc:.2f}%\")\n",
    "    print(f\"  Validation Loss: {avg_val_loss:.4f}, Validation Pixel Accuracy: {val_pixel_acc:.2f}%\")\n",
    "    # 记录到TensorBoard\n",
    "    writer.add_scalar('Loss/train', avg_train_loss, epoch)\n",
    "    writer.add_scalar('Accuracy/train', train_pixel_acc, epoch)\n",
    "    writer.add_scalar('Loss/validation', avg_val_loss, epoch)\n",
    "    writer.add_scalar('Accuracy/validation', val_pixel_acc, epoch)\n",
    "    writer.add_scalar('Learning_Rate', optimizer.param_groups[0]['lr'], epoch)\n",
    "    \n",
    "    # 更新学习率，并将验证集损失传入\n",
    "    scheduler.step(avg_val_loss)\n",
    "    print(f\"  Current learning rate: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "\n",
    "    # --- 4. 保存最佳模型 ---\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(net.state_dict(), MODEL_SAVE_PATH)\n",
    "        print(f\"  ---> New best model saved to {MODEL_SAVE_PATH} (Validation Loss: {best_val_loss:.4f})\")\n",
    "    \n",
    "    print(\"-\" * 30)\n",
    "\n",
    "print('Finished Training')\n",
    "print(f\"Best model saved at {MODEL_SAVE_PATH} with validation loss: {best_val_loss:.4f}\")\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce815b53",
   "metadata": {
    "papermill": {
     "duration": 14.035489,
     "end_time": "2025-07-22T13:12:42.481336",
     "exception": false,
     "start_time": "2025-07-22T13:12:28.445847",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9e7ff52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T13:13:10.677378Z",
     "iopub.status.busy": "2025-07-22T13:13:10.676717Z",
     "iopub.status.idle": "2025-07-22T13:13:16.509411Z",
     "shell.execute_reply": "2025-07-22T13:13:16.508562Z"
    },
    "papermill": {
     "duration": 20.099764,
     "end_time": "2025-07-22T13:13:16.510550",
     "exception": false,
     "start_time": "2025-07-22T13:12:56.410786",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型加载成功！\n",
      "开始在 'test' 集上进行预测和可视化...\n",
      "已保存可视化结果: /kaggle/working/outputs/results/Abyssinian_201_pred.png\n",
      "已保存可视化结果: /kaggle/working/outputs/results/Abyssinian_202_pred.png\n",
      "已保存可视化结果: /kaggle/working/outputs/results/Abyssinian_204_pred.png\n",
      "已保存可视化结果: /kaggle/working/outputs/results/Abyssinian_205_pred.png\n",
      "已保存可视化结果: /kaggle/working/outputs/results/Abyssinian_206_pred.png\n",
      "已保存可视化结果: /kaggle/working/outputs/results/Abyssinian_207_pred.png\n",
      "已保存可视化结果: /kaggle/working/outputs/results/Abyssinian_20_pred.png\n",
      "已保存可视化结果: /kaggle/working/outputs/results/Abyssinian_210_pred.png\n",
      "已保存可视化结果: /kaggle/working/outputs/results/Abyssinian_212_pred.png\n",
      "已保存可视化结果: /kaggle/working/outputs/results/Abyssinian_213_pred.png\n",
      "\n",
      "可视化完成！结果已保存在 '/kaggle/working/outputs/results/' 文件夹中。\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "MODEL_PATH = '/kaggle/working/fcn_pet_best.pth' # 你训练好的模型路径\n",
    "OUTPUT_DIR = '/kaggle/working/outputs/results/'\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "IMAGE_SIZE = (256, 256)\n",
    "NUM_VISUALIZATIONS = 10\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# --- 1. 颜色映射---\n",
    "PET_COLORMAP = np.array([\n",
    "    [0, 0, 0],       # 类别 0: 背景 (黑色)\n",
    "    [128, 0, 0],     # 类别 1: 宠物 (红色)\n",
    "], dtype=np.uint8)\n",
    "\n",
    "def mask_to_color(mask, colormap):\n",
    "    # 创建一个三通道的彩色掩码\n",
    "    color_mask = np.zeros((mask.shape[0], mask.shape[1], 3), dtype=np.uint8)\n",
    "    # 遍历颜色映射表中的每一种颜色\n",
    "    for class_idx, color in enumerate(colormap):\n",
    "        # 将掩码中所有等于当前类别索引的像素，都赋值为对应的颜色\n",
    "        color_mask[mask == class_idx] = color\n",
    "    return color_mask\n",
    "\n",
    "\n",
    "\n",
    "# 定义数据变换\n",
    "val_augs = A.Compose([\n",
    "    A.Resize(width=IMAGE_SIZE[0], height=IMAGE_SIZE[1]),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2()\n",
    "])\n",
    "# 加载模型\n",
    "model = FCN(num_classes=NUM_CLASSES).to(device)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "model.eval()\n",
    "print(\"模型加载成功！\")\n",
    "# --- 5. 关键变更：准备数据集的方式 ---\n",
    "# 我们需要两个数据集实例：\n",
    "# a) 一个应用了变换，用于输入模型\n",
    "test_dataset_transformed = PetDatasetWrapper(root=DATA_ROOT, split='test', augmentations=val_augs, download=False)\n",
    "# b) 一个不应用任何变换，用于获取原始图像和ID\n",
    "test_dataset_original = torchvision.datasets.OxfordIIITPet(root=DATA_ROOT, split='test', download=False)\n",
    "print(f\"开始在 'test' 集上进行预测和可视化...\")\n",
    "with torch.no_grad():\n",
    "    for i in range(min(NUM_VISUALIZATIONS, len(test_dataset_transformed))):\n",
    "        # --- 6. 关键变更：获取数据的方式 ---\n",
    "        \n",
    "        # a) 从转换后的数据集中获取模型输入和真值掩码\n",
    "        image_tensor, gt_mask = test_dataset_transformed[i]\n",
    "        \n",
    "        # b) 从原始数据集中获取原始图像和文件名ID\n",
    "        original_image, _ = test_dataset_original[i] # 这是原始的PIL Image\n",
    "        # torchvision.datasets.OxfordIIITPet 的文件名存储在 _images 属性中\n",
    "        image_id = os.path.splitext(os.path.basename(test_dataset_original._images[i]))[0]\n",
    "        # -------------------------------------------------\n",
    "        \n",
    "        # 模型需要一个batch维度，所以我们用unsqueeze(0)增加一个维度\n",
    "        image_tensor = image_tensor.unsqueeze(0).to(device)\n",
    "        \n",
    "        # 模型预测\n",
    "        output = model(image_tensor)\n",
    "        pred_mask = torch.argmax(output, dim=1)\n",
    "        \n",
    "        # 转为Numpy\n",
    "        pred_mask_np = pred_mask.cpu().squeeze(0).numpy()\n",
    "        gt_mask_np = gt_mask.cpu().numpy() # gt_mask 已经是tensor了，直接转numpy\n",
    "        \n",
    "        # 将忽略区域(255)处理一下，方便可视化，统一设为背景类别0\n",
    "        gt_mask_np[gt_mask_np == 255] = 0 \n",
    "        \n",
    "        # --- 7. 关键变更：使用新的颜色映射表 ---\n",
    "        pred_mask_color = mask_to_color(pred_mask_np, PET_COLORMAP)\n",
    "        gt_mask_color = mask_to_color(gt_mask_np, PET_COLORMAP)\n",
    "        \n",
    "        # 绘图\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "        \n",
    "        # 显示原始图像 (需要resize以匹配输出尺寸)\n",
    "        axes[0].imshow(original_image.resize(IMAGE_SIZE))\n",
    "        axes[0].set_title(f'Original Image: {image_id}')\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        axes[1].imshow(gt_mask_color)\n",
    "        axes[1].set_title('Ground Truth Mask')\n",
    "        axes[1].axis('off')\n",
    "        \n",
    "        axes[2].imshow(pred_mask_color)\n",
    "        axes[2].set_title('Predicted Mask')\n",
    "        axes[2].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        save_path = os.path.join(OUTPUT_DIR, f'{image_id}_pred.png')\n",
    "        plt.savefig(save_path)\n",
    "        plt.close(fig) # 关闭图形，防止在Jupyter中重复显示\n",
    "        print(f\"已保存可视化结果: {save_path}\")\n",
    "print(f\"\\n可视化完成！结果已保存在 '{OUTPUT_DIR}' 文件夹中。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9952a8ce",
   "metadata": {
    "papermill": {
     "duration": 14.01224,
     "end_time": "2025-07-22T13:13:44.307690",
     "exception": false,
     "start_time": "2025-07-22T13:13:30.295450",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4bda8c",
   "metadata": {
    "papermill": {
     "duration": 14.207731,
     "end_time": "2025-07-22T13:14:12.209157",
     "exception": false,
     "start_time": "2025-07-22T13:13:58.001426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714fe91c",
   "metadata": {
    "papermill": {
     "duration": 14.362157,
     "end_time": "2025-07-22T13:14:40.370806",
     "exception": false,
     "start_time": "2025-07-22T13:14:26.008649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e0f612",
   "metadata": {
    "papermill": {
     "duration": 13.774058,
     "end_time": "2025-07-22T13:15:07.967868",
     "exception": false,
     "start_time": "2025-07-22T13:14:54.193810",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 35388,
     "sourceId": 47853,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7917073,
     "sourceId": 12540530,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 18363.054468,
   "end_time": "2025-07-22T13:15:24.620780",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-22T08:09:21.566312",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
