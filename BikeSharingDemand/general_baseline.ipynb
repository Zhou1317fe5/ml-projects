{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import interp\n",
    "from math import isnan\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_curve, auc, f1_score\n",
    "from sklearn.externals import joblib\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gbdt_feature_selection(fe_name, matrix_x_temp, label_y, th):\n",
    "    \"\"\"\n",
    "    使用GBDT(梯度提升决策树)进行特征选择\n",
    "    \n",
    "    参数:\n",
    "    - fe_name: 特征名称列表\n",
    "    - matrix_x_temp: 特征矩阵\n",
    "    - label_y: 标签数据\n",
    "    - th: 特征重要性阈值\n",
    "    \"\"\"\n",
    "    \n",
    "    # 第一部分：模型训练和特征选择\n",
    "    clf = GradientBoostingClassifier(n_estimators=50, random_state=100)  # 创建GBDT分类器\n",
    "    clf.fit(matrix_x_temp, label_y)  # 训练模型\n",
    "    # 使用SelectFromModel进行特征选择，只保留重要性大于阈值的特征\n",
    "    sfm = SelectFromModel(clf, prefit=True, threshold=th)  \n",
    "    matrix_x = sfm.transform(matrix_x_temp)  # 转换特征矩阵，只保留选中的特征\n",
    "\n",
    "    # 第二部分：统计非零特征数量\n",
    "    feature_score_dict = {}\n",
    "    # 将特征名称和对应的重要性分数组合成字典\n",
    "    for fn, s in zip(fe_name, clf.feature_importances_):\n",
    "        feature_score_dict[fn] = s\n",
    "    # 计算重要性为0的特征数量\n",
    "    m = 0\n",
    "    for k in feature_score_dict:\n",
    "        if feature_score_dict[k] == 0.0:\n",
    "            m += 1\n",
    "    print('number of not-zero features:' + str(len(feature_score_dict) - m))\n",
    "\n",
    "    # 第三部分：特征重要性排序和输出\n",
    "    # 按重要性降序排序\n",
    "    feature_score_dict_sorted = sorted(feature_score_dict.items(),\n",
    "                                     key=lambda d: d[1], reverse=True)\n",
    "    # 打印特征重要性\n",
    "    print('feature_importance:')\n",
    "    for ii in range(len(feature_score_dict_sorted)):\n",
    "        print(feature_score_dict_sorted[ii][0], feature_score_dict_sorted[ii][1])\n",
    "    \n",
    "    # 将特征重要性保存到文件\n",
    "    f = open('../eda/gbdt_feature_importance.txt', 'w')\n",
    "    f.write('Rank\\tFeature Name\\tFeature Importance\\n')\n",
    "    for i in range(len(feature_score_dict_sorted)):\n",
    "        f.write(str(i) + '\\t' + str(feature_score_dict_sorted[i][0]) + '\\t' + \n",
    "                str(feature_score_dict_sorted[i][1]) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "    # 第四部分：获取选中的特征\n",
    "    how_long = matrix_x.shape[1]  # 获取转换后的特征数量\n",
    "    # 获取重要性最高的前how_long个特征\n",
    "    feature_used_dict_temp = feature_score_dict_sorted[:how_long]\n",
    "    feature_used_name = []\n",
    "    for ii in range(len(feature_used_dict_temp)):\n",
    "        feature_used_name.append(feature_used_dict_temp[ii][0])\n",
    "    \n",
    "    # 打印选中的特征\n",
    "    print('feature_chooesed:')\n",
    "    for ii in range(len(feature_used_name)):\n",
    "        print(feature_used_name[ii])\n",
    "    \n",
    "    # 将选中的特征保存到文件\n",
    "    f = open('../eda/gbdt_feature_chose.txt', 'w')\n",
    "    f.write('Feature Chose Name :\\n')\n",
    "    for i in range(len(feature_used_name)):\n",
    "        f.write(str(feature_used_name[i]) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "    # 第五部分：获取未被选中的特征\n",
    "    feature_not_used_name = []\n",
    "    for i in range(len(fe_name)):\n",
    "        if fe_name[i] not in feature_used_name:\n",
    "            feature_not_used_name.append(fe_name[i])\n",
    "\n",
    "    # 返回：转换后的特征矩阵、未使用的特征名称列表、选中的特征数量\n",
    "    return matrix_x, feature_not_used_name, len(feature_used_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `gbdt_feature_selection` 函数详解\n",
    "\n",
    "此函数 `gbdt_feature_selection`  使用梯度提升决策树（GBDT）模型进行特征选择，并返回选中的特征、未选中的特征以及其他相关信息。该函数的主要步骤包括：模型训练和特征选择、统计非零特征数量、特征重要性排序和输出、获取选中的特征以及获取未被选中的特征。\n",
    "\n",
    "### 函数定义\n",
    "\n",
    "```python\n",
    "def gbdt_feature_selection(fe_name, matrix_x_temp, label_y, th):\n",
    "    # 函数体\n",
    "```\n",
    "\n",
    "*   **输入参数：**\n",
    "    *   `fe_name`: 特征名称的列表。\n",
    "    *   `matrix_x_temp`: 原始特征矩阵，是训练模型的输入。\n",
    "    *   `label_y`: 目标变量，是监督学习模型的训练标签。\n",
    "    *   `th`: 特征选择的阈值。\n",
    "*   **返回值：**\n",
    "    *   `matrix_x`: 经过特征选择后的特征矩阵。\n",
    "    *   `feature_not_used_name`: 未被选中的特征名称列表。\n",
    "    *  `len(feature_used_name)`: 选中的特征的数量。\n",
    "\n",
    "### 第一部分：模型训练和特征选择\n",
    "\n",
    "使用 GBDT 模型进行特征选择，并根据重要性阈值筛选特征。\n",
    "\n",
    "1.  **创建 GBDT 分类器：**\n",
    "    ```python\n",
    "    clf = GradientBoostingClassifier(n_estimators=50, random_state=100)\n",
    "    ```\n",
    "    *   使用 `GradientBoostingClassifier` 创建一个 GBDT 分类器，设置 `n_estimators=50` 表示使用 50 个决策树，`random_state=100` 用于保证结果的可重复性。\n",
    "2.  **训练 GBDT 模型：**\n",
    "    ```python\n",
    "    clf.fit(matrix_x_temp, label_y)\n",
    "    ```\n",
    "    *   使用原始特征矩阵 `matrix_x_temp` 和目标变量 `label_y` 训练 GBDT 模型。\n",
    "3.  **使用 `SelectFromModel` 进行特征选择：**\n",
    "    ```python\n",
    "    sfm = SelectFromModel(clf, prefit=True, threshold=th)\n",
    "    matrix_x = sfm.transform(matrix_x_temp)\n",
    "    ```\n",
    "    *   使用 `SelectFromModel` 类，并传入已经训练好的 GBDT 模型 `clf` 和指定的阈值 `th`。`prefit=True` 表示模型已经训练好。`threshold` 参数用于指定特征重要性的阈值，只有重要性大于 `th` 的特征才会被保留。\n",
    "    *  `sfm.transform(matrix_x_temp)` 使用训练好的模型对特征矩阵进行转换，只保留重要性大于阈值的特征。\n",
    "    \n",
    "**目的:** 通过训练 GBDT 模型，并设置特征重要性阈值 `th`，来筛选出对模型有重要贡献的特征。\n",
    "\n",
    "### 第二部分：统计非零特征数量\n",
    "\n",
    "统计特征重要性不为零的特征数量。\n",
    "\n",
    "1.  **创建特征重要性字典：**\n",
    "    ```python\n",
    "     feature_score_dict = {}\n",
    "    for fn, s in zip(fe_name, clf.feature_importances_):\n",
    "        feature_score_dict[fn] = s\n",
    "    ```\n",
    "    *   将特征名称 `fe_name` 和对应的重要性分数 `clf.feature_importances_` 组合成一个字典 `feature_score_dict`。\n",
    "2.  **计算重要性为零的特征数量：**\n",
    "    ```python\n",
    "    m = 0\n",
    "    for k in feature_score_dict:\n",
    "        if feature_score_dict[k] == 0.0:\n",
    "            m += 1\n",
    "    print('number of not-zero features:' + str(len(feature_score_dict) - m))\n",
    "    ```\n",
    "    *   遍历特征重要性字典，计算重要性为零的特征数量 `m`，并打印非零特征的数量。\n",
    "\n",
    "**目的:** 统计有多少特征对模型训练有贡献。\n",
    "\n",
    "### 第三部分：特征重要性排序和输出\n",
    "\n",
    "将特征按照重要性排序，并将结果打印并保存到文件中。\n",
    "\n",
    "1.  **按重要性降序排序：**\n",
    "    ```python\n",
    "    feature_score_dict_sorted = sorted(feature_score_dict.items(),\n",
    "                                     key=lambda d: d[1], reverse=True)\n",
    "    ```\n",
    "    *   使用 `sorted` 函数对特征重要性字典进行排序，根据重要性分数降序排列。\n",
    "2.  **打印特征重要性：**\n",
    "    ```python\n",
    "    print('feature_importance:')\n",
    "    for ii in range(len(feature_score_dict_sorted)):\n",
    "        print(feature_score_dict_sorted[ii][0], feature_score_dict_sorted[ii][1])\n",
    "    ```\n",
    "    *   遍历排序后的特征列表，打印特征名称和对应的特征重要性。\n",
    "3.  **将特征重要性保存到文件：**\n",
    "    ```python\n",
    "    f = open('../eda/gbdt_feature_importance.txt', 'w')\n",
    "    f.write('Rank\\tFeature Name\\tFeature Importance\\n')\n",
    "    for i in range(len(feature_score_dict_sorted)):\n",
    "        f.write(str(i) + '\\t' + str(feature_score_dict_sorted[i][0]) + '\\t' + \n",
    "                str(feature_score_dict_sorted[i][1]) + '\\n')\n",
    "    f.close()\n",
    "    ```\n",
    "    *   将特征重要性排名写入到 `../eda/gbdt_feature_importance.txt` 文件中，包括排名、特征名称和特征重要性分数。\n",
    "\n",
    "**目的:** 输出特征的重要性排序，方便查看哪些特征对模型的贡献最大，并保存结果以便后续分析。\n",
    "\n",
    "### 第四部分：获取选中的特征\n",
    "\n",
    "获取经过特征选择后保留的特征。\n",
    "\n",
    "1.  **获取转换后的特征数量：**\n",
    "    ```python\n",
    "    how_long = matrix_x.shape[1]\n",
    "    ```\n",
    "    *   获取转换后特征矩阵 `matrix_x` 的列数，也就是保留的特征数量。\n",
    "2.  **获取重要性最高的前 `how_long` 个特征：**\n",
    "    ```python\n",
    "    feature_used_dict_temp = feature_score_dict_sorted[:how_long]\n",
    "    feature_used_name = []\n",
    "    for ii in range(len(feature_used_dict_temp)):\n",
    "        feature_used_name.append(feature_used_dict_temp[ii][0])\n",
    "    ```\n",
    "    *   从排序后的特征重要性列表中，取出前 `how_long` 个特征，并将特征名称存储到 `feature_used_name` 列表中。\n",
    "3.  **打印选中的特征：**\n",
    "    ```python\n",
    "    print('feature_chooesed:')\n",
    "    for ii in range(len(feature_used_name)):\n",
    "        print(feature_used_name[ii])\n",
    "    ```\n",
    "    *   打印选中的特征名称。\n",
    "4.  **将选中的特征保存到文件：**\n",
    "    ```python\n",
    "    f = open('../eda/gbdt_feature_chose.txt', 'w')\n",
    "    f.write('Feature Chose Name :\\n')\n",
    "    for i in range(len(feature_used_name)):\n",
    "        f.write(str(feature_used_name[i]) + '\\n')\n",
    "    f.close()\n",
    "    ```\n",
    "    *   将选中的特征名称写入到 `../eda/gbdt_feature_chose.txt` 文件中。\n",
    "\n",
    "**目的:**  获取经过 GBDT 模型选择后保留下来的特征，用于后续模型训练。\n",
    "\n",
    "### 第五部分：获取未被选中的特征\n",
    "\n",
    "获取被 GBDT 模型排除掉的特征。\n",
    "\n",
    "1.  **获取未被选中的特征名称：**\n",
    "    ```python\n",
    "    feature_not_used_name = []\n",
    "    for i in range(len(fe_name)):\n",
    "        if fe_name[i] not in feature_used_name:\n",
    "            feature_not_used_name.append(fe_name[i])\n",
    "    ```\n",
    "    *  遍历原始特征列表 `fe_name`，如果特征名称没有在选中的特征名称列表 `feature_used_name` 中，则将其添加到 `feature_not_used_name` 列表中。\n",
    "\n",
    "**目的:** 方便查看哪些特征在模型中被认为不重要。\n",
    "\n",
    "### 返回值\n",
    "\n",
    "```python\n",
    " return matrix_x, feature_not_used_name, len(feature_used_name)\n",
    "```\n",
    "\n",
    "*   函数返回经过特征选择后的特征矩阵 `matrix_x`，未被选中的特征名称列表 `feature_not_used_name`，以及选中的特征数量 `len(feature_used_name)`。\n",
    "\n",
    "**总结:**\n",
    "\n",
    "`gbdt_feature_selection`  函数使用 GBDT 模型进行特征选择，并返回选择后的特征矩阵和未使用的特征名称列表。该函数的主要步骤包括训练模型、计算特征重要性、根据阈值选择特征、打印特征重要性、保存选择的特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_feature_selection(fe_name, matrix_x_temp, label_y, th):\n",
    "    # SelectfromModel\n",
    "    clf = LGBMClassifier(n_estimators=50)\n",
    "    clf.fit(matrix_x_temp, label_y)\n",
    "    sfm = SelectFromModel(clf, prefit=True, threshold=th)\n",
    "    matrix_x = sfm.transform(matrix_x_temp)\n",
    "\n",
    "    # 打印出有多少特征重要性非零的特征\n",
    "    feature_score_dict = {}\n",
    "    for fn, s in zip(fe_name, clf.feature_importances_):\n",
    "        feature_score_dict[fn] = s\n",
    "    m = 0\n",
    "    for k in feature_score_dict:\n",
    "        if feature_score_dict[k] == 0.0:\n",
    "            m += 1\n",
    "    print('number of not-zero features:' + str(len(feature_score_dict) - m))\n",
    "\n",
    "    # 打印出特征重要性\n",
    "    feature_score_dict_sorted = sorted(feature_score_dict.items(),\n",
    "                                       key=lambda d: d[1], reverse=True)\n",
    "    print('feature_importance:')\n",
    "    for ii in range(len(feature_score_dict_sorted)):\n",
    "        print(feature_score_dict_sorted[ii][0], feature_score_dict_sorted[ii][1])\n",
    "    print('\\n')\n",
    "\n",
    "    f = open('../eda/lgb_feature_importance.txt', 'w')\n",
    "    f.write('Rank\\tFeature Name\\tFeature Importance\\n')\n",
    "    for i in range(len(feature_score_dict_sorted)):\n",
    "        f.write(str(i) + '\\t' + str(feature_score_dict_sorted[i][0]) + '\\t' + str(feature_score_dict_sorted[i][1]) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "    # 打印具体使用了哪些字段\n",
    "    how_long = matrix_x.shape[1]  # matrix_x 是 特征选择后的 输入矩阵\n",
    "    feature_used_dict_temp = feature_score_dict_sorted[:how_long]\n",
    "    feature_used_name = []\n",
    "    for ii in range(len(feature_used_dict_temp)):\n",
    "        feature_used_name.append(feature_used_dict_temp[ii][0])\n",
    "    print('feature_chooesed:')\n",
    "    for ii in range(len(feature_used_name)):\n",
    "        print(feature_used_name[ii])\n",
    "    print('\\n')\n",
    "\n",
    "    f = open('../eda/lgb_feature_chose.txt', 'w')\n",
    "    f.write('Feature Chose Name :\\n')\n",
    "    for i in range(len(feature_used_name)):\n",
    "        f.write(str(feature_used_name[i]) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "    # 找到未被使用的字段名\n",
    "    feature_not_used_name = []\n",
    "    for i in range(len(fe_name)):\n",
    "        if fe_name[i] not in feature_used_name:\n",
    "            feature_not_used_name.append(fe_name[i])\n",
    "\n",
    "    # 生成一个染色体（诸如01011100这样的）\n",
    "    chromosome_temp = ''\n",
    "    feature_name_ivar = fe_name[:-1]\n",
    "    for ii in range(len(feature_name_ivar)):\n",
    "        if feature_name_ivar[ii] in feature_used_name:\n",
    "            chromosome_temp += '1'\n",
    "        else:\n",
    "            chromosome_temp += '0'\n",
    "    print('Chromosome:')\n",
    "    print(chromosome_temp)\n",
    "    joblib.dump(chromosome_temp, '../config/chromosome.pkl')\n",
    "    print('\\n')\n",
    "    return matrix_x, feature_not_used_name[:], len(feature_used_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_feature_selection(fe_name, matrix_x_temp, label_y, th):\n",
    "    # SelectfromModel\n",
    "    clf = XGBClassifier(n_estimators=50)\n",
    "    clf.fit(matrix_x_temp, label_y)\n",
    "    sfm = SelectFromModel(clf, prefit=True, threshold=th)\n",
    "    matrix_x = sfm.transform(matrix_x_temp)\n",
    "\n",
    "    # 打印出有多少特征重要性非零的特征\n",
    "    feature_score_dict = {}\n",
    "    for fn, s in zip(fe_name, clf.feature_importances_):\n",
    "        feature_score_dict[fn] = s\n",
    "    m = 0\n",
    "    for k in feature_score_dict:\n",
    "        if feature_score_dict[k] == 0.0:\n",
    "            m += 1\n",
    "    print('number of not-zero features:' + str(len(feature_score_dict) - m))\n",
    "\n",
    "    # 打印出特征重要性\n",
    "    feature_score_dict_sorted = sorted(feature_score_dict.items(),\n",
    "                                       key=lambda d: d[1], reverse=True)\n",
    "    print('xgb_feature_importance:')\n",
    "    for ii in range(len(feature_score_dict_sorted)):\n",
    "        print(feature_score_dict_sorted[ii][0], feature_score_dict_sorted[ii][1])\n",
    "    print('\\n')\n",
    "\n",
    "    f = open('../eda/xgb_feature_importance.txt', 'w')\n",
    "    f.write('Rank\\tFeature Name\\tFeature Importance\\n')\n",
    "    for i in range(len(feature_score_dict_sorted)):\n",
    "        f.write(str(i) + '\\t' + str(feature_score_dict_sorted[i][0]) + '\\t' + str(feature_score_dict_sorted[i][1]) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "    # 打印具体使用了哪些字段\n",
    "    how_long = matrix_x.shape[1]  # matrix_x 是 特征选择后的 输入矩阵\n",
    "    feature_used_dict_temp = feature_score_dict_sorted[:how_long]\n",
    "    feature_used_name = []\n",
    "    for ii in range(len(feature_used_dict_temp)):\n",
    "        feature_used_name.append(feature_used_dict_temp[ii][0])\n",
    "    print('feature_chooesed:')\n",
    "    for ii in range(len(feature_used_name)):\n",
    "        print(feature_used_name[ii])\n",
    "    print('\\n')\n",
    "\n",
    "    f = open('../eda/xgb_feature_chose.txt', 'w')\n",
    "    f.write('Feature Chose Name :\\n')\n",
    "    for i in range(len(feature_used_name)):\n",
    "        f.write(str(feature_used_name[i]) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "    # 找到未被使用的字段名\n",
    "    feature_not_used_name = []\n",
    "    for i in range(len(fe_name)):\n",
    "        if fe_name[i] not in feature_used_name:\n",
    "            feature_not_used_name.append(fe_name[i])\n",
    "\n",
    "    # 生成一个染色体（诸如01011100这样的）\n",
    "    chromosome_temp = ''\n",
    "    feature_name_ivar = fe_name[:-1]\n",
    "    for ii in range(len(feature_name_ivar)):\n",
    "        if feature_name_ivar[ii] in feature_used_name:\n",
    "            chromosome_temp += '1'\n",
    "        else:\n",
    "            chromosome_temp += '0'\n",
    "    print('Chromosome:')\n",
    "    print(chromosome_temp)\n",
    "    joblib.dump(chromosome_temp, '../config/chromosome.pkl')\n",
    "    print('\\n')\n",
    "    return matrix_x, feature_not_used_name[:], len(feature_used_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_test_feature_drop(data_test, feature_name_drop):\n",
    "    # print feature_name_drop\n",
    "    for col in feature_name_drop:\n",
    "        data_test.drop(col, axis=1, inplace=True)\n",
    "    print(\"data_test_shape:\")\n",
    "    print(data_test.shape)\n",
    "    return data_test.as_matrix()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_predict_results_to_csv(csv_name, uid, prob_list):\n",
    "\n",
    "    csv_file = file(csv_name, 'wb')\n",
    "    writer = csv.writer(csv_file)\n",
    "    combined_list = [['ID', 'pred']]\n",
    "    if len(uid) == len(prob_list):\n",
    "        for i in range(len(uid)):\n",
    "            combined_list.append([str(uid[i]), str(prob_list[i])])\n",
    "        writer.writerows(combined_list)\n",
    "        csv_file.close()\n",
    "    else:\n",
    "        print('no和pred的个数不一致')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def xgb_lgb_cv_modeling():\n",
    "    \"\"\"\n",
    "\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    '''Data input'''\n",
    "    data_train = pd.read_csv('../data/train.csv', index_col='ID')\n",
    "    data_predict = pd.read_csv('../data/pred.csv', index_col='ID')\n",
    "\n",
    "    '''trainset feature engineering 根据具体的数据集进行编写'''\n",
    "    data_train_without_label = data_train.drop('Label', axis=1)\n",
    "    \n",
    "    '''Sample'''\n",
    "    # s = 0\n",
    "    # np.random.seed(s)\n",
    "    # sampler = np.random.permutation(len(data_train_without_label.values))\n",
    "    # data_train_randomized = data_train_without_label.take(sampler)\n",
    "\n",
    "    feature_name = list(data_train_without_label.columns.values)\n",
    "    data_predict_user_id = list(data_predict.index.values)\n",
    "\n",
    "    '''fillna'''\n",
    "    frames = [data_train_without_label, data_predict]\n",
    "    data_all = pd.concat(frames)\n",
    "    data_train_filled = data_train_without_label.fillna(value=data_all.median())\n",
    "\n",
    "    '''construct train and test dataset'''\n",
    "    x_temp = data_train_filled.iloc[:, :].as_matrix()  # 自变量\n",
    "    y = data_train.iloc[:, -1].as_matrix()  # 因变量\n",
    "\n",
    "    '''Feature selection'''\n",
    "    X, dropped_feature_name, len_feature_choose = xgb_feature_selection(feature_name, x_temp, y, '0.1*mean')\n",
    "    # 0.1*mean可以选出10个特征\n",
    "    # 0.00001*mean可以选出14个特征\n",
    "\n",
    "    '''online test dataset -- B_test'''\n",
    "    # del data_predict['V17']\n",
    "    # data_predict['UserInfo_242x40'] = data_predict['UserInfo_242'] * data_predict['UserInfo_40']\n",
    "\n",
    "    data_predict_filled = data_predict.fillna(value=data_all.median())\n",
    "    data_predict_filled_after_feature_selection = data_test_feature_drop(data_predict_filled, dropped_feature_name)\n",
    "\n",
    "    '''Split train/test data sets'''\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)  # 分层抽样  cv的意思是cross-validation\n",
    "\n",
    "    '''Choose a classification model'''\n",
    "    parameter_n_estimators = 100\n",
    "    classifier = LGBMClassifier(n_estimators=parameter_n_estimators, learning_rate=0.1)\n",
    "\n",
    "    '''hyperparameter optimization'''\n",
    "    # param = {\n",
    "    #     'max_depth': 6,\n",
    "    #     'num_leaves': 64,\n",
    "    #     'learning_rate': 0.03,\n",
    "    #     'scale_pos_weight': 1,\n",
    "    #     'num_threads': 40,\n",
    "    #     'objective': 'binary',\n",
    "    #     'bagging_fraction': 0.7,\n",
    "    #     'bagging_freq': 1,\n",
    "    #     'min_sum_hessian_in_leaf': 100\n",
    "    # }\n",
    "    #\n",
    "    # param['is_unbalance'] = 'true'\n",
    "    # param['metric'] = 'auc'\n",
    "\n",
    "    # （1）num_leaves\n",
    "    #\n",
    "    # LightGBM使用的是leaf - wise的算法，因此在调节树的复杂程度时，使用的是num_leaves而不是max_depth。\n",
    "    #\n",
    "    # 大致换算关系：num_leaves = 2 ^ (max_depth)\n",
    "    #\n",
    "    # （2）样本分布非平衡数据集：可以param[‘is_unbalance’]=’true’\n",
    "    #\n",
    "    # （3）Bagging参数：bagging_fraction + bagging_freq（必须同时设置）、feature_fraction\n",
    "    #\n",
    "    # （4）min_data_in_leaf、min_sum_hessian_in_leaf\n",
    "\n",
    "    '''Model fit, predict and ROC'''\n",
    "    colors = cycle(['cyan', 'indigo', 'seagreen', 'orange', 'blue'])\n",
    "    lw = 2\n",
    "    mean_f1 = 0.0\n",
    "    mean_tpr = 0.0\n",
    "    mean_fpr = np.linspace(0, 1, 500)\n",
    "    i_of_roc = 0\n",
    "    a = 0\n",
    "\n",
    "    th = 0.5\n",
    "\n",
    "    for (train_indice, test_indice), color in zip(cv.split(X, y), colors):\n",
    "        a_model = classifier.fit(X[train_indice], y[train_indice])\n",
    "\n",
    "        # y_predict_label = a_model.predict(X[test_indice])\n",
    "\n",
    "        probas_ = a_model.predict_proba(X[test_indice])\n",
    "\n",
    "        fpr, tpr, thresholds = roc_curve(y[test_indice], probas_[:, 1])\n",
    "\n",
    "        a += 1\n",
    "\n",
    "        mean_tpr += interp(mean_fpr, fpr, tpr)\n",
    "        mean_tpr[0] = 0.0\n",
    "\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, lw=lw, color=color, label='ROC fold %d (area = %0.4f)' % (i_of_roc, roc_auc))\n",
    "        i_of_roc += 1\n",
    "\n",
    "        label_transformed = probas_[:, 1]\n",
    "        for i in range(len(label_transformed)):\n",
    "            if label_transformed[i] > th:\n",
    "                label_transformed[i] = 1\n",
    "            else:\n",
    "                label_transformed[i] = 0\n",
    "        lt = label_transformed.astype('int32')\n",
    "        f1 = f1_score(y[test_indice], lt)\n",
    "        mean_f1 += f1\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', lw=lw, color='k', label='Luck')\n",
    "\n",
    "    mean_tpr /= cv.get_n_splits(X, y)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    print('mean_auc=' + str(mean_auc))\n",
    "    print('mean_f1=' + str(mean_f1/5))\n",
    "    plt.plot(mean_fpr, mean_tpr, color='g', linestyle='--', label='Mean ROC (area = %0.4f)' % mean_auc, lw=lw)\n",
    "    plt.xlim([-0.01, 1.01])\n",
    "    plt.ylim([-0.01, 1.01])\n",
    "    plt.xlabel('False Positive Rate mean_f1:'+str(mean_f1))\n",
    "    plt.ylabel('True Positive Rate')\n",
    "\n",
    "    plt.title('ROC_gbdt_' + str(len_feature_choose) + '_features_f1_' + str(mean_f1/5))\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig('../result/pred_ROC_XL' + '_N_' + str(parameter_n_estimators) + '_features_' + str(len_feature_choose) +\n",
    "                '_proba_to_label_using_th_' + str(th) + '.png')\n",
    "    # plt.show()\n",
    "\n",
    "    a_model = classifier.fit(X, y)\n",
    "\n",
    "    # label_predict = a_model.predict(data_predict_filled_after_feature_selection)  # 对B_test进行预测\n",
    "    proba_predict = a_model.predict_proba(data_predict_filled_after_feature_selection)\n",
    "\n",
    "    '''proba result'''\n",
    "    result_file_name = '../result/pred_result_XL_N_' + str(parameter_n_estimators) + '_features_' + str(len_feature_choose) + '_proba.csv'\n",
    "    write_predict_results_to_csv(result_file_name, data_predict_user_id, proba_predict[:, 1].tolist())\n",
    "\n",
    "    # '''写入要提交的结果'''\n",
    "    # result_file_name = '../result/pred_result_N_' + str(parameter_n_estimators) + '_features_' + str(len_feature_choose) + '.csv'\n",
    "    # write_predict_results_to_csv(result_file_name, data_predict_user_id, label_predict.tolist())\n",
    "\n",
    "    '''results file'''\n",
    "    label_transformed = proba_predict[:, 1]\n",
    "    for i in range(len(label_transformed)):\n",
    "        if label_transformed[i] > th:\n",
    "            label_transformed[i] = 1\n",
    "        else:\n",
    "            label_transformed[i] = 0\n",
    "    lt = label_transformed.astype('int32')\n",
    "    result_file_name = '../result/pred_result_XL_N_' + str(parameter_n_estimators) + '_features_' + str(len_feature_choose) + \\\n",
    "                       '_proba_to_label_using_th_' + str(th) + '.csv'\n",
    "    write_predict_results_to_csv(result_file_name, data_predict_user_id, lt.tolist())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
