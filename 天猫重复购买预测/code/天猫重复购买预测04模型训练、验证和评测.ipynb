{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入相关包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据（训练数据前10000行，测试数据前100条）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./data/train_all.csv',nrows=10000)\n",
    "test_data = pd.read_csv('./data/test_all.csv',nrows=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>age_range</th>\n",
       "      <th>gender</th>\n",
       "      <th>user_cnt</th>\n",
       "      <th>seller_nunique</th>\n",
       "      <th>cat_nunique</th>\n",
       "      <th>brand_nunique</th>\n",
       "      <th>item_nunique</th>\n",
       "      <th>time_stamp_nunique</th>\n",
       "      <th>...</th>\n",
       "      <th>embeeding_93</th>\n",
       "      <th>embeeding_94</th>\n",
       "      <th>embeeding_95</th>\n",
       "      <th>embeeding_96</th>\n",
       "      <th>embeeding_97</th>\n",
       "      <th>embeeding_98</th>\n",
       "      <th>embeeding_99</th>\n",
       "      <th>lgb_clf</th>\n",
       "      <th>xgb_clf</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105600.0</td>\n",
       "      <td>1487.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.933521</td>\n",
       "      <td>0.896583</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110976.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>274.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.945943</td>\n",
       "      <td>0.934458</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>374400.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.927698</td>\n",
       "      <td>0.930589</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>189312.0</td>\n",
       "      <td>1760.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>237.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.917096</td>\n",
       "      <td>0.922519</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>189312.0</td>\n",
       "      <td>2511.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>237.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.938043</td>\n",
       "      <td>0.936024</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 231 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  merchant_id  age_range  gender  user_cnt  seller_nunique  \\\n",
       "0  105600.0       1487.0        6.0     1.0     310.0            96.0   \n",
       "1  110976.0        159.0        5.0     0.0     274.0           181.0   \n",
       "2  374400.0        302.0        5.0     1.0     278.0            57.0   \n",
       "3  189312.0       1760.0        4.0     0.0     237.0            49.0   \n",
       "4  189312.0       2511.0        4.0     0.0     237.0            49.0   \n",
       "\n",
       "   cat_nunique  brand_nunique  item_nunique  time_stamp_nunique  ...  \\\n",
       "0         37.0           88.0         217.0                29.0  ...   \n",
       "1         70.0          159.0         233.0                52.0  ...   \n",
       "2         59.0           62.0         148.0                35.0  ...   \n",
       "3         35.0           45.0         170.0                 9.0  ...   \n",
       "4         35.0           45.0         170.0                 9.0  ...   \n",
       "\n",
       "   embeeding_93  embeeding_94  embeeding_95  embeeding_96  embeeding_97  \\\n",
       "0           0.0           0.0           0.0           0.0           0.0   \n",
       "1           0.0           0.0           0.0           0.0           0.0   \n",
       "2           0.0           0.0           0.0           0.0           0.0   \n",
       "3           0.0           0.0           0.0           0.0           0.0   \n",
       "4           0.0           0.0           0.0           0.0           0.0   \n",
       "\n",
       "   embeeding_98  embeeding_99   lgb_clf   xgb_clf  label  \n",
       "0           0.0           0.0  0.933521  0.896583    0.0  \n",
       "1           0.0           0.0  0.945943  0.934458    0.0  \n",
       "2           0.0           0.0  0.927698  0.930589    0.0  \n",
       "3           0.0           0.0  0.917096  0.922519    0.0  \n",
       "4           0.0           0.0  0.938043  0.936024    0.0  \n",
       "\n",
       "[5 rows x 231 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>age_range</th>\n",
       "      <th>gender</th>\n",
       "      <th>user_cnt</th>\n",
       "      <th>seller_nunique</th>\n",
       "      <th>cat_nunique</th>\n",
       "      <th>brand_nunique</th>\n",
       "      <th>item_nunique</th>\n",
       "      <th>time_stamp_nunique</th>\n",
       "      <th>...</th>\n",
       "      <th>embeeding_92</th>\n",
       "      <th>embeeding_93</th>\n",
       "      <th>embeeding_94</th>\n",
       "      <th>embeeding_95</th>\n",
       "      <th>embeeding_96</th>\n",
       "      <th>embeeding_97</th>\n",
       "      <th>embeeding_98</th>\n",
       "      <th>embeeding_99</th>\n",
       "      <th>lgb_clf</th>\n",
       "      <th>xgb_clf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105600.0</td>\n",
       "      <td>1487.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.931309</td>\n",
       "      <td>0.838208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110976.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>274.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.937711</td>\n",
       "      <td>0.940051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>374400.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.934414</td>\n",
       "      <td>0.935365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>189312.0</td>\n",
       "      <td>1760.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>237.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.931040</td>\n",
       "      <td>0.932673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>189312.0</td>\n",
       "      <td>2511.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>237.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.929423</td>\n",
       "      <td>0.929092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 230 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  merchant_id  age_range  gender  user_cnt  seller_nunique  \\\n",
       "0  105600.0       1487.0        6.0     1.0     310.0            96.0   \n",
       "1  110976.0        159.0        5.0     0.0     274.0           181.0   \n",
       "2  374400.0        302.0        5.0     1.0     278.0            57.0   \n",
       "3  189312.0       1760.0        4.0     0.0     237.0            49.0   \n",
       "4  189312.0       2511.0        4.0     0.0     237.0            49.0   \n",
       "\n",
       "   cat_nunique  brand_nunique  item_nunique  time_stamp_nunique  ...  \\\n",
       "0         37.0           88.0         217.0                29.0  ...   \n",
       "1         70.0          159.0         233.0                52.0  ...   \n",
       "2         59.0           62.0         148.0                35.0  ...   \n",
       "3         35.0           45.0         170.0                 9.0  ...   \n",
       "4         35.0           45.0         170.0                 9.0  ...   \n",
       "\n",
       "   embeeding_92  embeeding_93  embeeding_94  embeeding_95  embeeding_96  \\\n",
       "0           0.0           0.0           0.0           0.0           0.0   \n",
       "1           0.0           0.0           0.0           0.0           0.0   \n",
       "2           0.0           0.0           0.0           0.0           0.0   \n",
       "3           0.0           0.0           0.0           0.0           0.0   \n",
       "4           0.0           0.0           0.0           0.0           0.0   \n",
       "\n",
       "   embeeding_97  embeeding_98  embeeding_99   lgb_clf   xgb_clf  \n",
       "0           0.0           0.0           0.0  0.931309  0.838208  \n",
       "1           0.0           0.0           0.0  0.937711  0.940051  \n",
       "2           0.0           0.0           0.0  0.934414  0.935365  \n",
       "3           0.0           0.0           0.0  0.931040  0.932673  \n",
       "4           0.0           0.0           0.0  0.929423  0.929092  \n",
       "\n",
       "[5 rows x 230 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取全部数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = pd.read_csv('train_all.csv',nrows=None)\n",
    "# test_data = pd.read_csv('test_all.csv',nrows=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'merchant_id', 'age_range', 'gender', 'user_cnt',\n",
       "       'seller_nunique', 'cat_nunique', 'brand_nunique', 'item_nunique',\n",
       "       'time_stamp_nunique',\n",
       "       ...\n",
       "       'embeeding_93', 'embeeding_94', 'embeeding_95', 'embeeding_96',\n",
       "       'embeeding_97', 'embeeding_98', 'embeeding_99', 'lgb_clf', 'xgb_clf',\n",
       "       'label'],\n",
       "      dtype='object', length=231)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取训练和测试数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_columns = [col for col in train_data.columns if col not in ['user_id','label']]\n",
    "train = train_data[features_columns].values\n",
    "test = test_data[features_columns].values\n",
    "target =train_data['label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 切分40%数据用于线下验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200, 229) (1200,)\n",
      "(800, 229) (800,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.92875"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0, n_jobs=-1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, target, test_size=0.4, random_state=0)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "clf = clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 交叉验证：评估估算器性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9325 0.9325 0.9325 0.9325 0.93  ]\n",
      "Accuracy: 0.93 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0, n_jobs=-1)\n",
    "scores = cross_val_score(clf, train, target, cv=5)\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.48253558 0.48253558 0.48253558 0.48253558 0.48186528]\n",
      "F1: 0.48 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0, n_jobs=-1)\n",
    "scores = cross_val_score(clf, train, target, cv=5, scoring='f1_macro')\n",
    "print(scores)  \n",
    "print(\"F1: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ShuffleSplit切分数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.915     , 0.93      , 0.92166667, 0.935     , 0.93333333])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0, n_jobs=-1)\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)\n",
    "cross_val_score(clf, train, target, cv=cv)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自己写交叉验证"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KFlod切分数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.93\n",
      "1 0.92\n",
      "2 0.94\n",
      "3 0.94\n",
      "4 0.93\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0, n_jobs=-1)\n",
    "kf = KFold(n_splits=5)\n",
    "for k, (train_index, test_index) in enumerate(kf.split(train)):\n",
    "    X_train, X_test, y_train, y_test = train[train_index], train[test_index], target[train_index], target[test_index]\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    print(k, clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StratifiedKFold切分数据(label均分)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.9325\n",
      "1 0.9325\n",
      "2 0.9325\n",
      "3 0.9325\n",
      "4 0.93\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0, n_jobs=-1)\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "for k, (train_index, test_index) in enumerate(skf.split(train, target)):\n",
    "    X_train, X_test, y_train, y_test = train[train_index], train[test_index], target[train_index], target[test_index]\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    print(k, clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'n_estimators': 50}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.466 (+/-0.002) for {'n_estimators': 50}\n",
      "0.466 (+/-0.003) for {'n_estimators': 100}\n",
      "0.466 (+/-0.003) for {'n_estimators': 200}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.99      0.96       932\n",
      "         1.0       0.00      0.00      0.00        68\n",
      "\n",
      "    accuracy                           0.93      1000\n",
      "   macro avg       0.47      0.50      0.48      1000\n",
      "weighted avg       0.87      0.93      0.90      1000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# Split the dataset in two equal parts\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, target, test_size=0.5, random_state=0)\n",
    "\n",
    "# model \n",
    "clf = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "\n",
    "tuned_parameters = {\n",
    "                    'n_estimators': [50, 100, 200]\n",
    "#                     ,'criterion': ['gini', 'entropy']\n",
    "#                     ,'max_depth': [2, 5]\n",
    "#                     ,'max_features': ['log2', 'sqrt', 'int']\n",
    "#                     ,'bootstrap': [True, False]\n",
    "#                     ,'warm_start': [True, False]\n",
    "                    }\n",
    "\n",
    "scores = ['precision']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(clf, tuned_parameters, cv=5,\n",
    "                       scoring='%s_macro' % score)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模糊矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[456   3]\n",
      " [ 40   1]]\n",
      "Normalized confusion matrix\n",
      "[[0.99 0.01]\n",
      " [0.98 0.02]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# label name\n",
    "class_names = ['no-repeat', 'repeat']\n",
    "\n",
    "# Split the data into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, target, random_state=0)\n",
    "\n",
    "# Run classifier, using a model that is too regularized (C too low) to see\n",
    "# the impact on the results\n",
    "clf = RandomForestClassifier(n_jobs=-1)\n",
    "y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   no-repeat       0.92      0.99      0.95       459\n",
      "      repeat       0.25      0.02      0.04        41\n",
      "\n",
      "    accuracy                           0.91       500\n",
      "   macro avg       0.58      0.51      0.50       500\n",
      "weighted avg       0.86      0.91      0.88       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# label name\n",
    "class_names = ['no-repeat', 'repeat']\n",
    "\n",
    "# Split the data into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, target, random_state=0)\n",
    "\n",
    "# Run classifier, using a model that is too regularized (C too low) to see\n",
    "# the impact on the results\n",
    "clf = RandomForestClassifier(n_jobs=-1)\n",
    "y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 不同的分类模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.918"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "stdScaler = StandardScaler()\n",
    "X = stdScaler.fit_transform(train)\n",
    "\n",
    "# Split the data into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, target, random_state=0)\n",
    "\n",
    "clf = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial').fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.906"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "stdScaler = StandardScaler()\n",
    "X = stdScaler.fit_transform(train)\n",
    "\n",
    "# Split the data into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, target, random_state=0)\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=3).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GaussianNB 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.504"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "stdScaler = StandardScaler()\n",
    "X = stdScaler.fit_transform(train)\n",
    "\n",
    "# Split the data into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, target, random_state=0)\n",
    "\n",
    "clf = GaussianNB().fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tree树模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.866"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "# Split the data into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, target, random_state=0)\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bagging模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.918"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Split the data into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, target, random_state=0)\n",
    "clf = BaggingClassifier(KNeighborsClassifier(), max_samples=0.5, max_features=0.5)\n",
    "\n",
    "clf = clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 随机森林模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.918"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Split the data into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, target, random_state=0)\n",
    "clf = clf = RandomForestClassifier(n_estimators=10, max_depth=3, min_samples_split=12, random_state=0)\n",
    "\n",
    "clf = clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExTree模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.908"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# Split the data into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, target, random_state=0)\n",
    "clf = ExtraTreesClassifier(n_estimators=10, max_depth=None, min_samples_split=2, random_state=0)\n",
    "\n",
    "clf = clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "229"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.n_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07, 0.02, 0.02, 0.02, 0.02, 0.02, 0.01, 0.01, 0.02, 0.01])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.feature_importances_[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.918"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Split the data into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, target, random_state=0)\n",
    "clf = AdaBoostClassifier(n_estimators=10)\n",
    "\n",
    "clf = clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBDT模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.912"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Split the data into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, target, random_state=0)\n",
    "clf = GradientBoostingClassifier(n_estimators=10, learning_rate=1.0, max_depth=1, random_state=0)\n",
    "\n",
    "clf = clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VOTE模型投票"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.92 (+/- 0.01) [Logistic Regression]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.93 (+/- 0.00) [Random Forest]\n",
      "Accuracy: 0.49 (+/- 0.03) [naive Bayes]\n",
      "Accuracy: 0.92 (+/- 0.01) [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "stdScaler = StandardScaler()\n",
    "X = stdScaler.fit_transform(train)\n",
    "y = target\n",
    "\n",
    "\n",
    "clf1 = LogisticRegression(solver='lbfgs', multi_class='multinomial', random_state=1)\n",
    "clf2 = RandomForestClassifier(n_estimators=50, random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='hard')\n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3, eclf], ['Logistic Regression', 'Random Forest', 'naive Bayes', 'Ensemble']):\n",
    "    scores = cross_val_score(clf, X, y, cv=5, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lgb 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Unknown parameter: tree_method\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Unknown parameter: tree_method\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001559 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6627\n",
      "[LightGBM] [Info] Number of data points in the train set: 1200, number of used features: 124\n",
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Unknown parameter: tree_method\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Info] Start training from score -0.068100\n",
      "[LightGBM] [Info] Start training from score -2.720629\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[22]\tvalid_0's multi_logloss: 0.253344\n"
     ]
    }
   ],
   "source": [
    "import lightgbm\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, target, test_size=0.4, random_state=0)\n",
    "X_test, X_valid, y_test, y_valid = train_test_split(X_test, y_test, test_size=0.5, random_state=0)\n",
    "\n",
    "clf = lightgbm\n",
    "\n",
    "train_matrix = clf.Dataset(X_train, label=y_train)\n",
    "test_matrix = clf.Dataset(X_test, label=y_test)\n",
    "params = {\n",
    "          'boosting_type': 'gbdt',\n",
    "          #'boosting_type': 'dart',\n",
    "          'objective': 'multiclass',\n",
    "          'metric': 'multi_logloss',\n",
    "          'min_child_weight': 1.5,\n",
    "          'num_leaves': 2**5,\n",
    "          'lambda_l2': 10,\n",
    "          'subsample': 0.7,\n",
    "          'colsample_bytree': 0.7,\n",
    "          'colsample_bylevel': 0.7,\n",
    "          'learning_rate': 0.03,\n",
    "          'tree_method': 'exact',\n",
    "          'seed': 2017,\n",
    "          \"num_class\": 2,\n",
    "          'silent': True,\n",
    "          }\n",
    "num_round = 10000\n",
    "#early_stopping_rounds = 100\n",
    "#callbacks=[lightgbm.log_evaluation(period=100), lightgbm.early_stopping(stopping_rounds=100)]\n",
    "callbacks=[lightgbm.early_stopping(stopping_rounds=100)]\n",
    "model = clf.train(params, \n",
    "                  train_matrix,\n",
    "                  num_round,\n",
    "                  valid_sets=test_matrix,\n",
    "                  #early_stopping_rounds=early_stopping_rounds\n",
    "                  callbacks=callbacks \n",
    "                  )\n",
    "pre= model.predict(X_valid,num_iteration=model.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score :  0.9275\n"
     ]
    }
   ],
   "source": [
    "print('score : ', np.mean((pre[:,1]>0.5)==y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgb 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:0.67493\teval-mlogloss:0.67523\n",
      "[1]\ttrain-mlogloss:0.65782\teval-mlogloss:0.65839\n",
      "[2]\ttrain-mlogloss:0.64136\teval-mlogloss:0.64210\n",
      "[3]\ttrain-mlogloss:0.62561\teval-mlogloss:0.62645\n",
      "[4]\ttrain-mlogloss:0.61037\teval-mlogloss:0.61149\n",
      "[5]\ttrain-mlogloss:0.59608\teval-mlogloss:0.59751\n",
      "[6]\ttrain-mlogloss:0.58224\teval-mlogloss:0.58400\n",
      "[7]\ttrain-mlogloss:0.56915\teval-mlogloss:0.57106\n",
      "[8]\ttrain-mlogloss:0.55639\teval-mlogloss:0.55855\n",
      "[9]\ttrain-mlogloss:0.54458\teval-mlogloss:0.54696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\ttrain-mlogloss:0.53305\teval-mlogloss:0.53569\n",
      "[11]\ttrain-mlogloss:0.52191\teval-mlogloss:0.52485\n",
      "[12]\ttrain-mlogloss:0.51136\teval-mlogloss:0.51460\n",
      "[13]\ttrain-mlogloss:0.50123\teval-mlogloss:0.50463\n",
      "[14]\ttrain-mlogloss:0.49148\teval-mlogloss:0.49513\n",
      "[15]\ttrain-mlogloss:0.48229\teval-mlogloss:0.48624\n",
      "[16]\ttrain-mlogloss:0.47339\teval-mlogloss:0.47751\n",
      "[17]\ttrain-mlogloss:0.46491\teval-mlogloss:0.46922\n",
      "[18]\ttrain-mlogloss:0.45654\teval-mlogloss:0.46132\n",
      "[19]\ttrain-mlogloss:0.44865\teval-mlogloss:0.45361\n",
      "[20]\ttrain-mlogloss:0.44106\teval-mlogloss:0.44632\n",
      "[21]\ttrain-mlogloss:0.43378\teval-mlogloss:0.43917\n",
      "[22]\ttrain-mlogloss:0.42685\teval-mlogloss:0.43248\n",
      "[23]\ttrain-mlogloss:0.42003\teval-mlogloss:0.42578\n",
      "[24]\ttrain-mlogloss:0.41348\teval-mlogloss:0.41940\n",
      "[25]\ttrain-mlogloss:0.40730\teval-mlogloss:0.41341\n",
      "[26]\ttrain-mlogloss:0.40120\teval-mlogloss:0.40749\n",
      "[27]\ttrain-mlogloss:0.39534\teval-mlogloss:0.40186\n",
      "[28]\ttrain-mlogloss:0.38974\teval-mlogloss:0.39649\n",
      "[29]\ttrain-mlogloss:0.38438\teval-mlogloss:0.39138\n",
      "[30]\ttrain-mlogloss:0.37915\teval-mlogloss:0.38637\n",
      "[31]\ttrain-mlogloss:0.37416\teval-mlogloss:0.38167\n",
      "[32]\ttrain-mlogloss:0.36938\teval-mlogloss:0.37711\n",
      "[33]\ttrain-mlogloss:0.36468\teval-mlogloss:0.37255\n",
      "[34]\ttrain-mlogloss:0.36013\teval-mlogloss:0.36820\n",
      "[35]\ttrain-mlogloss:0.35603\teval-mlogloss:0.36427\n",
      "[36]\ttrain-mlogloss:0.35190\teval-mlogloss:0.36039\n",
      "[37]\ttrain-mlogloss:0.34803\teval-mlogloss:0.35665\n",
      "[38]\ttrain-mlogloss:0.34395\teval-mlogloss:0.35278\n",
      "[39]\ttrain-mlogloss:0.34019\teval-mlogloss:0.34929\n",
      "[40]\ttrain-mlogloss:0.33669\teval-mlogloss:0.34595\n",
      "[41]\ttrain-mlogloss:0.33317\teval-mlogloss:0.34263\n",
      "[42]\ttrain-mlogloss:0.32976\teval-mlogloss:0.33935\n",
      "[43]\ttrain-mlogloss:0.32660\teval-mlogloss:0.33632\n",
      "[44]\ttrain-mlogloss:0.32360\teval-mlogloss:0.33345\n",
      "[45]\ttrain-mlogloss:0.32056\teval-mlogloss:0.33057\n",
      "[46]\ttrain-mlogloss:0.31756\teval-mlogloss:0.32778\n",
      "[47]\ttrain-mlogloss:0.31468\teval-mlogloss:0.32506\n",
      "[48]\ttrain-mlogloss:0.31192\teval-mlogloss:0.32246\n",
      "[49]\ttrain-mlogloss:0.30930\teval-mlogloss:0.31997\n",
      "[50]\ttrain-mlogloss:0.30683\teval-mlogloss:0.31757\n",
      "[51]\ttrain-mlogloss:0.30441\teval-mlogloss:0.31528\n",
      "[52]\ttrain-mlogloss:0.30205\teval-mlogloss:0.31312\n",
      "[53]\ttrain-mlogloss:0.29980\teval-mlogloss:0.31109\n",
      "[54]\ttrain-mlogloss:0.29768\teval-mlogloss:0.30905\n",
      "[55]\ttrain-mlogloss:0.29559\teval-mlogloss:0.30718\n",
      "[56]\ttrain-mlogloss:0.29361\teval-mlogloss:0.30526\n",
      "[57]\ttrain-mlogloss:0.29165\teval-mlogloss:0.30349\n",
      "[58]\ttrain-mlogloss:0.28989\teval-mlogloss:0.30188\n",
      "[59]\ttrain-mlogloss:0.28817\teval-mlogloss:0.30022\n",
      "[60]\ttrain-mlogloss:0.28633\teval-mlogloss:0.29851\n",
      "[61]\ttrain-mlogloss:0.28460\teval-mlogloss:0.29690\n",
      "[62]\ttrain-mlogloss:0.28303\teval-mlogloss:0.29550\n",
      "[63]\ttrain-mlogloss:0.28137\teval-mlogloss:0.29393\n",
      "[64]\ttrain-mlogloss:0.27978\teval-mlogloss:0.29256\n",
      "[65]\ttrain-mlogloss:0.27819\teval-mlogloss:0.29115\n",
      "[66]\ttrain-mlogloss:0.27665\teval-mlogloss:0.28980\n",
      "[67]\ttrain-mlogloss:0.27516\teval-mlogloss:0.28856\n",
      "[68]\ttrain-mlogloss:0.27368\teval-mlogloss:0.28732\n",
      "[69]\ttrain-mlogloss:0.27231\teval-mlogloss:0.28620\n",
      "[70]\ttrain-mlogloss:0.27103\teval-mlogloss:0.28509\n",
      "[71]\ttrain-mlogloss:0.26974\teval-mlogloss:0.28391\n",
      "[72]\ttrain-mlogloss:0.26848\teval-mlogloss:0.28279\n",
      "[73]\ttrain-mlogloss:0.26730\teval-mlogloss:0.28182\n",
      "[74]\ttrain-mlogloss:0.26616\teval-mlogloss:0.28092\n",
      "[75]\ttrain-mlogloss:0.26498\teval-mlogloss:0.27990\n",
      "[76]\ttrain-mlogloss:0.26382\teval-mlogloss:0.27897\n",
      "[77]\ttrain-mlogloss:0.26284\teval-mlogloss:0.27810\n",
      "[78]\ttrain-mlogloss:0.26175\teval-mlogloss:0.27732\n",
      "[79]\ttrain-mlogloss:0.26073\teval-mlogloss:0.27645\n",
      "[80]\ttrain-mlogloss:0.25966\teval-mlogloss:0.27564\n",
      "[81]\ttrain-mlogloss:0.25863\teval-mlogloss:0.27478\n",
      "[82]\ttrain-mlogloss:0.25768\teval-mlogloss:0.27399\n",
      "[83]\ttrain-mlogloss:0.25692\teval-mlogloss:0.27330\n",
      "[84]\ttrain-mlogloss:0.25601\teval-mlogloss:0.27253\n",
      "[85]\ttrain-mlogloss:0.25517\teval-mlogloss:0.27180\n",
      "[86]\ttrain-mlogloss:0.25433\teval-mlogloss:0.27111\n",
      "[87]\ttrain-mlogloss:0.25351\teval-mlogloss:0.27031\n",
      "[88]\ttrain-mlogloss:0.25267\teval-mlogloss:0.26966\n",
      "[89]\ttrain-mlogloss:0.25188\teval-mlogloss:0.26909\n",
      "[90]\ttrain-mlogloss:0.25118\teval-mlogloss:0.26847\n",
      "[91]\ttrain-mlogloss:0.25056\teval-mlogloss:0.26789\n",
      "[92]\ttrain-mlogloss:0.24998\teval-mlogloss:0.26736\n",
      "[93]\ttrain-mlogloss:0.24934\teval-mlogloss:0.26685\n",
      "[94]\ttrain-mlogloss:0.24874\teval-mlogloss:0.26637\n",
      "[95]\ttrain-mlogloss:0.24817\teval-mlogloss:0.26584\n",
      "[96]\ttrain-mlogloss:0.24749\teval-mlogloss:0.26537\n",
      "[97]\ttrain-mlogloss:0.24695\teval-mlogloss:0.26487\n",
      "[98]\ttrain-mlogloss:0.24642\teval-mlogloss:0.26447\n",
      "[99]\ttrain-mlogloss:0.24586\teval-mlogloss:0.26400\n",
      "[100]\ttrain-mlogloss:0.24537\teval-mlogloss:0.26364\n",
      "[101]\ttrain-mlogloss:0.24486\teval-mlogloss:0.26312\n",
      "[102]\ttrain-mlogloss:0.24431\teval-mlogloss:0.26274\n",
      "[103]\ttrain-mlogloss:0.24382\teval-mlogloss:0.26241\n",
      "[104]\ttrain-mlogloss:0.24342\teval-mlogloss:0.26223\n",
      "[105]\ttrain-mlogloss:0.24291\teval-mlogloss:0.26185\n",
      "[106]\ttrain-mlogloss:0.24240\teval-mlogloss:0.26155\n",
      "[107]\ttrain-mlogloss:0.24191\teval-mlogloss:0.26116\n",
      "[108]\ttrain-mlogloss:0.24151\teval-mlogloss:0.26077\n",
      "[109]\ttrain-mlogloss:0.24116\teval-mlogloss:0.26056\n",
      "[110]\ttrain-mlogloss:0.24075\teval-mlogloss:0.26025\n",
      "[111]\ttrain-mlogloss:0.24050\teval-mlogloss:0.26002\n",
      "[112]\ttrain-mlogloss:0.24021\teval-mlogloss:0.25979\n",
      "[113]\ttrain-mlogloss:0.23986\teval-mlogloss:0.25954\n",
      "[114]\ttrain-mlogloss:0.23951\teval-mlogloss:0.25929\n",
      "[115]\ttrain-mlogloss:0.23918\teval-mlogloss:0.25906\n",
      "[116]\ttrain-mlogloss:0.23875\teval-mlogloss:0.25872\n",
      "[117]\ttrain-mlogloss:0.23849\teval-mlogloss:0.25855\n",
      "[118]\ttrain-mlogloss:0.23811\teval-mlogloss:0.25833\n",
      "[119]\ttrain-mlogloss:0.23781\teval-mlogloss:0.25812\n",
      "[120]\ttrain-mlogloss:0.23752\teval-mlogloss:0.25788\n",
      "[121]\ttrain-mlogloss:0.23726\teval-mlogloss:0.25780\n",
      "[122]\ttrain-mlogloss:0.23702\teval-mlogloss:0.25764\n",
      "[123]\ttrain-mlogloss:0.23682\teval-mlogloss:0.25749\n",
      "[124]\ttrain-mlogloss:0.23656\teval-mlogloss:0.25732\n",
      "[125]\ttrain-mlogloss:0.23628\teval-mlogloss:0.25708\n",
      "[126]\ttrain-mlogloss:0.23603\teval-mlogloss:0.25689\n",
      "[127]\ttrain-mlogloss:0.23581\teval-mlogloss:0.25670\n",
      "[128]\ttrain-mlogloss:0.23562\teval-mlogloss:0.25669\n",
      "[129]\ttrain-mlogloss:0.23548\teval-mlogloss:0.25657\n",
      "[130]\ttrain-mlogloss:0.23525\teval-mlogloss:0.25643\n",
      "[131]\ttrain-mlogloss:0.23507\teval-mlogloss:0.25631\n",
      "[132]\ttrain-mlogloss:0.23490\teval-mlogloss:0.25612\n",
      "[133]\ttrain-mlogloss:0.23473\teval-mlogloss:0.25602\n",
      "[134]\ttrain-mlogloss:0.23456\teval-mlogloss:0.25591\n",
      "[135]\ttrain-mlogloss:0.23438\teval-mlogloss:0.25579\n",
      "[136]\ttrain-mlogloss:0.23410\teval-mlogloss:0.25568\n",
      "[137]\ttrain-mlogloss:0.23390\teval-mlogloss:0.25560\n",
      "[138]\ttrain-mlogloss:0.23381\teval-mlogloss:0.25552\n",
      "[139]\ttrain-mlogloss:0.23367\teval-mlogloss:0.25540\n",
      "[140]\ttrain-mlogloss:0.23355\teval-mlogloss:0.25530\n",
      "[141]\ttrain-mlogloss:0.23340\teval-mlogloss:0.25521\n",
      "[142]\ttrain-mlogloss:0.23328\teval-mlogloss:0.25507\n",
      "[143]\ttrain-mlogloss:0.23314\teval-mlogloss:0.25493\n",
      "[144]\ttrain-mlogloss:0.23306\teval-mlogloss:0.25485\n",
      "[145]\ttrain-mlogloss:0.23286\teval-mlogloss:0.25475\n",
      "[146]\ttrain-mlogloss:0.23275\teval-mlogloss:0.25468\n",
      "[147]\ttrain-mlogloss:0.23266\teval-mlogloss:0.25470\n",
      "[148]\ttrain-mlogloss:0.23250\teval-mlogloss:0.25458\n",
      "[149]\ttrain-mlogloss:0.23233\teval-mlogloss:0.25443\n",
      "[150]\ttrain-mlogloss:0.23225\teval-mlogloss:0.25436\n",
      "[151]\ttrain-mlogloss:0.23215\teval-mlogloss:0.25427\n",
      "[152]\ttrain-mlogloss:0.23200\teval-mlogloss:0.25418\n",
      "[153]\ttrain-mlogloss:0.23187\teval-mlogloss:0.25409\n",
      "[154]\ttrain-mlogloss:0.23181\teval-mlogloss:0.25404\n",
      "[155]\ttrain-mlogloss:0.23170\teval-mlogloss:0.25399\n",
      "[156]\ttrain-mlogloss:0.23159\teval-mlogloss:0.25404\n",
      "[157]\ttrain-mlogloss:0.23150\teval-mlogloss:0.25397\n",
      "[158]\ttrain-mlogloss:0.23142\teval-mlogloss:0.25394\n",
      "[159]\ttrain-mlogloss:0.23133\teval-mlogloss:0.25390\n",
      "[160]\ttrain-mlogloss:0.23119\teval-mlogloss:0.25381\n",
      "[161]\ttrain-mlogloss:0.23111\teval-mlogloss:0.25384\n",
      "[162]\ttrain-mlogloss:0.23099\teval-mlogloss:0.25381\n",
      "[163]\ttrain-mlogloss:0.23091\teval-mlogloss:0.25379\n",
      "[164]\ttrain-mlogloss:0.23083\teval-mlogloss:0.25370\n",
      "[165]\ttrain-mlogloss:0.23075\teval-mlogloss:0.25364\n",
      "[166]\ttrain-mlogloss:0.23068\teval-mlogloss:0.25374\n",
      "[167]\ttrain-mlogloss:0.23057\teval-mlogloss:0.25367\n",
      "[168]\ttrain-mlogloss:0.23052\teval-mlogloss:0.25364\n",
      "[169]\ttrain-mlogloss:0.23038\teval-mlogloss:0.25371\n",
      "[170]\ttrain-mlogloss:0.23033\teval-mlogloss:0.25370\n",
      "[171]\ttrain-mlogloss:0.23026\teval-mlogloss:0.25374\n",
      "[172]\ttrain-mlogloss:0.23020\teval-mlogloss:0.25372\n",
      "[173]\ttrain-mlogloss:0.23010\teval-mlogloss:0.25369\n",
      "[174]\ttrain-mlogloss:0.23003\teval-mlogloss:0.25374\n",
      "[175]\ttrain-mlogloss:0.22992\teval-mlogloss:0.25377\n",
      "[176]\ttrain-mlogloss:0.22983\teval-mlogloss:0.25383\n",
      "[177]\ttrain-mlogloss:0.22978\teval-mlogloss:0.25382\n",
      "[178]\ttrain-mlogloss:0.22973\teval-mlogloss:0.25379\n",
      "[179]\ttrain-mlogloss:0.22970\teval-mlogloss:0.25377\n",
      "[180]\ttrain-mlogloss:0.22968\teval-mlogloss:0.25375\n",
      "[181]\ttrain-mlogloss:0.22965\teval-mlogloss:0.25373\n",
      "[182]\ttrain-mlogloss:0.22962\teval-mlogloss:0.25370\n",
      "[183]\ttrain-mlogloss:0.22952\teval-mlogloss:0.25372\n",
      "[184]\ttrain-mlogloss:0.22946\teval-mlogloss:0.25371\n",
      "[185]\ttrain-mlogloss:0.22945\teval-mlogloss:0.25370\n",
      "[186]\ttrain-mlogloss:0.22937\teval-mlogloss:0.25382\n",
      "[187]\ttrain-mlogloss:0.22935\teval-mlogloss:0.25381\n",
      "[188]\ttrain-mlogloss:0.22933\teval-mlogloss:0.25380\n",
      "[189]\ttrain-mlogloss:0.22924\teval-mlogloss:0.25371\n",
      "[190]\ttrain-mlogloss:0.22919\teval-mlogloss:0.25372\n",
      "[191]\ttrain-mlogloss:0.22916\teval-mlogloss:0.25371\n",
      "[192]\ttrain-mlogloss:0.22912\teval-mlogloss:0.25369\n",
      "[193]\ttrain-mlogloss:0.22909\teval-mlogloss:0.25367\n",
      "[194]\ttrain-mlogloss:0.22908\teval-mlogloss:0.25366\n",
      "[195]\ttrain-mlogloss:0.22904\teval-mlogloss:0.25372\n",
      "[196]\ttrain-mlogloss:0.22898\teval-mlogloss:0.25365\n",
      "[197]\ttrain-mlogloss:0.22897\teval-mlogloss:0.25364\n",
      "[198]\ttrain-mlogloss:0.22893\teval-mlogloss:0.25365\n",
      "[199]\ttrain-mlogloss:0.22892\teval-mlogloss:0.25364\n",
      "[200]\ttrain-mlogloss:0.22890\teval-mlogloss:0.25363\n",
      "[201]\ttrain-mlogloss:0.22886\teval-mlogloss:0.25365\n",
      "[202]\ttrain-mlogloss:0.22877\teval-mlogloss:0.25357\n",
      "[203]\ttrain-mlogloss:0.22869\teval-mlogloss:0.25351\n",
      "[204]\ttrain-mlogloss:0.22865\teval-mlogloss:0.25351\n",
      "[205]\ttrain-mlogloss:0.22857\teval-mlogloss:0.25365\n",
      "[206]\ttrain-mlogloss:0.22856\teval-mlogloss:0.25364\n",
      "[207]\ttrain-mlogloss:0.22841\teval-mlogloss:0.25370\n",
      "[208]\ttrain-mlogloss:0.22840\teval-mlogloss:0.25369\n",
      "[209]\ttrain-mlogloss:0.22836\teval-mlogloss:0.25374\n",
      "[210]\ttrain-mlogloss:0.22835\teval-mlogloss:0.25373\n",
      "[211]\ttrain-mlogloss:0.22832\teval-mlogloss:0.25375\n",
      "[212]\ttrain-mlogloss:0.22828\teval-mlogloss:0.25380\n",
      "[213]\ttrain-mlogloss:0.22827\teval-mlogloss:0.25380\n",
      "[214]\ttrain-mlogloss:0.22827\teval-mlogloss:0.25380\n",
      "[215]\ttrain-mlogloss:0.22824\teval-mlogloss:0.25382\n",
      "[216]\ttrain-mlogloss:0.22823\teval-mlogloss:0.25381\n",
      "[217]\ttrain-mlogloss:0.22812\teval-mlogloss:0.25382\n",
      "[218]\ttrain-mlogloss:0.22806\teval-mlogloss:0.25383\n",
      "[219]\ttrain-mlogloss:0.22801\teval-mlogloss:0.25385\n",
      "[220]\ttrain-mlogloss:0.22800\teval-mlogloss:0.25384\n",
      "[221]\ttrain-mlogloss:0.22800\teval-mlogloss:0.25384\n",
      "[222]\ttrain-mlogloss:0.22795\teval-mlogloss:0.25388\n",
      "[223]\ttrain-mlogloss:0.22788\teval-mlogloss:0.25396\n",
      "[224]\ttrain-mlogloss:0.22777\teval-mlogloss:0.25398\n",
      "[225]\ttrain-mlogloss:0.22773\teval-mlogloss:0.25399\n",
      "[226]\ttrain-mlogloss:0.22772\teval-mlogloss:0.25399\n",
      "[227]\ttrain-mlogloss:0.22762\teval-mlogloss:0.25395\n",
      "[228]\ttrain-mlogloss:0.22760\teval-mlogloss:0.25397\n",
      "[229]\ttrain-mlogloss:0.22756\teval-mlogloss:0.25398\n",
      "[230]\ttrain-mlogloss:0.22752\teval-mlogloss:0.25400\n",
      "[231]\ttrain-mlogloss:0.22747\teval-mlogloss:0.25402\n",
      "[232]\ttrain-mlogloss:0.22741\teval-mlogloss:0.25407\n",
      "[233]\ttrain-mlogloss:0.22737\teval-mlogloss:0.25414\n",
      "[234]\ttrain-mlogloss:0.22737\teval-mlogloss:0.25414\n",
      "[235]\ttrain-mlogloss:0.22735\teval-mlogloss:0.25420\n",
      "[236]\ttrain-mlogloss:0.22726\teval-mlogloss:0.25423\n",
      "[237]\ttrain-mlogloss:0.22722\teval-mlogloss:0.25423\n",
      "[238]\ttrain-mlogloss:0.22715\teval-mlogloss:0.25424\n",
      "[239]\ttrain-mlogloss:0.22714\teval-mlogloss:0.25424\n",
      "[240]\ttrain-mlogloss:0.22714\teval-mlogloss:0.25424\n",
      "[241]\ttrain-mlogloss:0.22714\teval-mlogloss:0.25424\n",
      "[242]\ttrain-mlogloss:0.22711\teval-mlogloss:0.25425\n",
      "[243]\ttrain-mlogloss:0.22701\teval-mlogloss:0.25426\n",
      "[244]\ttrain-mlogloss:0.22699\teval-mlogloss:0.25421\n",
      "[245]\ttrain-mlogloss:0.22693\teval-mlogloss:0.25418\n",
      "[246]\ttrain-mlogloss:0.22686\teval-mlogloss:0.25422\n",
      "[247]\ttrain-mlogloss:0.22681\teval-mlogloss:0.25424\n",
      "[248]\ttrain-mlogloss:0.22678\teval-mlogloss:0.25429\n",
      "[249]\ttrain-mlogloss:0.22677\teval-mlogloss:0.25429\n",
      "[250]\ttrain-mlogloss:0.22669\teval-mlogloss:0.25428\n",
      "[251]\ttrain-mlogloss:0.22669\teval-mlogloss:0.25428\n",
      "[252]\ttrain-mlogloss:0.22668\teval-mlogloss:0.25428\n",
      "[253]\ttrain-mlogloss:0.22666\teval-mlogloss:0.25427\n",
      "[254]\ttrain-mlogloss:0.22665\teval-mlogloss:0.25427\n",
      "[255]\ttrain-mlogloss:0.22660\teval-mlogloss:0.25433\n",
      "[256]\ttrain-mlogloss:0.22660\teval-mlogloss:0.25433\n",
      "[257]\ttrain-mlogloss:0.22660\teval-mlogloss:0.25433\n",
      "[258]\ttrain-mlogloss:0.22654\teval-mlogloss:0.25437\n",
      "[259]\ttrain-mlogloss:0.22648\teval-mlogloss:0.25432\n",
      "[260]\ttrain-mlogloss:0.22648\teval-mlogloss:0.25432\n",
      "[261]\ttrain-mlogloss:0.22644\teval-mlogloss:0.25435\n",
      "[262]\ttrain-mlogloss:0.22643\teval-mlogloss:0.25435\n",
      "[263]\ttrain-mlogloss:0.22643\teval-mlogloss:0.25435\n",
      "[264]\ttrain-mlogloss:0.22632\teval-mlogloss:0.25439\n",
      "[265]\ttrain-mlogloss:0.22622\teval-mlogloss:0.25439\n",
      "[266]\ttrain-mlogloss:0.22622\teval-mlogloss:0.25439\n",
      "[267]\ttrain-mlogloss:0.22619\teval-mlogloss:0.25439\n",
      "[268]\ttrain-mlogloss:0.22616\teval-mlogloss:0.25442\n",
      "[269]\ttrain-mlogloss:0.22607\teval-mlogloss:0.25441\n",
      "[270]\ttrain-mlogloss:0.22607\teval-mlogloss:0.25441\n",
      "[271]\ttrain-mlogloss:0.22607\teval-mlogloss:0.25441\n",
      "[272]\ttrain-mlogloss:0.22607\teval-mlogloss:0.25441\n",
      "[273]\ttrain-mlogloss:0.22607\teval-mlogloss:0.25441\n",
      "[274]\ttrain-mlogloss:0.22602\teval-mlogloss:0.25441\n",
      "[275]\ttrain-mlogloss:0.22600\teval-mlogloss:0.25436\n",
      "[276]\ttrain-mlogloss:0.22594\teval-mlogloss:0.25441\n",
      "[277]\ttrain-mlogloss:0.22594\teval-mlogloss:0.25441\n",
      "[278]\ttrain-mlogloss:0.22594\teval-mlogloss:0.25441\n",
      "[279]\ttrain-mlogloss:0.22593\teval-mlogloss:0.25441\n",
      "[280]\ttrain-mlogloss:0.22593\teval-mlogloss:0.25442\n",
      "[281]\ttrain-mlogloss:0.22593\teval-mlogloss:0.25442\n",
      "[282]\ttrain-mlogloss:0.22592\teval-mlogloss:0.25442\n",
      "[283]\ttrain-mlogloss:0.22592\teval-mlogloss:0.25442\n",
      "[284]\ttrain-mlogloss:0.22592\teval-mlogloss:0.25442\n",
      "[285]\ttrain-mlogloss:0.22592\teval-mlogloss:0.25442\n",
      "[286]\ttrain-mlogloss:0.22583\teval-mlogloss:0.25452\n",
      "[287]\ttrain-mlogloss:0.22583\teval-mlogloss:0.25452\n",
      "[288]\ttrain-mlogloss:0.22578\teval-mlogloss:0.25455\n",
      "[289]\ttrain-mlogloss:0.22574\teval-mlogloss:0.25452\n",
      "[290]\ttrain-mlogloss:0.22569\teval-mlogloss:0.25449\n",
      "[291]\ttrain-mlogloss:0.22564\teval-mlogloss:0.25450\n",
      "[292]\ttrain-mlogloss:0.22564\teval-mlogloss:0.25450\n",
      "[293]\ttrain-mlogloss:0.22564\teval-mlogloss:0.25450\n",
      "[294]\ttrain-mlogloss:0.22560\teval-mlogloss:0.25447\n",
      "[295]\ttrain-mlogloss:0.22560\teval-mlogloss:0.25447\n",
      "[296]\ttrain-mlogloss:0.22554\teval-mlogloss:0.25450\n",
      "[297]\ttrain-mlogloss:0.22547\teval-mlogloss:0.25452\n",
      "[298]\ttrain-mlogloss:0.22547\teval-mlogloss:0.25451\n",
      "[299]\ttrain-mlogloss:0.22548\teval-mlogloss:0.25451\n",
      "[300]\ttrain-mlogloss:0.22545\teval-mlogloss:0.25453\n",
      "[301]\ttrain-mlogloss:0.22545\teval-mlogloss:0.25453\n",
      "[302]\ttrain-mlogloss:0.22541\teval-mlogloss:0.25455\n",
      "[303]\ttrain-mlogloss:0.22540\teval-mlogloss:0.25455\n",
      "[304]\ttrain-mlogloss:0.22540\teval-mlogloss:0.25455\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, target, test_size=0.4, random_state=0)\n",
    "X_test, X_valid, y_test, y_valid = train_test_split(X_test, y_test, test_size=0.5, random_state=0)\n",
    "\n",
    "clf = xgboost\n",
    "\n",
    "train_matrix = clf.DMatrix(X_train, label=y_train, missing=-1)\n",
    "test_matrix = clf.DMatrix(X_test, label=y_test, missing=-1)\n",
    "z = clf.DMatrix(X_valid, label=y_valid, missing=-1)\n",
    "params = {'booster': 'gbtree',\n",
    "          'objective': 'multi:softprob',\n",
    "          'eval_metric': 'mlogloss',\n",
    "          'gamma': 1,\n",
    "          'min_child_weight': 1.5,\n",
    "          'max_depth': 5,\n",
    "          'lambda': 100,\n",
    "          'subsample': 0.7,\n",
    "          'colsample_bytree': 0.7,\n",
    "          'colsample_bylevel': 0.7,\n",
    "          'eta': 0.03,\n",
    "          'tree_method': 'exact',\n",
    "          'seed': 2017,\n",
    "          \"num_class\": 2\n",
    "          }\n",
    "\n",
    "num_round = 10000\n",
    "early_stopping_rounds = 100\n",
    "watchlist = [(train_matrix, 'train'),\n",
    "             (test_matrix, 'eval')\n",
    "             ]\n",
    "\n",
    "model = clf.train(params,\n",
    "                  train_matrix,\n",
    "                  num_boost_round=num_round,\n",
    "                  evals=watchlist,\n",
    "                  early_stopping_rounds=early_stopping_rounds\n",
    "                  )\n",
    "pre = model.predict(z,ntree_limit=model.best_ntree_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score :  0.9275\n"
     ]
    }
   ],
   "source": [
    "print('score : ', np.mean((pre[:,1]>0.3)==y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自己封装模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking,Bootstrap,Bagging技术实践"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    导入相关包\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SBBTree():\n",
    "    \"\"\"\n",
    "        SBBTree\n",
    "        Stacking,Bootstap,Bagging\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "                    self, \n",
    "                    params,\n",
    "                    stacking_num,\n",
    "                    bagging_num,\n",
    "                    bagging_test_size,\n",
    "                    num_boost_round,\n",
    "                    #early_stopping_rounds\n",
    "                    callbacks\n",
    "                ):\n",
    "        \"\"\"\n",
    "            Initializes the SBBTree.\n",
    "            Args:\n",
    "              params : lgb params.\n",
    "              stacking_num : k_flod stacking.\n",
    "              bagging_num : bootstrap num.\n",
    "              bagging_test_size : bootstrap sample rate.\n",
    "              num_boost_round : boost num.\n",
    "              early_stopping_rounds : early_stopping_rounds.\n",
    "        \"\"\"\n",
    "        self.params = params\n",
    "        self.stacking_num = stacking_num\n",
    "        self.bagging_num = bagging_num\n",
    "        self.bagging_test_size = bagging_test_size\n",
    "        self.num_boost_round = num_boost_round\n",
    "        #self.early_stopping_rounds = early_stopping_rounds\n",
    "        self.callbacks = callbacks\n",
    "\n",
    "        self.model = lgb\n",
    "        self.stacking_model = []\n",
    "        self.bagging_model = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\" fit model. \"\"\"\n",
    "        if self.stacking_num > 1:\n",
    "            layer_train = np.zeros((X.shape[0], 2))\n",
    "            self.SK = StratifiedKFold(n_splits=self.stacking_num, shuffle=True, random_state=1)\n",
    "            for k,(train_index, test_index) in enumerate(self.SK.split(X, y)):\n",
    "                X_train = X[train_index]\n",
    "                y_train = y[train_index]\n",
    "                X_test = X[test_index]\n",
    "                y_test = y[test_index]\n",
    "\n",
    "                lgb_train = lgb.Dataset(X_train, y_train)\n",
    "                lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
    "\n",
    "                gbm = lgb.train(self.params,\n",
    "                            lgb_train,\n",
    "                            num_boost_round=self.num_boost_round,\n",
    "                            valid_sets=lgb_eval,\n",
    "                            #early_stopping_rounds=self.early_stopping_rounds\n",
    "                            callbacks=self.callbacks\n",
    "                            )\n",
    "\n",
    "                self.stacking_model.append(gbm)\n",
    "\n",
    "                pred_y = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
    "                layer_train[test_index, 1] = pred_y\n",
    "\n",
    "            X = np.hstack((X, layer_train[:,1].reshape((-1,1)))) \n",
    "        else:\n",
    "            pass\n",
    "        for bn in range(self.bagging_num):\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=self.bagging_test_size, random_state=bn)\n",
    "\n",
    "            lgb_train = lgb.Dataset(X_train, y_train)\n",
    "            lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
    "\n",
    "            callbacks=[lightgbm.early_stopping(stopping_rounds=200)]\n",
    "\n",
    "            gbm = lgb.train(self.params,\n",
    "                        lgb_train,\n",
    "                        num_boost_round=10000,\n",
    "                        valid_sets=lgb_eval,\n",
    "                        #early_stopping_rounds=200\n",
    "                        callbacks=[lightgbm.early_stopping(stopping_rounds=200)]\n",
    "                        )\n",
    "\n",
    "            self.bagging_model.append(gbm)\n",
    "\n",
    "    def predict(self, X_pred):\n",
    "        \"\"\" predict test data. \"\"\"\n",
    "        if self.stacking_num > 1:\n",
    "            test_pred = np.zeros((X_pred.shape[0], self.stacking_num))\n",
    "            for sn,gbm in enumerate(self.stacking_model):\n",
    "                pred = gbm.predict(X_pred, num_iteration=gbm.best_iteration)\n",
    "                test_pred[:, sn] = pred\n",
    "            X_pred = np.hstack((X_pred, test_pred.mean(axis=1).reshape((-1,1))))  \n",
    "        else:\n",
    "            pass \n",
    "        for bn,gbm in enumerate(self.bagging_model):\n",
    "            pred = gbm.predict(X_pred, num_iteration=gbm.best_iteration)\n",
    "            if bn == 0:\n",
    "                pred_out=pred\n",
    "            else:\n",
    "                pred_out+=pred\n",
    "        return pred_out/self.bagging_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试自己封装的模型类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[565]\tvalid_0's auc: 0.761952\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[598]\tvalid_0's auc: 0.789344\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[480]\tvalid_0's auc: 0.808629\n",
      "pred\n",
      "[0.12]\n",
      "TEST 1 ok\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[259]\tvalid_0's auc: 0.75051\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[259]\tvalid_0's auc: 0.75051\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[401]\tvalid_0's auc: 0.769037\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[368]\tvalid_0's auc: 0.766177\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[785]\tvalid_0's auc: 0.834114\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[452]\tvalid_0's auc: 0.753342\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[550]\tvalid_0's auc: 0.787433\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[730]\tvalid_0's auc: 0.803699\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[291]\tvalid_0's auc: 0.789216\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.756547\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[785]\tvalid_0's auc: 0.834114\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[452]\tvalid_0's auc: 0.753342\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[550]\tvalid_0's auc: 0.787433\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[730]\tvalid_0's auc: 0.803699\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[291]\tvalid_0's auc: 0.789216\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.756547\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\tvalid_0's auc: 0.764161\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[49]\tvalid_0's auc: 0.806934\n",
      "auc:  0.7107286034793483\n",
      "auc:  0.7791754018169113\n",
      "auc:  0.7681783074037294\n",
      "auc:  0.7900989370701387\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    TEST CODE\n",
    "\"\"\"\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.datasets import make_gaussian_quantiles\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "# X, y = make_classification(n_samples=1000, n_features=25, n_clusters_per_class=1, n_informative=15, random_state=1)\n",
    "X, y = make_gaussian_quantiles(mean=None, cov=1.0, n_samples=1000, n_features=50, n_classes=2, shuffle=True, random_state=2)\n",
    "# data = load_breast_cancer()\n",
    "# X, y = data.data, data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "params = {\n",
    "        'task': 'train',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'num_leaves': 9,\n",
    "        'learning_rate': 0.03,\n",
    "        'feature_fraction_seed': 2,\n",
    "        'feature_fraction': 0.9,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'min_data': 20,\n",
    "        'min_hessian': 1,\n",
    "        'verbose': -1,\n",
    "        'silent': 0\n",
    "        }\n",
    "# test 1\n",
    "#model = SBBTree(params=params, stacking_num=2, bagging_num=1,  bagging_test_size=0.33, num_boost_round=10000, early_stopping_rounds=200)\n",
    "model = SBBTree(params=params, stacking_num=2, bagging_num=1,  bagging_test_size=0.33, num_boost_round=10000, callbacks=[lightgbm.early_stopping(stopping_rounds=200)])\n",
    "model.fit(X,y)\n",
    "X_pred = X[0].reshape((1,-1))\n",
    "pred=model.predict(X_pred)\n",
    "print('pred')\n",
    "print(pred)\n",
    "print('TEST 1 ok')\n",
    "\n",
    "\n",
    "# test 1\n",
    "model = SBBTree(params, stacking_num=1, bagging_num=1, bagging_test_size=0.33, num_boost_round=10000, callbacks=[lightgbm.early_stopping(stopping_rounds=200)])\n",
    "model.fit(X_train,y_train)\n",
    "pred1=model.predict(X_test)\n",
    "\n",
    "# test 2 \n",
    "model = SBBTree(params, stacking_num=1, bagging_num=3, bagging_test_size=0.33, num_boost_round=10000, callbacks=[lightgbm.early_stopping(stopping_rounds=200)])\n",
    "model.fit(X_train,y_train)\n",
    "pred2=model.predict(X_test)\n",
    "\n",
    "# test 3 \n",
    "model = SBBTree(params, stacking_num=5, bagging_num=1, bagging_test_size=0.33, num_boost_round=10000, callbacks=[lightgbm.early_stopping(stopping_rounds=200)])\n",
    "model.fit(X_train,y_train)\n",
    "pred3=model.predict(X_test)\n",
    "\n",
    "# test 4 \n",
    "model = SBBTree(params, stacking_num=5, bagging_num=3, bagging_test_size=0.33, num_boost_round=10000, callbacks=[lightgbm.early_stopping(stopping_rounds=200)])\n",
    "model.fit(X_train,y_train)\n",
    "pred4=model.predict(X_test)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test+1, pred1, pos_label=2)\n",
    "print('auc: ',metrics.auc(fpr, tpr))\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test+1, pred2, pos_label=2)\n",
    "print('auc: ',metrics.auc(fpr, tpr))\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test+1, pred3, pos_label=2)\n",
    "print('auc: ',metrics.auc(fpr, tpr))\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test+1, pred4, pos_label=2)\n",
    "print('auc: ',metrics.auc(fpr, tpr))\n",
    "\n",
    "\n",
    "# auc:  0.7281621243885396\n",
    "# auc:  0.7710471146419509\n",
    "# auc:  0.7894369046305492\n",
    "# auc:  0.8084519474787597"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 天猫复购场景实战"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取特征数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "train_data = pd.read_csv('./data/train_all.csv',nrows=10000)\n",
    "test_data = pd.read_csv('./data/test_all.csv',nrows=100)\n",
    "\n",
    "features_columns = [col for col in train_data.columns if col not in ['user_id','label']]\n",
    "train = train_data[features_columns].values\n",
    "test = test_data[features_columns].values\n",
    "target =train_data['label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 设置模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "        'task': 'train',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'num_leaves': 9,\n",
    "        'learning_rate': 0.03,\n",
    "        'feature_fraction_seed': 2,\n",
    "        'feature_fraction': 0.9,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'min_data': 20,\n",
    "        'min_hessian': 1,\n",
    "        'verbose': -1,\n",
    "        'silent': 0\n",
    "        }\n",
    "\n",
    "model = SBBTree(params=params,\n",
    "                stacking_num=5,\n",
    "                bagging_num=3,\n",
    "                bagging_test_size=0.33,\n",
    "                num_boost_round=10000,\n",
    "                #early_stopping_rounds=200\n",
    "                callbacks=[lightgbm.early_stopping(stopping_rounds=200)]\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's auc: 0.651375\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1375]\tvalid_0's auc: 0.742925\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[805]\tvalid_0's auc: 0.671731\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\tvalid_0's auc: 0.725797\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's auc: 0.56442\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1177]\tvalid_0's auc: 0.668016\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[214]\tvalid_0's auc: 0.616207\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's auc: 0.558366\n"
     ]
    }
   ],
   "source": [
    "model.fit(train, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>predict_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105600</td>\n",
       "      <td>0.034984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110976</td>\n",
       "      <td>0.030769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>374400</td>\n",
       "      <td>0.038566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>189312</td>\n",
       "      <td>0.042045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>189312</td>\n",
       "      <td>0.038282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  predict_prob\n",
       "0   105600      0.034984\n",
       "1   110976      0.030769\n",
       "2   374400      0.038566\n",
       "3   189312      0.042045\n",
       "4   189312      0.038282"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(test)\n",
    "df_out = pd.DataFrame()\n",
    "df_out['user_id'] = test_data['user_id'].astype(int)\n",
    "df_out['predict_prob'] = pred\n",
    "df_out.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save OK!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    保留数据头，不保存index\n",
    "\"\"\"\n",
    "df_out.to_csv('./data/df_out.csv',header=True,index=False)\n",
    "print('save OK!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !head df_out.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
