{"cells":[{"cell_type":"markdown","metadata":{},"source":["# 1 基础代码"]},{"cell_type":"markdown","metadata":{},"source":["## 1.1 导入相关库"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\") "]},{"cell_type":"markdown","metadata":{},"source":["## 1.2 读取数据"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# 训练数据前 10000行，测试数据前100条\n","train_data = pd.read_csv('./data/train_all.csv',nrows=10000)\n","test_data = pd.read_csv('./data/test_all.csv',nrows=100)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# 读取全部数据\n","# train_data = pd.read_csv('train_all.csv',nrows=None)\n","# test_data = pd.read_csv('test_all.csv',nrows=None)"]},{"cell_type":"markdown","metadata":{},"source":["## 1.3 获取训练和测试数据"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["features_columns = [col for col in train_data.columns if col not in ['user_id','label']]\n","train = train_data[features_columns].values\n","test = test_data[features_columns].values\n","target =train_data['label'].values"]},{"cell_type":"markdown","metadata":{},"source":["# 2 缺失值补全"]},{"cell_type":"markdown","metadata":{},"source":["处理缺失值有很多方法，最常用为以下几种：\n","1. 删除。当数据量较大时，或者缺失数据占比较小时，可以使用这种方法。\n","2. 填充。通用的方法是采用平均数、中位数来填充，可以适用插值或者模型预测的方法进行缺失补全。\n","3. 不处理。树类模型对缺失值不明感。"]},{"cell_type":"markdown","metadata":{},"source":["#### 采用中值进行填充"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# from sklearn.preprocessing import Imputer\n","# imputer = Imputer(strategy=\"median\")\n","\n","from sklearn.impute import SimpleImputer\n","\n","imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n","imputer = imputer.fit(train)\n","train_imputer = imputer.transform(train)\n","test_imputer = imputer.transform(test)"]},{"cell_type":"markdown","metadata":{},"source":["# 3 特征选择"]},{"cell_type":"markdown","metadata":{},"source":["下面将采用前面提到的方法来进行特征选择，然后通过以下代码对比特征选择前后模型的性能。"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import cross_val_score\n","from sklearn.ensemble import RandomForestClassifier\n","\n","def feature_selection(train, train_sel, target):\n","    clf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0, n_jobs=-1)\n","    \n","    scores = cross_val_score(clf, train, target, cv=5)\n","    scores_sel = cross_val_score(clf, train_sel, target, cv=5)\n","    \n","    print(\"No Select Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))     \n","    print(\"Features Select Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"]},{"cell_type":"markdown","metadata":{},"source":["## 3.1删除方差较小的要素\n","VarianceThreshold是一种简单的基线特征选择方法。它会删除方差不符合某个阈值的所有要素。默认情况下，它会删除所有零方差要素，即在所有样本中具有相同值的要素。"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["训练数据未特征筛选维度 (8455, 229)\n","训练数据特征筛选维度后 (8455, 24)\n"]}],"source":["from sklearn.feature_selection import VarianceThreshold\n","\n","sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n","sel = sel.fit(train)\n","train_sel = sel.transform(train)\n","test_sel = sel.transform(test)\n","print('训练数据未特征筛选维度', train.shape)\n","print('训练数据特征筛选维度后', train_sel.shape)"]},{"cell_type":"markdown","metadata":{},"source":["特征选择前后区别"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["No Select Accuracy: 0.93 (+/- 0.00)\n","Features Select Accuracy: 0.93 (+/- 0.00)\n"]}],"source":["feature_selection(train, train_sel, target)"]},{"cell_type":"markdown","metadata":{},"source":["## 3.2单变量特征选择\n","通过基于单变量统计检验选择最佳特征。"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["训练数据未特征筛选维度 (8455, 229)\n","训练数据特征筛选维度后 (8455, 2)\n"]}],"source":["from sklearn.feature_selection import SelectKBest\n","from sklearn.feature_selection import mutual_info_classif\n","\n","sel = SelectKBest(mutual_info_classif, k=2)\n","sel = sel.fit(train, target)\n","train_sel = sel.transform(train)\n","test_sel = sel.transform(test)\n","print('训练数据未特征筛选维度', train.shape)\n","print('训练数据特征筛选维度后', train_sel.shape)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["训练数据未特征筛选维度 (8455, 229)\n","训练数据特征筛选维度后 (8455, 10)\n"]}],"source":["sel = SelectKBest(mutual_info_classif, k=10)\n","sel = sel.fit(train, target)\n","train_sel = sel.transform(train)\n","test_sel = sel.transform(test)\n","print('训练数据未特征筛选维度', train.shape)\n","print('训练数据特征筛选维度后', train_sel.shape)"]},{"cell_type":"markdown","metadata":{},"source":["特征选择前后区别"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["No Select Accuracy: 0.93 (+/- 0.00)\n","Features Select Accuracy: 0.93 (+/- 0.00)\n"]}],"source":["feature_selection(train, train_sel, target)"]},{"cell_type":"markdown","metadata":{},"source":["## 3.3递归功能消除\n","通过递归地训练多个模型来选择特征。首先，它使用整个特征集合训练一个模型，并按照得分最低的特征的顺序依次消除特征，直到达到预定的特征数量。"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False  True\n","  True]\n","[228 227 226 224 222 219 218 216 215 214 213 212 211 210 206 205 204 203\n"," 201 199 195 192 186 178 174 171 169 168 167 165 164 163 162 160 159 158\n"," 157 156 154 153 152 151 149 148 147 145 144 143 142 140 138 137 136 135\n"," 134 133 132 131 130 129 126 125 124 122 118 117 116 115 114 113 112 111\n"," 109 107 106 105 104 103 102  95  93  91  90  79  78  75  73  72  70  69\n","  68  62  59  58  57  53  34  30  27   3   8  19   5  15   4  11  13  10\n","  16  21   2 175 179 187 181 225 223 221 220 217 183 189 207 209 208 193\n"," 197 202 200 198 196 194 191 190 188 185 184 182 180 177 176 173 172 170\n","  25 166  31 161  35  37 155  39  41 150  43 146  45 141 139  47  49  51\n","  63 127 128 119 123 121 120  81  83  85  87 110 108  97  99 101 100  98\n","  96  94  92  89  88  86  84  82  80  77  76  74  71  65  67  66  64  61\n","  60  55  56  54  52  50  48  46  44  42  40  38  36  33  32  29  28  26\n","  24  14  12   9   7   6  20  22  17  18  23   1   1]\n"]}],"source":["from sklearn.feature_selection import RFECV\n","from sklearn.ensemble import RandomForestClassifier\n","\n","clf = RandomForestClassifier(n_estimators=10, max_depth=2, random_state=0, n_jobs=-1)\n","selector = RFECV(clf, step=1, cv=2)\n","selector = selector.fit(train, target)\n","print(selector.support_)\n","print(selector.ranking_)"]},{"cell_type":"markdown","metadata":{},"source":["## 3.4使用模型选择特征"]},{"cell_type":"markdown","metadata":{},"source":["使用LR拟合的参数进行变量选择（L2范数进行特征选择），LR模型采用拟合参数形式进行变量选择，筛选对回归目标影响大的特征"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["训练数据未特征筛选维度 (8455, 229)\n","训练数据特征筛选维度后 (8455, 19)\n"]}],"source":["from sklearn.feature_selection import SelectFromModel\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.preprocessing import Normalizer\n","\n","normalizer = Normalizer()\n","normalizer = normalizer.fit(train)  \n","\n","train_norm = normalizer.transform(train)                            \n","test_norm = normalizer.transform(test)\n","\n","LR = LogisticRegression(penalty='l2',C=5)\n","LR = LR.fit(train_norm, target)\n","model = SelectFromModel(LR, prefit=True)\n","train_sel = model.transform(train)\n","test_sel = model.transform(test)\n","print('训练数据未特征筛选维度', train.shape)\n","print('训练数据特征筛选维度后', train_sel.shape)"]},{"cell_type":"markdown","metadata":{},"source":["L2范数选择参数"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/plain":["array([ 0.23210864,  0.03214927, -0.00939419,  0.85088717, -0.91507123,\n","       -0.26081965, -0.86681364,  0.57445561,  0.73849952,  0.00342517])"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["LR.coef_[0][:10]"]},{"cell_type":"markdown","metadata":{},"source":["特征选择前后区别"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["No Select Accuracy: 0.93 (+/- 0.00)\n","Features Select Accuracy: 0.93 (+/- 0.00)\n"]}],"source":["feature_selection(train, train_sel, target)"]},{"cell_type":"markdown","metadata":{},"source":["使用LR拟合的参数进行变量选择（L1范数进行特征选择），LR模型采用拟合参数形式进行变量选择，筛选对回归目标影响大的特征"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["训练数据未特征筛选维度 (8455, 229)\n","训练数据特征筛选维度后 (8455, 12)\n"]}],"source":["from sklearn.feature_selection import SelectFromModel\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.preprocessing import Normalizer\n","\n","normalizer = Normalizer()\n","normalizer = normalizer.fit(train)  \n","\n","train_norm = normalizer.transform(train)                            \n","test_norm = normalizer.transform(test)\n","\n","LR = LogisticRegression(penalty='l1',C=5,solver='liblinear')\n","LR = LR.fit(train_norm, target)\n","model = SelectFromModel(LR, prefit=True)\n","train_sel = model.transform(train)\n","test_sel = model.transform(test)\n","print('训练数据未特征筛选维度', train.shape)\n","print('训练数据特征筛选维度后', train_sel.shape)"]},{"cell_type":"markdown","metadata":{},"source":["L1范数选择参数。对于α的良好选择，只要满足某些特定条件，LASSO就可以仅使用少量观察来完全恢复精确的非零变量集。"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"text/plain":["array([0.16879959, 0.        , 0.        , 0.56714802, 0.        ,\n","       0.        , 0.        , 0.78078353, 0.        , 0.        ])"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["LR.coef_[0][:10]"]},{"cell_type":"markdown","metadata":{},"source":["特征选择前后区别"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["No Select Accuracy: 0.93 (+/- 0.00)\n","Features Select Accuracy: 0.93 (+/- 0.00)\n"]}],"source":["feature_selection(train, train_sel, target)"]},{"cell_type":"markdown","metadata":{},"source":["## 3.5基于树模型特征选择\n","树模型基于分裂评价标准所计算的总的评分作为依据进行相关排序，然后进行特征筛选"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["训练数据未特征筛选维度 (8455, 229)\n","训练数据特征筛选维度后 (8455, 72)\n"]}],"source":["from sklearn.ensemble import ExtraTreesClassifier\n","from sklearn.feature_selection import SelectFromModel\n","\n","clf = ExtraTreesClassifier(n_estimators=50)\n","clf = clf.fit(train, target)\n","\n","model = SelectFromModel(clf, prefit=True)\n","train_sel = model.transform(train)\n","test_sel = model.transform(test)\n","print('训练数据未特征筛选维度', train.shape)\n","print('训练数据特征筛选维度后', train_sel.shape)"]},{"cell_type":"markdown","metadata":{},"source":["树特征重要性"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"data":{"text/plain":["array([0.08131766, 0.01536015, 0.00893797, 0.01597656, 0.01636607,\n","       0.01680214, 0.01653297, 0.01548492, 0.01723172, 0.00725235])"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["clf.feature_importances_[:10]"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["df_features_import = pd.DataFrame()\n","df_features_import['features_import'] = clf.feature_importances_\n","df_features_import['features_name'] = features_columns"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>features_import</th>\n","      <th>features_name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.081318</td>\n","      <td>merchant_id</td>\n","    </tr>\n","    <tr>\n","      <th>228</th>\n","      <td>0.075728</td>\n","      <td>xgb_clf</td>\n","    </tr>\n","    <tr>\n","      <th>227</th>\n","      <td>0.067072</td>\n","      <td>lgb_clf</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>0.018029</td>\n","      <td>brand_most_1_cnt</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>0.017616</td>\n","      <td>seller_most_1_cnt</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>0.017317</td>\n","      <td>seller_most_1</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.017232</td>\n","      <td>time_stamp_nunique</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>0.017172</td>\n","      <td>action_type_1_cnt</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>0.017125</td>\n","      <td>cat_most_1</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>0.016890</td>\n","      <td>seller_nunique_0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.016802</td>\n","      <td>cat_nunique</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0.016614</td>\n","      <td>time_stamp_std</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.016533</td>\n","      <td>brand_nunique</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.016366</td>\n","      <td>seller_nunique</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.015977</td>\n","      <td>user_cnt</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>0.015876</td>\n","      <td>brand_most_1</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>0.015715</td>\n","      <td>user_cnt_0</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>0.015566</td>\n","      <td>user_cnt_2</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.015485</td>\n","      <td>item_nunique</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.015360</td>\n","      <td>age_range</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>0.015145</td>\n","      <td>cat_most_1_cnt</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>0.014939</td>\n","      <td>user_cnt_3</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>0.014691</td>\n","      <td>user_cnt_1</td>\n","    </tr>\n","    <tr>\n","      <th>87</th>\n","      <td>0.009245</td>\n","      <td>tfidf_60</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.008938</td>\n","      <td>gender</td>\n","    </tr>\n","    <tr>\n","      <th>86</th>\n","      <td>0.008607</td>\n","      <td>tfidf_59</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.007252</td>\n","      <td>action_type_nunique</td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>0.006752</td>\n","      <td>tfidf_15</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>0.006479</td>\n","      <td>tfidf_3</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>0.006460</td>\n","      <td>tfidf_10</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     features_import        features_name\n","0           0.081318          merchant_id\n","228         0.075728              xgb_clf\n","227         0.067072              lgb_clf\n","20          0.018029     brand_most_1_cnt\n","18          0.017616    seller_most_1_cnt\n","14          0.017317        seller_most_1\n","8           0.017232   time_stamp_nunique\n","21          0.017172    action_type_1_cnt\n","15          0.017125           cat_most_1\n","26          0.016890     seller_nunique_0\n","5           0.016802          cat_nunique\n","12          0.016614       time_stamp_std\n","6           0.016533        brand_nunique\n","4           0.016366       seller_nunique\n","3           0.015977             user_cnt\n","16          0.015876         brand_most_1\n","22          0.015715           user_cnt_0\n","24          0.015566           user_cnt_2\n","7           0.015485         item_nunique\n","1           0.015360            age_range\n","19          0.015145       cat_most_1_cnt\n","25          0.014939           user_cnt_3\n","23          0.014691           user_cnt_1\n","87          0.009245             tfidf_60\n","2           0.008938               gender\n","86          0.008607             tfidf_59\n","9           0.007252  action_type_nunique\n","42          0.006752             tfidf_15\n","30          0.006479              tfidf_3\n","37          0.006460             tfidf_10"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["df_features_import.sort_values(['features_import'],ascending=0).head(30)"]},{"cell_type":"markdown","metadata":{},"source":["特征选择前后区别"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["No Select Accuracy: 0.93 (+/- 0.00)\n","Features Select Accuracy: 0.93 (+/- 0.00)\n"]}],"source":["feature_selection(train, train_sel, target)"]},{"cell_type":"markdown","metadata":{},"source":["## 3.6 Lgb特征重要性\n","利用LGB模型进行特征选择："]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: tree_method\n","[LightGBM] [Warning] Unknown parameter: silent\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: tree_method\n","[LightGBM] [Warning] Unknown parameter: silent\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002200 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 14861\n","[LightGBM] [Info] Number of data points in the train set: 5073, number of used features: 128\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: tree_method\n","[LightGBM] [Warning] Unknown parameter: silent\n","[LightGBM] [Info] Start training from score -0.073183\n","[LightGBM] [Info] Start training from score -2.651155\n","Training until validation scores don't improve for 100 rounds\n","Early stopping, best iteration is:\n","[41]\tvalid_0's multi_logloss: 0.236027\n"]}],"source":["import lightgbm\n","from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(train, target, test_size=0.4, random_state=0)\n","\n","clf = lightgbm\n","\n","train_matrix = clf.Dataset(X_train, label=y_train)\n","test_matrix = clf.Dataset(X_test, label=y_test)\n","params = {\n","          'boosting_type': 'gbdt',\n","          #'boosting_type': 'dart',\n","          'objective': 'multiclass',\n","          'metric': 'multi_logloss',\n","          'min_child_weight': 1.5,\n","          'num_leaves': 2**5,\n","          'lambda_l2': 10,\n","          'subsample': 0.7,\n","          'colsample_bytree': 0.7,\n","          'colsample_bylevel': 0.7,\n","          'learning_rate': 0.03,\n","          'tree_method': 'exact',\n","          'seed': 2017,\n","          \"num_class\": 2,\n","          'silent': True,\n","          }\n","num_round = 10000\n","early_stopping_rounds = 100\n","model = clf.train(params, \n","                  train_matrix,\n","                  num_round,\n","                  valid_sets=test_matrix,\n","                  callbacks=[lightgbm.early_stopping(stopping_rounds=100)])"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["def lgb_transform(train, test, model, topK):\n","    train_df = pd.DataFrame(train)\n","    train_df.columns = range(train.shape[1])\n","    \n","    test_df = pd.DataFrame(test)\n","    test_df.columns = range(test.shape[1])\n","    \n","    features_import = pd.DataFrame()\n","    features_import['importance'] = model.feature_importance()\n","    features_import['col'] = range(train.shape[1])\n","    \n","    features_import = features_import.sort_values(['importance'],ascending=0).head(topK)\n","    sel_col = list(features_import.col)\n","    \n","    train_sel = train_df[sel_col]\n","    test_sel = test_df[sel_col]\n","    return train_sel, test_sel"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["训练数据未特征筛选维度 (8455, 229)\n","训练数据特征筛选维度后 (8455, 20)\n"]}],"source":["train_sel, test_sel = lgb_transform(train, test, model, 20)\n","print('训练数据未特征筛选维度', train.shape)\n","print('训练数据特征筛选维度后', train_sel.shape)"]},{"cell_type":"markdown","metadata":{},"source":["lgb特征重要性"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"data":{"text/plain":["array([ 85,  29,   7,  69, 103,  98,  68,  40, 124,   2])"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["model.feature_importance()[:10]"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["#sorted(model.feature_importance(),reverse=True)[:10]"]},{"cell_type":"markdown","metadata":{},"source":["特征选择前后区别"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["No Select Accuracy: 0.93 (+/- 0.00)\n","Features Select Accuracy: 0.93 (+/- 0.00)\n"]}],"source":["feature_selection(train, train_sel, target)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"mlenv","language":"python","name":"mlenv"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"latex_envs":{"LaTeX_envs_menu_present":true,"autoclose":false,"autocomplete":true,"bibliofile":"biblio.bib","cite_by":"apalike","current_citInitial":1,"eqLabelWithNumbers":true,"eqNumInitial":1,"hotkeys":{"equation":"Ctrl-E","itemize":"Ctrl-I"},"labels_anchors":false,"latex_user_defs":false,"report_style_numbering":false,"user_envs_cfg":false}},"nbformat":4,"nbformat_minor":4}
