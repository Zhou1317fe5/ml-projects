{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"},"language_info":{"name":"python","version":"3.7.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"latex_envs":{"LaTeX_envs_menu_present":true,"autoclose":false,"autocomplete":true,"bibliofile":"biblio.bib","cite_by":"apalike","current_citInitial":1,"eqLabelWithNumbers":true,"eqNumInitial":1,"hotkeys":{"equation":"Ctrl-E","itemize":"Ctrl-I"},"labels_anchors":false,"latex_user_defs":false,"report_style_numbering":false,"user_envs_cfg":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 导入相关包","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport warnings\nwarnings.filterwarnings(\"ignore\") ","metadata":{},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## 读取数据（训练数据前10000行，测试数据前100条）","metadata":{}},{"cell_type":"code","source":"train_data = pd.read_csv('train_all.csv',nrows=10000)\ntest_data = pd.read_csv('test_all.csv',nrows=100)","metadata":{},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## 读取全部数据","metadata":{}},{"cell_type":"code","source":"# train_data = pd.read_csv('train_all.csv',nrows=None)\n# test_data = pd.read_csv('test_all.csv',nrows=None)","metadata":{},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## 获取训练和测试数据","metadata":{}},{"cell_type":"code","source":"features_columns = [col for col in train_data.columns if col not in ['user_id','label']]\ntrain = train_data[features_columns].values\ntest = test_data[features_columns].values\ntarget =train_data['label'].values","metadata":{},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## 缺失值补全","metadata":{}},{"cell_type":"markdown","source":"处理缺失值有很多方法，最常用为以下几种：\n1. 删除。当数据量较大时，或者缺失数据占比较小时，可以使用这种方法。\n2. 填充。通用的方法是采用平均数、中位数来填充，可以适用插值或者模型预测的方法进行缺失补全。\n3. 不处理。树类模型对缺失值不明感。","metadata":{}},{"cell_type":"markdown","source":"#### 采用中值进行填充","metadata":{}},{"cell_type":"code","source":"# from sklearn.preprocessing import Imputer\n# imputer = Imputer(strategy=\"median\")\n\nfrom sklearn.impute import SimpleImputer\n\nimputer = SimpleImputer(missing_values=np.nan, strategy='mean')\nimputer = imputer.fit(train)\ntrain_imputer = imputer.transform(train)\ntest_imputer = imputer.transform(test)","metadata":{},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"outputs":[]},{"cell_type":"markdown","source":"## 特征选择概念","metadata":{}},{"cell_type":"markdown","source":"在机器学习和统计学中，特征选择（英语：feature selection）也被称为变量选择、属性选择 或变量子集选择 。它是指：为了构建模型而选择相关特征（即属性、指标）子集的过程。使用特征选择技术有三个原因：\n\n    简化模型，使之更易于被研究人员或用户理解，\n    缩短训练时间，\n    改善通用性、降低过拟合（即降低方差）。\n\n要使用特征选择技术的关键假设是：训练数据包含许多冗余 或无关 的特征，因而移除这些特征并不会导致丢失信息。 冗余 或无关 特征是两个不同的概念。如果一个特征本身有用，但如果这个特征与另一个有用特征强相关，且那个特征也出现在数据中，那么这个特征可能就变得多余。\n特征选择技术与特征提取有所不同。特征提取是从原有特征的功能中创造新的特征，而特征选择则只返回原有特征中的子集。 特征选择技术的常常用于许多特征但样本（即数据点）相对较少的领域。特征选择应用的典型用例包括：解析书面文本和微阵列数据，这些场景下特征成千上万，但样本只有几十到几百个。","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\n\ndef feature_selection(train, train_sel, target):\n    clf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0, n_jobs=-1)\n    \n    scores = cross_val_score(clf, train, target, cv=5)\n    scores_sel = cross_val_score(clf, train_sel, target, cv=5)\n    \n    print(\"No Select Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))     \n    print(\"Features Select Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))","metadata":{},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"### 删除方差较小的要素（方法一）\nVarianceThreshold是一种简单的基线特征选择方法。它会删除方差不符合某个阈值的所有要素。默认情况下，它会删除所有零方差要素，即在所有样本中具有相同值的要素。","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_selection import VarianceThreshold\n\nsel = VarianceThreshold(threshold=(.8 * (1 - .8)))\nsel = sel.fit(train)\ntrain_sel = sel.transform(train)\ntest_sel = sel.transform(test)\nprint('训练数据未特征筛选维度', train.shape)\nprint('训练数据特征筛选维度后', train_sel.shape)","metadata":{},"execution_count":7,"outputs":[{"name":"stdout","output_type":"stream","text":"训练数据未特征筛选维度 (2000, 229)\n\n训练数据特征筛选维度后 (2000, 29)\n"}]},{"cell_type":"code","source":"","metadata":{},"outputs":[]},{"cell_type":"markdown","source":"### 特征选择前后区别","metadata":{}},{"cell_type":"code","source":"feature_selection(train, train_sel, target)","metadata":{},"execution_count":8,"outputs":[{"name":"stdout","output_type":"stream","text":"No Select Accuracy: 0.93 (+/- 0.00)\n\nFeatures Select Accuracy: 0.93 (+/- 0.00)\n"}]},{"cell_type":"markdown","source":"### 单变量特征选择（方法二）\n通过基于单变量统计检验选择最佳特征。","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_selection import SelectKBest\n# from sklearn.feature_selection import chi2\nfrom sklearn.feature_selection import mutual_info_classif\n\nsel = SelectKBest(mutual_info_classif, k=2)\nsel = sel.fit(train, target)\ntrain_sel = sel.transform(train)\ntest_sel = sel.transform(test)\nprint('训练数据未特征筛选维度', train.shape)\nprint('训练数据特征筛选维度后', train_sel.shape)","metadata":{},"execution_count":9,"outputs":[{"name":"stdout","output_type":"stream","text":"训练数据未特征筛选维度 (2000, 229)\n\n训练数据特征筛选维度后 (2000, 2)\n"}]},{"cell_type":"code","source":"sel = SelectKBest(mutual_info_classif, k=10)\nsel = sel.fit(train, target)\ntrain_sel = sel.transform(train)\ntest_sel = sel.transform(test)\nprint('训练数据未特征筛选维度', train.shape)\nprint('训练数据特征筛选维度后', train_sel.shape)","metadata":{},"execution_count":10,"outputs":[{"name":"stdout","output_type":"stream","text":"训练数据未特征筛选维度 (2000, 229)\n\n训练数据特征筛选维度后 (2000, 10)\n"}]},{"cell_type":"code","source":"","metadata":{},"outputs":[]},{"cell_type":"markdown","source":"### 特征选择前后区别","metadata":{}},{"cell_type":"code","source":"feature_selection(train, train_sel, target)","metadata":{},"execution_count":11,"outputs":[{"name":"stdout","output_type":"stream","text":"No Select Accuracy: 0.93 (+/- 0.00)\n\nFeatures Select Accuracy: 0.93 (+/- 0.00)\n"}]},{"cell_type":"markdown","source":"### 递归功能消除（方法三）\n选定模型拟合，进行递归拟合，每次把评分低得特征去除，重复上诉循环。","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_selection import RFECV\nfrom sklearn.ensemble import RandomForestClassifier\n\nclf = RandomForestClassifier(n_estimators=10, max_depth=2, random_state=0, n_jobs=-1)\nselector = RFECV(clf, step=1, cv=2)\nselector = selector.fit(train, target)\nprint(selector.support_)\nprint(selector.ranking_)","metadata":{},"execution_count":12,"outputs":[{"name":"stdout","output_type":"stream","text":"[False False False False False False False False False False False False\n\n False False False False False False False False False False False False\n\n False False False False False False False False False False False False\n\n False False False False False False False False False False False False\n\n False False False False False False False False False False False False\n\n False False False False False False False False False False False False\n\n False False False False False False False False False False False False\n\n False False False False False False False False False False False False\n\n False False False False False False False False False False False False\n\n False False False False False False False False False False False False\n\n False False False False False False False False False False False False\n\n False False False False False False False False False False False False\n\n False False False False False False False False False False False False\n\n False False False False False False False False False False False False\n\n False False False False False False False False False False False  True\n\n  True False False False False False False False False False False  True\n\n False  True False False False False  True False False  True False False\n\n False  True False  True False  True False  True False False False False\n\n False False False False False False False False False False False False\n\n False]\n\n[220 219 218 217 216 215 213 212 211 210 209 208 207 206 205 204 203 202\n\n 201 200 197 195 192 187 186 185 184 183 182 181 180 179 178 177 176 175\n\n 174 173 172 171 170 169 168 167 166 165 164 163 162 161 160 158 157 155\n\n 154 153 152 151 150 149 148 147 146 145 144 143 142 141 140 139 137 136\n\n 134 133 132 131 130 129 128 127 126 125 124 123 122 121 120 117 116 115\n\n 114 113 112 111 110 109 108 107 106 105 104 103 102 101 100  99  98  97\n\n  95  94  93  92  91  90  89  88  87 214  86  85  84  83 189 193 199 198\n\n 196 194 191 190 188  81  80  79  77  74  73  72  71  69  68  67  66  65\n\n  64 156  63  61  60  59  58  57  55  54 138 135  50  48  46  45  44  42\n\n  39 119 118  38  35  31  28  25  24  22  17  15  14  96  13  12  43   1\n\n   1   4  82  75  78  76  26  30  70  20   7   1  62   1  51  53  49  47\n\n   1  27  41   1  23  21  18   1  11   1  19   1   6   1   8  29   2   5\n\n  10   3   9  16  32  33  34  36  37  40  52  56 159]\n"}]},{"cell_type":"code","source":"","metadata":{},"outputs":[]},{"cell_type":"markdown","source":"### 使用模型选择特征（方法四）","metadata":{}},{"cell_type":"markdown","source":"#### 使用LR拟合的参数进行变量选择（L2范数进行特征选择）\nLR模型采用拟合参数形式进行变量选择，筛选对回归目标影响大的","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_selection import SelectFromModel\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import Normalizer\n\nnormalizer = Normalizer()\nnormalizer = normalizer.fit(train)  \n\ntrain_norm = normalizer.transform(train)                            \ntest_norm = normalizer.transform(test)\n\nLR = LogisticRegression(penalty='l2',C=5)\nLR = LR.fit(train_norm, target)\nmodel = SelectFromModel(LR, prefit=True)\ntrain_sel = model.transform(train)\ntest_sel = model.transform(test)\nprint('训练数据未特征筛选维度', train.shape)\nprint('训练数据特征筛选维度后', train_sel.shape)","metadata":{},"execution_count":13,"outputs":[{"name":"stdout","output_type":"stream","text":"训练数据未特征筛选维度 (2000, 229)\n\n训练数据特征筛选维度后 (2000, 19)\n"}]},{"cell_type":"code","source":"","metadata":{},"outputs":[]},{"cell_type":"markdown","source":"##### L2范数选择参数","metadata":{}},{"cell_type":"code","source":"LR.coef_[0][:10]","metadata":{},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":["array([ 0.27519508, -0.02736226, -0.00522652,  0.90644126, -0.4310027 ,\n","       -0.25110925, -0.4058899 ,  0.29059019,  0.10568508, -0.02731211])"]},"metadata":{}}]},{"cell_type":"markdown","source":"### 特征选择前后区别","metadata":{}},{"cell_type":"code","source":"feature_selection(train, train_sel, target)","metadata":{},"execution_count":15,"outputs":[{"name":"stdout","output_type":"stream","text":"No Select Accuracy: 0.93 (+/- 0.00)\n\nFeatures Select Accuracy: 0.93 (+/- 0.00)\n"}]},{"cell_type":"markdown","source":"#### 使用LR拟合的参数进行变量选择（L1范数进行特征选择）\nLR模型采用拟合参数形式进行变量选择，筛选对回归目标影响大的","metadata":{}},{"cell_type":"code","source":"# from sklearn.feature_selection import SelectFromModel\n# from sklearn.linear_model import LogisticRegression\n# from sklearn.preprocessing import Normalizer\n\n# normalizer = Normalizer()\n# normalizer = normalizer.fit(train)  \n\n# train_norm = normalizer.transform(train)                            \n# test_norm = normalizer.transform(test)\n\n# LR = LogisticRegression(penalty='l1',C=5)\n# LR = LR.fit(train_norm, target)\n# model = SelectFromModel(LR, prefit=True)\n# train_sel = model.transform(train)\n# test_sel = model.transform(test)\n# print('训练数据未特征筛选维度', train.shape)\n# print('训练数据特征筛选维度后', train_sel.shape)","metadata":{},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"##### L1范数选择参数\n对于α的良好选择，只要满足某些特定条件，Lasso就可以仅使用少量观察来完全恢复精确的非零变量集。","metadata":{}},{"cell_type":"code","source":"# LR.coef_[0][:10]","metadata":{},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"### 特征选择前后区别","metadata":{}},{"cell_type":"code","source":"feature_selection(train, train_sel, target)","metadata":{},"execution_count":18,"outputs":[{"name":"stdout","output_type":"stream","text":"No Select Accuracy: 0.93 (+/- 0.00)\n\nFeatures Select Accuracy: 0.93 (+/- 0.00)\n"}]},{"cell_type":"markdown","source":"### 基于树模型特征选择\n树模型基于分裂评价标准所计算的总的评分作为依据进行相关排序，然后进行特征筛选","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.feature_selection import SelectFromModel\n\nclf = ExtraTreesClassifier(n_estimators=50)\nclf = clf.fit(train, target)\n\nmodel = SelectFromModel(clf, prefit=True)\ntrain_sel = model.transform(train)\ntest_sel = model.transform(test)\nprint('训练数据未特征筛选维度', train.shape)\nprint('训练数据特征筛选维度后', train_sel.shape)","metadata":{},"execution_count":19,"outputs":[{"name":"stdout","output_type":"stream","text":"训练数据未特征筛选维度 (2000, 229)\n\n训练数据特征筛选维度后 (2000, 71)\n"}]},{"cell_type":"markdown","source":"#### 树特征重要性","metadata":{}},{"cell_type":"code","source":"clf.feature_importances_[:10]","metadata":{},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":["array([0.09210871, 0.00578114, 0.00388741, 0.0047027 , 0.00324662,\n","       0.00409547, 0.00560588, 0.00399393, 0.00499705, 0.00233944])"]},"metadata":{}}]},{"cell_type":"code","source":"df_features_import = pd.DataFrame()\ndf_features_import['features_import'] = clf.feature_importances_\ndf_features_import['features_name'] = features_columns","metadata":{},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"df_features_import.sort_values(['features_import'],ascending=0).head(30)","metadata":{},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>features_import</th>\n","      <th>features_name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.092109</td>\n","      <td>merchant_id</td>\n","    </tr>\n","    <tr>\n","      <th>228</th>\n","      <td>0.085244</td>\n","      <td>xgb_clf</td>\n","    </tr>\n","    <tr>\n","      <th>227</th>\n","      <td>0.056583</td>\n","      <td>lgb_clf</td>\n","    </tr>\n","    <tr>\n","      <th>199</th>\n","      <td>0.007003</td>\n","      <td>embeeding_72</td>\n","    </tr>\n","    <tr>\n","      <th>179</th>\n","      <td>0.006930</td>\n","      <td>embeeding_52</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>0.006444</td>\n","      <td>seller_most_1_cnt</td>\n","    </tr>\n","    <tr>\n","      <th>207</th>\n","      <td>0.006367</td>\n","      <td>embeeding_80</td>\n","    </tr>\n","    <tr>\n","      <th>193</th>\n","      <td>0.006110</td>\n","      <td>embeeding_66</td>\n","    </tr>\n","    <tr>\n","      <th>190</th>\n","      <td>0.006107</td>\n","      <td>embeeding_63</td>\n","    </tr>\n","    <tr>\n","      <th>132</th>\n","      <td>0.006077</td>\n","      <td>embeeding_5</td>\n","    </tr>\n","    <tr>\n","      <th>144</th>\n","      <td>0.005996</td>\n","      <td>embeeding_17</td>\n","    </tr>\n","    <tr>\n","      <th>146</th>\n","      <td>0.005913</td>\n","      <td>embeeding_19</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.005781</td>\n","      <td>age_range</td>\n","    </tr>\n","    <tr>\n","      <th>158</th>\n","      <td>0.005715</td>\n","      <td>embeeding_31</td>\n","    </tr>\n","    <tr>\n","      <th>191</th>\n","      <td>0.005701</td>\n","      <td>embeeding_64</td>\n","    </tr>\n","    <tr>\n","      <th>165</th>\n","      <td>0.005673</td>\n","      <td>embeeding_38</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>0.005648</td>\n","      <td>cat_most_1</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.005606</td>\n","      <td>brand_nunique</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>0.005488</td>\n","      <td>user_cnt_0</td>\n","    </tr>\n","    <tr>\n","      <th>220</th>\n","      <td>0.005485</td>\n","      <td>embeeding_93</td>\n","    </tr>\n","    <tr>\n","      <th>166</th>\n","      <td>0.005473</td>\n","      <td>embeeding_39</td>\n","    </tr>\n","    <tr>\n","      <th>87</th>\n","      <td>0.005472</td>\n","      <td>tfidf_60</td>\n","    </tr>\n","    <tr>\n","      <th>127</th>\n","      <td>0.005463</td>\n","      <td>embeeding_0</td>\n","    </tr>\n","    <tr>\n","      <th>196</th>\n","      <td>0.005427</td>\n","      <td>embeeding_69</td>\n","    </tr>\n","    <tr>\n","      <th>205</th>\n","      <td>0.005407</td>\n","      <td>embeeding_78</td>\n","    </tr>\n","    <tr>\n","      <th>147</th>\n","      <td>0.005402</td>\n","      <td>embeeding_20</td>\n","    </tr>\n","    <tr>\n","      <th>163</th>\n","      <td>0.005347</td>\n","      <td>embeeding_36</td>\n","    </tr>\n","    <tr>\n","      <th>192</th>\n","      <td>0.005328</td>\n","      <td>embeeding_65</td>\n","    </tr>\n","    <tr>\n","      <th>169</th>\n","      <td>0.005280</td>\n","      <td>embeeding_42</td>\n","    </tr>\n","    <tr>\n","      <th>50</th>\n","      <td>0.005277</td>\n","      <td>tfidf_23</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     features_import      features_name\n","0           0.092109        merchant_id\n","228         0.085244            xgb_clf\n","227         0.056583            lgb_clf\n","199         0.007003       embeeding_72\n","179         0.006930       embeeding_52\n","18          0.006444  seller_most_1_cnt\n","207         0.006367       embeeding_80\n","193         0.006110       embeeding_66\n","190         0.006107       embeeding_63\n","132         0.006077        embeeding_5\n","144         0.005996       embeeding_17\n","146         0.005913       embeeding_19\n","1           0.005781          age_range\n","158         0.005715       embeeding_31\n","191         0.005701       embeeding_64\n","165         0.005673       embeeding_38\n","15          0.005648         cat_most_1\n","6           0.005606      brand_nunique\n","22          0.005488         user_cnt_0\n","220         0.005485       embeeding_93\n","166         0.005473       embeeding_39\n","87          0.005472           tfidf_60\n","127         0.005463        embeeding_0\n","196         0.005427       embeeding_69\n","205         0.005407       embeeding_78\n","147         0.005402       embeeding_20\n","163         0.005347       embeeding_36\n","192         0.005328       embeeding_65\n","169         0.005280       embeeding_42\n","50          0.005277           tfidf_23"]},"metadata":{}}]},{"cell_type":"code","source":"# features_columns","metadata":{},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"outputs":[]},{"cell_type":"markdown","source":"### 特征选择前后区别","metadata":{}},{"cell_type":"code","source":"feature_selection(train, train_sel, target)","metadata":{},"execution_count":24,"outputs":[{"name":"stdout","output_type":"stream","text":"No Select Accuracy: 0.93 (+/- 0.00)\n\nFeatures Select Accuracy: 0.93 (+/- 0.00)\n"}]},{"cell_type":"markdown","source":"### Lgb特征重要性","metadata":{}},{"cell_type":"code","source":"import lightgbm\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(train, target, test_size=0.4, random_state=0)\n\nclf = lightgbm\n\ntrain_matrix = clf.Dataset(X_train, label=y_train)\ntest_matrix = clf.Dataset(X_test, label=y_test)\nparams = {\n          'boosting_type': 'gbdt',\n          #'boosting_type': 'dart',\n          'objective': 'multiclass',\n          'metric': 'multi_logloss',\n          'min_child_weight': 1.5,\n          'num_leaves': 2**5,\n          'lambda_l2': 10,\n          'subsample': 0.7,\n          'colsample_bytree': 0.7,\n          'colsample_bylevel': 0.7,\n          'learning_rate': 0.03,\n          'tree_method': 'exact',\n          'seed': 2017,\n          \"num_class\": 2,\n          'silent': True,\n          }\nnum_round = 10000\nearly_stopping_rounds = 100\nmodel = clf.train(params, \n                  train_matrix,\n                  num_round,\n                  valid_sets=test_matrix,\n                  early_stopping_rounds=early_stopping_rounds)","metadata":{},"execution_count":25,"outputs":[{"name":"stdout","output_type":"stream","text":"[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n\n[LightGBM] [Warning] Unknown parameter: tree_method\n\n[LightGBM] [Warning] Unknown parameter: silent\n\n[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n\n[LightGBM] [Warning] Unknown parameter: tree_method\n\n[LightGBM] [Warning] Unknown parameter: silent\n\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006242 seconds.\n\nYou can set `force_row_wise=true` to remove the overhead.\n\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\n[LightGBM] [Info] Total Bins 32114\n\n[LightGBM] [Info] Number of data points in the train set: 1200, number of used features: 224\n\n[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n\n[LightGBM] [Warning] Unknown parameter: tree_method\n\n[LightGBM] [Warning] Unknown parameter: silent\n\n[LightGBM] [Info] Start training from score -0.068100\n\n[LightGBM] [Info] Start training from score -2.720629\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[1]\tvalid_0's multi_logloss: 0.256738\n\nTraining until validation scores don't improve for 100 rounds\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[2]\tvalid_0's multi_logloss: 0.256574\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[3]\tvalid_0's multi_logloss: 0.256518\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[4]\tvalid_0's multi_logloss: 0.25657\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[5]\tvalid_0's multi_logloss: 0.256756\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[6]\tvalid_0's multi_logloss: 0.25682\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[7]\tvalid_0's multi_logloss: 0.256989\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[8]\tvalid_0's multi_logloss: 0.257236\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[9]\tvalid_0's multi_logloss: 0.25712\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[10]\tvalid_0's multi_logloss: 0.257011\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[11]\tvalid_0's multi_logloss: 0.257042\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[12]\tvalid_0's multi_logloss: 0.257402\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[13]\tvalid_0's multi_logloss: 0.257419\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[14]\tvalid_0's multi_logloss: 0.257646\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[15]\tvalid_0's multi_logloss: 0.257552\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[16]\tvalid_0's multi_logloss: 0.257604\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[17]\tvalid_0's multi_logloss: 0.257797\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[18]\tvalid_0's multi_logloss: 0.257928\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[19]\tvalid_0's multi_logloss: 0.258142\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[20]\tvalid_0's multi_logloss: 0.25847\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[21]\tvalid_0's multi_logloss: 0.258654\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[22]\tvalid_0's multi_logloss: 0.258846\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[23]\tvalid_0's multi_logloss: 0.258962\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[24]\tvalid_0's multi_logloss: 0.258991\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[25]\tvalid_0's multi_logloss: 0.259334\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[26]\tvalid_0's multi_logloss: 0.259433\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[27]\tvalid_0's multi_logloss: 0.259912\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[28]\tvalid_0's multi_logloss: 0.260153\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[29]\tvalid_0's multi_logloss: 0.260576\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[30]\tvalid_0's multi_logloss: 0.26094\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[31]\tvalid_0's multi_logloss: 0.261198\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[32]\tvalid_0's multi_logloss: 0.26141\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[33]\tvalid_0's multi_logloss: 0.261614\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[34]\tvalid_0's multi_logloss: 0.261801\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[35]\tvalid_0's multi_logloss: 0.261931\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[36]\tvalid_0's multi_logloss: 0.262242\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[37]\tvalid_0's multi_logloss: 0.262492\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[38]\tvalid_0's multi_logloss: 0.26273\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[39]\tvalid_0's multi_logloss: 0.262855\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[40]\tvalid_0's multi_logloss: 0.263225\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[41]\tvalid_0's multi_logloss: 0.263311\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[42]\tvalid_0's multi_logloss: 0.263612\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[43]\tvalid_0's multi_logloss: 0.263937\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[44]\tvalid_0's multi_logloss: 0.264398\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[45]\tvalid_0's multi_logloss: 0.264822\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[46]\tvalid_0's multi_logloss: 0.264977\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[47]\tvalid_0's multi_logloss: 0.265401\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[48]\tvalid_0's multi_logloss: 0.265718\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[49]\tvalid_0's multi_logloss: 0.265859\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[50]\tvalid_0's multi_logloss: 0.266173\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[51]\tvalid_0's multi_logloss: 0.266544\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[52]\tvalid_0's multi_logloss: 0.266719\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[53]\tvalid_0's multi_logloss: 0.266817\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[54]\tvalid_0's multi_logloss: 0.267013\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[55]\tvalid_0's multi_logloss: 0.267385\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[56]\tvalid_0's multi_logloss: 0.267389\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[57]\tvalid_0's multi_logloss: 0.267662\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[58]\tvalid_0's multi_logloss: 0.267792\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[59]\tvalid_0's multi_logloss: 0.268017\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[60]\tvalid_0's multi_logloss: 0.268158\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[61]\tvalid_0's multi_logloss: 0.268437\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[62]\tvalid_0's multi_logloss: 0.268773\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[63]\tvalid_0's multi_logloss: 0.268824\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[64]\tvalid_0's multi_logloss: 0.269138\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[65]\tvalid_0's multi_logloss: 0.269357\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[66]\tvalid_0's multi_logloss: 0.269572\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[67]\tvalid_0's multi_logloss: 0.269786\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[68]\tvalid_0's multi_logloss: 0.270102\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[69]\tvalid_0's multi_logloss: 0.270435\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[70]\tvalid_0's multi_logloss: 0.270566\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[71]\tvalid_0's multi_logloss: 0.270679\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[72]\tvalid_0's multi_logloss: 0.271056\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[73]\tvalid_0's multi_logloss: 0.271474\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[74]\tvalid_0's multi_logloss: 0.27168\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[75]\tvalid_0's multi_logloss: 0.271918\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[76]\tvalid_0's multi_logloss: 0.271937\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[77]\tvalid_0's multi_logloss: 0.272113\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[78]\tvalid_0's multi_logloss: 0.27242\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[79]\tvalid_0's multi_logloss: 0.272712\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[80]\tvalid_0's multi_logloss: 0.27267\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[81]\tvalid_0's multi_logloss: 0.273019\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[82]\tvalid_0's multi_logloss: 0.272981\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[83]\tvalid_0's multi_logloss: 0.273218\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[84]\tvalid_0's multi_logloss: 0.27353\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[85]\tvalid_0's multi_logloss: 0.273649\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[86]\tvalid_0's multi_logloss: 0.273775\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[87]\tvalid_0's multi_logloss: 0.273835\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[88]\tvalid_0's multi_logloss: 0.274091\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[89]\tvalid_0's multi_logloss: 0.274422\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[90]\tvalid_0's multi_logloss: 0.274716\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[91]\tvalid_0's multi_logloss: 0.275082\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[92]\tvalid_0's multi_logloss: 0.275278\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[93]\tvalid_0's multi_logloss: 0.275447\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[94]\tvalid_0's multi_logloss: 0.275438\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[95]\tvalid_0's multi_logloss: 0.275778\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[96]\tvalid_0's multi_logloss: 0.27591\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[97]\tvalid_0's multi_logloss: 0.276129\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[98]\tvalid_0's multi_logloss: 0.276326\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[99]\tvalid_0's multi_logloss: 0.276449\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[100]\tvalid_0's multi_logloss: 0.276745\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[101]\tvalid_0's multi_logloss: 0.276895\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[102]\tvalid_0's multi_logloss: 0.276914\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[103]\tvalid_0's multi_logloss: 0.277281\n\nEarly stopping, best iteration is:\n\n[3]\tvalid_0's multi_logloss: 0.256518\n"}]},{"cell_type":"code","source":"def lgb_transform(train, test, model, topK):\n    train_df = pd.DataFrame(train)\n    train_df.columns = range(train.shape[1])\n    \n    test_df = pd.DataFrame(test)\n    test_df.columns = range(test.shape[1])\n    \n    features_import = pd.DataFrame()\n    features_import['importance'] = model.feature_importance()\n    features_import['col'] = range(train.shape[1])\n    \n    features_import = features_import.sort_values(['importance'],ascending=0).head(topK)\n    sel_col = list(features_import.col)\n    \n    train_sel = train_df[sel_col]\n    test_sel = test_df[sel_col]\n    return train_sel, test_sel","metadata":{},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"train_sel, test_sel = lgb_transform(train, test, model, 20)\nprint('训练数据未特征筛选维度', train.shape)\nprint('训练数据特征筛选维度后', train_sel.shape)","metadata":{},"execution_count":27,"outputs":[{"name":"stdout","output_type":"stream","text":"训练数据未特征筛选维度 (2000, 229)\n\n训练数据特征筛选维度后 (2000, 20)\n"}]},{"cell_type":"markdown","source":"### lgb特征重要性","metadata":{}},{"cell_type":"code","source":"model.feature_importance()[:10]","metadata":{},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":["array([2, 3, 0, 0, 0, 1, 1, 0, 1, 0])"]},"metadata":{}}]},{"cell_type":"code","source":"#sorted(model.feature_importance(),reverse=True)[:10]","metadata":{},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"### 特征选择前后区别","metadata":{}},{"cell_type":"code","source":"feature_selection(train, train_sel, target)","metadata":{},"execution_count":30,"outputs":[{"name":"stdout","output_type":"stream","text":"No Select Accuracy: 0.93 (+/- 0.00)\n\nFeatures Select Accuracy: 0.93 (+/- 0.00)\n"}]},{"cell_type":"code","source":"","metadata":{},"outputs":[]}]}