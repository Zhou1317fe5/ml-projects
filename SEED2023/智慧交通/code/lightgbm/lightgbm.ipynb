{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "plt.rcParams[\"figure.figsize\"] = (20,5) # 设置pyplot绘制的图片大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.0.0'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据获取并处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#load_dataset\n",
    "lanes = pd.read_csv('../data/Lane.csv')  \n",
    "light = pd.read_csv('../data/Light_status.csv')\n",
    "roads = pd.read_csv('../data/Entrance_road.csv') \n",
    "flow = pd.read_csv('../data/Flow.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Light_status.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CYCLE_START_TIME</th>\n",
       "      <th>STAGE_START_TIME</th>\n",
       "      <th>STAGE_END_TIME</th>\n",
       "      <th>STAGE_LENGTH</th>\n",
       "      <th>GREEN_TIME</th>\n",
       "      <th>GREEN_FLASH_TIME</th>\n",
       "      <th>YELLOW_TIME</th>\n",
       "      <th>ALL_RED_TIME</th>\n",
       "      <th>CHANNELS</th>\n",
       "      <th>LANES</th>\n",
       "      <th>PHASES</th>\n",
       "      <th>LANE_FUNCS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-08-01 0:01:08</td>\n",
       "      <td>2023-08-01 00:01:08</td>\n",
       "      <td>2023-08-01 00:01:30</td>\n",
       "      <td>22</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>11,2,3,10</td>\n",
       "      <td>1_2,1_3,3_2,1_4,3_3,3_4</td>\n",
       "      <td>3,5,10</td>\n",
       "      <td>11,13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-08-01 0:02:18</td>\n",
       "      <td>2023-08-01 00:02:18</td>\n",
       "      <td>2023-08-01 00:02:40</td>\n",
       "      <td>22</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>11,2,3,10</td>\n",
       "      <td>1_2,1_3,3_2,1_4,3_3,3_4</td>\n",
       "      <td>3,5,10</td>\n",
       "      <td>11,13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-08-01 0:04:38</td>\n",
       "      <td>2023-08-01 00:04:38</td>\n",
       "      <td>2023-08-01 00:05:00</td>\n",
       "      <td>22</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>11,2,3,10</td>\n",
       "      <td>1_2,1_3,3_2,1_4,3_3,3_4</td>\n",
       "      <td>3,5,10</td>\n",
       "      <td>11,13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-08-01 0:05:48</td>\n",
       "      <td>2023-08-01 00:05:48</td>\n",
       "      <td>2023-08-01 00:06:10</td>\n",
       "      <td>22</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>11,2,3,10</td>\n",
       "      <td>1_2,1_3,3_2,1_4,3_3,3_4</td>\n",
       "      <td>3,5,10</td>\n",
       "      <td>11,13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-08-01 0:06:58</td>\n",
       "      <td>2023-08-01 00:06:58</td>\n",
       "      <td>2023-08-01 00:07:20</td>\n",
       "      <td>22</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>11,2,3,10</td>\n",
       "      <td>1_2,1_3,3_2,1_4,3_3,3_4</td>\n",
       "      <td>3,5,10</td>\n",
       "      <td>11,13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     CYCLE_START_TIME     STAGE_START_TIME       STAGE_END_TIME  STAGE_LENGTH  \\\n",
       "0  2023-08-01 0:01:08  2023-08-01 00:01:08  2023-08-01 00:01:30            22   \n",
       "1  2023-08-01 0:02:18  2023-08-01 00:02:18  2023-08-01 00:02:40            22   \n",
       "2  2023-08-01 0:04:38  2023-08-01 00:04:38  2023-08-01 00:05:00            22   \n",
       "3  2023-08-01 0:05:48  2023-08-01 00:05:48  2023-08-01 00:06:10            22   \n",
       "4  2023-08-01 0:06:58  2023-08-01 00:06:58  2023-08-01 00:07:20            22   \n",
       "\n",
       "   GREEN_TIME  GREEN_FLASH_TIME  YELLOW_TIME  ALL_RED_TIME   CHANNELS  \\\n",
       "0          19                 0            3             0  11,2,3,10   \n",
       "1          19                 0            3             0  11,2,3,10   \n",
       "2          19                 0            3             0  11,2,3,10   \n",
       "3          19                 0            3             0  11,2,3,10   \n",
       "4          19                 0            3             0  11,2,3,10   \n",
       "\n",
       "                     LANES  PHASES LANE_FUNCS  \n",
       "0  1_2,1_3,3_2,1_4,3_3,3_4  3,5,10      11,13  \n",
       "1  1_2,1_3,3_2,1_4,3_3,3_4  3,5,10      11,13  \n",
       "2  1_2,1_3,3_2,1_4,3_3,3_4  3,5,10      11,13  \n",
       "3  1_2,1_3,3_2,1_4,3_3,3_4  3,5,10      11,13  \n",
       "4  1_2,1_3,3_2,1_4,3_3,3_4  3,5,10      11,13  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "light.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转换成日期属性\n",
    "light['CYCLE_START_TIME'] = pd.to_datetime(light['CYCLE_START_TIME'])\n",
    "light['STAGE_START_TIME'] = pd.to_datetime(light['STAGE_START_TIME'])\n",
    "light['STAGE_END_TIME'] = pd.to_datetime(light['STAGE_END_TIME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除GREEN_FLASH_TIME YELLOW_TIME无用列\n",
    "light.drop('GREEN_FLASH_TIME',axis=1,inplace=True)\n",
    "light.drop('YELLOW_TIME',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将LANES列转为对应的1W 1E 2W形式\n",
    "light['released_lanes'] = light['LANES'].str.split(',') # 用，分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将放行车道号“_”前代表的进口道，1，2，3，4替换为为W，N，E，S。\n",
    "\n",
    "# 定义一个替换函数 replace_dir\n",
    "def replace_lanes(lanes):\n",
    "    replaced = []\n",
    "    for i in lanes:\n",
    "        i = i.replace('1_', 'W_')\n",
    "        i = i.replace('2_', 'N_')\n",
    "        i = i.replace('3_', 'E_')\n",
    "        i = i.replace('4_', 'S_')\n",
    "        \n",
    "        replaced.append(i)\n",
    "    \n",
    "    return replaced\n",
    "\n",
    "# apply替换\n",
    "light['released_lanes'] = light['released_lanes'].apply(replace_lanes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 调换顺序，改为前面为车道号，后面为进口道，并去掉下划线\n",
    "light['released_lanes'] = light['released_lanes'].apply(lambda lanes: [lane.replace('_', '')[-1] + lane.replace('_', '')[:-1] for lane in lanes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1_2,1_3,3_2,1_4,3_3,3_4', '1_1,3_1', '2_2,2_3,2_4,4_2,4_3,4_4',\n",
       "       '2_1,4_1'], dtype=object)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 按LANES分组\n",
    "lanes_unique = light['LANES'].unique()\n",
    "lanes_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按LANES分组\n",
    "ligth_2W3W2E4W3E4E=light[light['LANES']=='1_2,1_3,3_2,1_4,3_3,3_4']\n",
    "ligth_1W1E=light[light['LANES']=='1_1,3_1']\n",
    "ligth_2N3N4N2S3S4S=light[light['LANES']=='2_2,2_3,2_4,4_2,4_3,4_4']\n",
    "ligth_1N1S=light[light['LANES']=='2_1,4_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Development\\anaconda3\\envs\\ml\\lib\\site-packages\\pandas\\core\\frame.py:4913: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "# 删除STAGE_END_TIME，LANES\n",
    "ligth_2W3W2E4W3E4E.drop(['STAGE_END_TIME','LANES'],axis=1,inplace=True)\n",
    "ligth_1W1E.drop(['STAGE_END_TIME','LANES'],axis=1,inplace=True)\n",
    "ligth_2N3N4N2S3S4S.drop(['STAGE_END_TIME','LANES'],axis=1,inplace=True)\n",
    "ligth_1N1S.drop(['STAGE_END_TIME','LANES'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ligth_2W3W2E4W3E4E\n",
    "# 删除2023-08-01 00:05:00前的数据\n",
    "ligth_2W3W2E4W3E4E=ligth_2W3W2E4W3E4E.drop(index=ligth_2W3W2E4W3E4E.index[:3])\n",
    "ligth_2W3W2E4W3E4E=ligth_2W3W2E4W3E4E.reset_index(drop=True)\n",
    "# 将CYCLE_START_TIME设置为时间索引\n",
    "ligth_2W3W2E4W3E4E=ligth_2W3W2E4W3E4E.set_index('CYCLE_START_TIME')\n",
    "# 对数据进行重新采样，以五分钟为一个时间段，并选择从00:05:00开始的数据：\n",
    "start_time = pd.to_datetime(\"2023-08-01 00:05:00\")\n",
    "ligth_2W3W2E4W3E4E = ligth_2W3W2E4W3E4E.resample('5Min',label='left', closed='right').first().loc[start_time:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ligth_1W1E\n",
    "# 删除2023-08-01 00:05:00前的数据\n",
    "ligth_1W1E=ligth_1W1E.drop(index=ligth_1W1E.index[:3])\n",
    "ligth_1W1E=ligth_1W1E.reset_index(drop=True)\n",
    "# 将CYCLE_START_TIME设置为时间索引\n",
    "ligth_1W1E=ligth_1W1E.set_index('CYCLE_START_TIME')\n",
    "# 对数据进行重新采样，以五分钟为一个时间段，并选择从00:05:00开始的数据：\n",
    "start_time = pd.to_datetime(\"2023-08-01 00:05:00\")\n",
    "ligth_1W1E = ligth_1W1E.resample('5Min',label='left', closed='right').first().loc[start_time:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ligth_2N3N4N2S3S4S\n",
    "# 删除2023-08-01 00:05:00前的数据\n",
    "ligth_2N3N4N2S3S4S=ligth_2N3N4N2S3S4S.drop(index=ligth_2N3N4N2S3S4S.index[:3])\n",
    "ligth_2N3N4N2S3S4S=ligth_2N3N4N2S3S4S.reset_index(drop=True)\n",
    "# 将CYCLE_START_TIME设置为时间索引\n",
    "ligth_2N3N4N2S3S4S=ligth_2N3N4N2S3S4S.set_index('CYCLE_START_TIME')\n",
    "# 对数据进行重新采样，以五分钟为一个时间段，并选择从00:05:00开始的数据：\n",
    "start_time = pd.to_datetime(\"2023-08-01 00:05:00\")\n",
    "ligth_2N3N4N2S3S4S = ligth_2N3N4N2S3S4S.resample('5Min',label='left', closed='right').first().loc[start_time:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ligth_1N1S\n",
    "# 删除2023-08-01 00:05:00前的数据\n",
    "ligth_1N1S=ligth_1N1S.drop(index=ligth_1N1S.index[:3])\n",
    "ligth_1N1S=ligth_1N1S.reset_index(drop=True)\n",
    "# 将CYCLE_START_TIME设置为时间索引\n",
    "ligth_1N1S=ligth_1N1S.set_index('CYCLE_START_TIME')\n",
    "# 对数据进行重新采样，以五分钟为一个时间段，并选择从00:05:00开始的数据：\n",
    "start_time = pd.to_datetime(\"2023-08-01 00:05:00\")\n",
    "ligth_1N1S = ligth_1N1S.resample('5Min',label='left', closed='right').first().loc[start_time:] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flow.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow['START_TIME'] = pd.to_datetime(flow['START_TIME'])\n",
    "flow['END_TIME'] = pd.to_datetime(flow['END_TIME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow['LANE_ARM']=flow['LANE_ID'].astype(str)+flow['ARM_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "lane_arm = flow.pop(\"LANE_ARM\")\n",
    "flow.insert(2,'LANE_ARM',lane_arm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow.drop(['LANE_ID','ARM_ID'],axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1E', '1N', '1S', '1W', '2E', '2N', '2S', '2W', '3E', '3N', '3S',\n",
       "       '3W', '4E', '4N', '4S', '4W'], dtype=object)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LANE_ARM_uniqe =flow['LANE_ARM'].unique()\n",
    "LANE_ARM_uniqe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按LANE_ARM分组\n",
    "flow_1E = flow[flow['LANE_ARM']=='1E']\n",
    "flow_1N = flow[flow['LANE_ARM']=='1N']\n",
    "flow_1S = flow[flow['LANE_ARM']=='1S']\n",
    "flow_1W = flow[flow['LANE_ARM']=='1W']\n",
    "flow_2E = flow[flow['LANE_ARM']=='2E']\n",
    "flow_2N = flow[flow['LANE_ARM']=='2N']\n",
    "flow_2S = flow[flow['LANE_ARM']=='2S']\n",
    "flow_2W = flow[flow['LANE_ARM']=='2W']\n",
    "flow_3E = flow[flow['LANE_ARM']=='3E']\n",
    "flow_3N = flow[flow['LANE_ARM']=='3N']\n",
    "flow_3S = flow[flow['LANE_ARM']=='3S']\n",
    "flow_3W = flow[flow['LANE_ARM']=='3W']\n",
    "flow_4E = flow[flow['LANE_ARM']=='4E']\n",
    "flow_4N = flow[flow['LANE_ARM']=='4N']\n",
    "flow_4S = flow[flow['LANE_ARM']=='4S']\n",
    "flow_4W = flow[flow['LANE_ARM']=='4W']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_LANE_ARM = [flow_1E\n",
    ",flow_1N\n",
    ",flow_1S\n",
    ",flow_1W\n",
    ",flow_2E\n",
    ",flow_2N\n",
    ",flow_2S\n",
    ",flow_2W\n",
    ",flow_3E\n",
    ",flow_3N\n",
    ",flow_3S\n",
    ",flow_3W\n",
    ",flow_4E\n",
    ",flow_4N\n",
    ",flow_4S\n",
    ",flow_4W]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_1E = flow_1E.set_index('START_TIME')\n",
    "flow_1N = flow_1N.set_index('START_TIME')\n",
    "flow_1S = flow_1S.set_index('START_TIME')\n",
    "flow_1W = flow_1W.set_index('START_TIME')\n",
    "flow_2E = flow_2E.set_index('START_TIME')\n",
    "flow_2N = flow_2N.set_index('START_TIME')\n",
    "flow_2S = flow_2S.set_index('START_TIME')\n",
    "flow_2W = flow_2W.set_index('START_TIME')\n",
    "flow_3E = flow_3E.set_index('START_TIME')\n",
    "flow_3N = flow_3N.set_index('START_TIME')\n",
    "flow_3S = flow_3S.set_index('START_TIME')\n",
    "flow_3W = flow_3W.set_index('START_TIME')\n",
    "flow_4E = flow_4E.set_index('START_TIME')\n",
    "flow_4N = flow_4N.set_index('START_TIME')\n",
    "flow_4S = flow_4S.set_index('START_TIME')\n",
    "flow_4W = flow_4W.set_index('START_TIME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_flow_1E = pd.merge(flow_1E,ligth_1W1E, left_index=True, right_index=True, how='left')\n",
    "merged_flow_1N = pd.merge(flow_1N,ligth_1N1S, left_index=True, right_index=True, how='left')\n",
    "merged_flow_1S = pd.merge(flow_1S,ligth_1N1S, left_index=True, right_index=True, how='left')\n",
    "merged_flow_1W = pd.merge(flow_1W,ligth_1W1E, left_index=True, right_index=True, how='left')\n",
    "merged_flow_2E = pd.merge(flow_2E,ligth_2W3W2E4W3E4E, left_index=True, right_index=True, how='left')\n",
    "merged_flow_2N = pd.merge(flow_2N,ligth_2N3N4N2S3S4S, left_index=True, right_index=True, how='left')\n",
    "merged_flow_2S = pd.merge(flow_2S,ligth_2N3N4N2S3S4S, left_index=True, right_index=True, how='left')\n",
    "merged_flow_2W = pd.merge(flow_2W,ligth_2W3W2E4W3E4E, left_index=True, right_index=True, how='left')\n",
    "merged_flow_3E = pd.merge(flow_3E,ligth_2W3W2E4W3E4E, left_index=True, right_index=True, how='left')\n",
    "merged_flow_3N = pd.merge(flow_3N,ligth_2N3N4N2S3S4S, left_index=True, right_index=True, how='left')\n",
    "merged_flow_3S = pd.merge(flow_3S,ligth_2N3N4N2S3S4S, left_index=True, right_index=True, how='left')\n",
    "merged_flow_3W = pd.merge(flow_3W,ligth_2W3W2E4W3E4E, left_index=True, right_index=True, how='left')\n",
    "merged_flow_4E = pd.merge(flow_4E,ligth_2W3W2E4W3E4E, left_index=True, right_index=True, how='left')\n",
    "merged_flow_4N = pd.merge(flow_4N,ligth_2N3N4N2S3S4S, left_index=True, right_index=True, how='left')\n",
    "merged_flow_4S = pd.merge(flow_4S,ligth_2N3N4N2S3S4S, left_index=True, right_index=True, how='left')\n",
    "merged_flow_4W = pd.merge(flow_4W,ligth_2W3W2E4W3E4E, left_index=True, right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1E = merged_flow_1E.copy()\n",
    "df_1N = merged_flow_1N.copy()\n",
    "df_1S = merged_flow_1S.copy()\n",
    "df_1W = merged_flow_1W.copy()\n",
    "df_2E = merged_flow_2E.copy()\n",
    "df_2N = merged_flow_2N.copy()\n",
    "df_2S = merged_flow_2S.copy()\n",
    "df_2W = merged_flow_2W.copy()\n",
    "df_3E = merged_flow_3E.copy()\n",
    "df_3N = merged_flow_3N.copy()\n",
    "df_3S = merged_flow_3S.copy()\n",
    "df_3W = merged_flow_3W.copy()\n",
    "df_4E = merged_flow_4E.copy()\n",
    "df_4N = merged_flow_4N.copy()\n",
    "df_4S = merged_flow_4S.copy()\n",
    "df_4W = merged_flow_4W.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LANE_ARM</th>\n",
       "      <th>END_TIME</th>\n",
       "      <th>VOLUMN_5MIN</th>\n",
       "      <th>STAGE_START_TIME</th>\n",
       "      <th>STAGE_LENGTH</th>\n",
       "      <th>GREEN_TIME</th>\n",
       "      <th>ALL_RED_TIME</th>\n",
       "      <th>CHANNELS</th>\n",
       "      <th>PHASES</th>\n",
       "      <th>LANE_FUNCS</th>\n",
       "      <th>released_lanes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>START_TIME</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-08-01 00:05:00</th>\n",
       "      <td>1E</td>\n",
       "      <td>2023-08-01 00:10:00</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-08-01 00:06:10</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1,9</td>\n",
       "      <td>4,9</td>\n",
       "      <td>12</td>\n",
       "      <td>[1W, 1E]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01 00:10:00</th>\n",
       "      <td>1E</td>\n",
       "      <td>2023-08-01 00:15:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-08-01 00:10:50</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1,9</td>\n",
       "      <td>4,9</td>\n",
       "      <td>12</td>\n",
       "      <td>[1W, 1E]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01 00:15:00</th>\n",
       "      <td>1E</td>\n",
       "      <td>2023-08-01 00:20:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-08-01 00:15:30</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1,9</td>\n",
       "      <td>4,9</td>\n",
       "      <td>12</td>\n",
       "      <td>[1W, 1E]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01 00:20:00</th>\n",
       "      <td>1E</td>\n",
       "      <td>2023-08-01 00:25:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-08-01 00:21:20</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1,9</td>\n",
       "      <td>4,9</td>\n",
       "      <td>12</td>\n",
       "      <td>[1W, 1E]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01 00:25:00</th>\n",
       "      <td>1E</td>\n",
       "      <td>2023-08-01 00:30:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-08-01 00:26:00</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1,9</td>\n",
       "      <td>4,9</td>\n",
       "      <td>12</td>\n",
       "      <td>[1W, 1E]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-27 23:35:00</th>\n",
       "      <td>1E</td>\n",
       "      <td>2023-08-27 23:40:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-08-27 23:35:33</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1,9</td>\n",
       "      <td>4,9</td>\n",
       "      <td>12</td>\n",
       "      <td>[1W, 1E]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-27 23:40:00</th>\n",
       "      <td>1E</td>\n",
       "      <td>2023-08-27 23:45:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-08-27 23:41:23</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1,9</td>\n",
       "      <td>4,9</td>\n",
       "      <td>12</td>\n",
       "      <td>[1W, 1E]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-27 23:45:00</th>\n",
       "      <td>1E</td>\n",
       "      <td>2023-08-27 23:50:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-08-27 23:46:03</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1,9</td>\n",
       "      <td>4,9</td>\n",
       "      <td>12</td>\n",
       "      <td>[1W, 1E]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-27 23:50:00</th>\n",
       "      <td>1E</td>\n",
       "      <td>2023-08-27 23:55:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-08-27 23:50:43</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1,9</td>\n",
       "      <td>4,9</td>\n",
       "      <td>12</td>\n",
       "      <td>[1W, 1E]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-27 23:55:00</th>\n",
       "      <td>1E</td>\n",
       "      <td>2023-08-28 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-08-27 23:55:23</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1,9</td>\n",
       "      <td>4,9</td>\n",
       "      <td>12</td>\n",
       "      <td>[1W, 1E]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7549 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    LANE_ARM            END_TIME  VOLUMN_5MIN  \\\n",
       "START_TIME                                                      \n",
       "2023-08-01 00:05:00       1E 2023-08-01 00:10:00            2   \n",
       "2023-08-01 00:10:00       1E 2023-08-01 00:15:00            1   \n",
       "2023-08-01 00:15:00       1E 2023-08-01 00:20:00            0   \n",
       "2023-08-01 00:20:00       1E 2023-08-01 00:25:00            1   \n",
       "2023-08-01 00:25:00       1E 2023-08-01 00:30:00            0   \n",
       "...                      ...                 ...          ...   \n",
       "2023-08-27 23:35:00       1E 2023-08-27 23:40:00            1   \n",
       "2023-08-27 23:40:00       1E 2023-08-27 23:45:00            0   \n",
       "2023-08-27 23:45:00       1E 2023-08-27 23:50:00            0   \n",
       "2023-08-27 23:50:00       1E 2023-08-27 23:55:00            0   \n",
       "2023-08-27 23:55:00       1E 2023-08-28 00:00:00            0   \n",
       "\n",
       "                       STAGE_START_TIME  STAGE_LENGTH  GREEN_TIME  \\\n",
       "START_TIME                                                          \n",
       "2023-08-01 00:05:00 2023-08-01 00:06:10          13.0         9.0   \n",
       "2023-08-01 00:10:00 2023-08-01 00:10:50          13.0         9.0   \n",
       "2023-08-01 00:15:00 2023-08-01 00:15:30          13.0         9.0   \n",
       "2023-08-01 00:20:00 2023-08-01 00:21:20          13.0         9.0   \n",
       "2023-08-01 00:25:00 2023-08-01 00:26:00          13.0         9.0   \n",
       "...                                 ...           ...         ...   \n",
       "2023-08-27 23:35:00 2023-08-27 23:35:33          13.0         9.0   \n",
       "2023-08-27 23:40:00 2023-08-27 23:41:23          13.0         9.0   \n",
       "2023-08-27 23:45:00 2023-08-27 23:46:03          13.0         9.0   \n",
       "2023-08-27 23:50:00 2023-08-27 23:50:43          13.0         9.0   \n",
       "2023-08-27 23:55:00 2023-08-27 23:55:23          13.0         9.0   \n",
       "\n",
       "                     ALL_RED_TIME CHANNELS PHASES LANE_FUNCS released_lanes  \n",
       "START_TIME                                                                   \n",
       "2023-08-01 00:05:00           1.0      1,9    4,9         12       [1W, 1E]  \n",
       "2023-08-01 00:10:00           1.0      1,9    4,9         12       [1W, 1E]  \n",
       "2023-08-01 00:15:00           1.0      1,9    4,9         12       [1W, 1E]  \n",
       "2023-08-01 00:20:00           1.0      1,9    4,9         12       [1W, 1E]  \n",
       "2023-08-01 00:25:00           1.0      1,9    4,9         12       [1W, 1E]  \n",
       "...                           ...      ...    ...        ...            ...  \n",
       "2023-08-27 23:35:00           1.0      1,9    4,9         12       [1W, 1E]  \n",
       "2023-08-27 23:40:00           1.0      1,9    4,9         12       [1W, 1E]  \n",
       "2023-08-27 23:45:00           1.0      1,9    4,9         12       [1W, 1E]  \n",
       "2023-08-27 23:50:00           1.0      1,9    4,9         12       [1W, 1E]  \n",
       "2023-08-27 23:55:00           1.0      1,9    4,9         12       [1W, 1E]  \n",
       "\n",
       "[7549 rows x 11 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 合并车流量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VOLUMN_5MIN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>START_TIME</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-08-01 00:05:00</th>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01 00:10:00</th>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01 00:15:00</th>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01 00:20:00</th>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01 00:25:00</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-27 23:35:00</th>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-27 23:40:00</th>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-27 23:45:00</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-27 23:50:00</th>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-27 23:55:00</th>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7549 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     VOLUMN_5MIN\n",
       "START_TIME                      \n",
       "2023-08-01 00:05:00          7.0\n",
       "2023-08-01 00:10:00         11.0\n",
       "2023-08-01 00:15:00          6.0\n",
       "2023-08-01 00:20:00          9.0\n",
       "2023-08-01 00:25:00          2.0\n",
       "...                          ...\n",
       "2023-08-27 23:35:00         14.0\n",
       "2023-08-27 23:40:00          6.0\n",
       "2023-08-27 23:45:00          2.0\n",
       "2023-08-27 23:50:00          8.0\n",
       "2023-08-27 23:55:00         11.0\n",
       "\n",
       "[7549 rows x 1 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LANE_ARM = [\n",
    "flow_1N\n",
    ",flow_1S\n",
    ",flow_1W\n",
    ",flow_2E\n",
    ",flow_2N\n",
    ",flow_2S\n",
    ",flow_2W\n",
    ",flow_3E\n",
    ",flow_3N\n",
    ",flow_3S\n",
    ",flow_3W\n",
    ",flow_4E\n",
    ",flow_4N\n",
    ",flow_4S\n",
    ",flow_4W]\n",
    "\n",
    "merged_flow = flow_1E['VOLUMN_5MIN']\n",
    "merged_flow = pd.DataFrame(merged_flow)\n",
    "for i in LANE_ARM:\n",
    "    merged_flow['VOLUMN_5MIN'] = merged_flow['VOLUMN_5MIN']+i['VOLUMN_5MIN']\n",
    "    \n",
    "merged_flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征工程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 延迟特征\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 局部特征\n",
    "现在假设要预测的目标是7550。先抽取局部特征。使用历史数据中最后的7个数据构造特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_day = 7550\n",
    "\n",
    "#使用历史数据中最后的7个构造特征\n",
    "local_range = 7\n",
    "\n",
    "# 由于使用前7549个的数据预测第7550个，历史数据与预测目标的距离只有1个单位，因此predict_distance=1\n",
    "# 如果使用前7549个的数据预测第7550个，则历史数据与预测目标的距离有2个单位，因此predict_distance=2，以此类推\n",
    "predict_distance = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>la_1</th>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la_2</th>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la_3</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la_4</th>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la_5</th>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la_6</th>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la_7</th>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      flow\n",
       "la_1  11.0\n",
       "la_2   8.0\n",
       "la_3   2.0\n",
       "la_4   6.0\n",
       "la_5  14.0\n",
       "la_6  11.0\n",
       "la_7  12.0"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_local_features(data,target_day, predict_distance):\n",
    "    local_features = pd.DataFrame()\n",
    "    for i in range(local_range):\n",
    "        selected_data = data.iloc[target_day-predict_distance-i-1,0] #iloc基于行号，列号。注意索引-1\n",
    "        local_features.loc['la_'+str(i+1),'flow']=selected_data # loc行标签，列标签\n",
    "    return local_features\n",
    "\n",
    "get_local_features(merged_flow,target_day, predict_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里我们抽取了七个历史值。\n",
    "对于历史值的聚合，我们还可以用一个小技巧得到更稳定的特征。\n",
    "对于单个的历史值，或多或少都有些随机因素，具有较大的不确定性，例如某天天气不好，销量突然下降。\n",
    "实际上，我们可以用连续几历史数据的加和（或均值），用于减缓不确定性带来的影响。\n",
    "更具体来说，我们可以用前一个的历史值、前面两个的历史值的和、等等来作为局部特征。\n",
    "用代码表示的话，即"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>la_1</th>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la_2</th>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la_3</th>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la_4</th>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la_5</th>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la_6</th>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la_7</th>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      flow\n",
       "la_1  11.0\n",
       "la_2  19.0\n",
       "la_3  21.0\n",
       "la_4  27.0\n",
       "la_5  41.0\n",
       "la_6  52.0\n",
       "la_7  64.0"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_local_accumulated_features(data,target_day, predict_distance):\n",
    "    local_accumulated_feature = pd.DataFrame()\n",
    "    local_accumulated_feature.loc['la_1','flow'] = data.iloc[target_day-predict_distance-1,0]\n",
    "    for i in range(1,local_range):\n",
    "        selected_data = data.iloc[target_day-predict_distance-i-1,0] #iloc基于行号，列号。注意索引-1\n",
    "        local_accumulated_feature.loc['la_'+str(i+1),'flow']=selected_data+local_accumulated_feature.loc['la_'+str(i),'flow'] # loc行标签，列标签\n",
    "    return local_accumulated_feature\n",
    "\n",
    "get_local_accumulated_features(merged_flow,target_day, predict_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意到，我们现在只用上了近期的历史数据。还有很多远期的历史数据没用上。\n",
    "实际上远期的历史数据也是需要的，只不过不需要那么精细，可以做一些聚合。\n",
    "例如过去14个数据，过去30个数据的总和。为了更快的实现这个，我们先用cumsum 滚动累计每一个历史值。 然后抽取我们需要的数值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>la_1</th>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la_2</th>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la_3</th>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la_4</th>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la_5</th>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la_6</th>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la_7</th>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la_8</th>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la_9</th>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la_10</th>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la_14</th>\n",
       "      <td>133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la_21</th>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la_28</th>\n",
       "      <td>383.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la_42</th>\n",
       "      <td>822.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la_56</th>\n",
       "      <td>1449.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la_63</th>\n",
       "      <td>1788.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la_70</th>\n",
       "      <td>2318.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         flow\n",
       "la_1     11.0\n",
       "la_2     19.0\n",
       "la_3     21.0\n",
       "la_4     27.0\n",
       "la_5     41.0\n",
       "la_6     52.0\n",
       "la_7     64.0\n",
       "la_8     70.0\n",
       "la_9     81.0\n",
       "la_10    91.0\n",
       "la_14   133.0\n",
       "la_21   240.0\n",
       "la_28   383.0\n",
       "la_42   822.0\n",
       "la_56  1449.0\n",
       "la_63  1788.0\n",
       "la_70  2318.0"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_accumulated_features(data,target_day, predict_distance):\n",
    "    used_history_distances = [1, 2, 3, 4, 5, 6, 7, 8,9,10,14, 21, 28, 42, 56,63,70]\n",
    "\n",
    "    tx = data[target_day-predict_distance+1-max(used_history_distances)-1:target_day-predict_distance+1][::-1].cumsum(axis=0)\n",
    "    #tx = tx[::-1]\n",
    "\n",
    "    local_accumulated_feature = pd.DataFrame()\n",
    "    for distance in used_history_distances:\n",
    "        local_accumulated_feature.loc['la_'+str(distance),'flow']=tx.iloc[distance-1,0] # loc行标签，列标签\n",
    "    return local_accumulated_feature\n",
    "\n",
    "get_accumulated_features(merged_flow,target_day, predict_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这样我们就从历史序列里的最近的70个数据，构造出了上面的17个特征。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 周期特征\n",
    "现在我们来看周期特征。我们主要考虑以天作为周期,即288个历史数据。并且，我们选用288\\*7个历史值，也就是过去7天的数据，构造周期特征。因此，我们先取得和目标预测值**同周期**的历史数据。即往前第288\\*1个，第288\\*2个，第288\\*3个.....当时的数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>p_1</th>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_2</th>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_3</th>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_4</th>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_5</th>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_6</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_7</th>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     flow\n",
       "p_1  10.0\n",
       "p_2   8.0\n",
       "p_3   9.0\n",
       "p_4   8.0\n",
       "p_5  10.0\n",
       "p_6   4.0\n",
       "p_7   6.0"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_period_sale(data,target_day, predict_distance):\n",
    "    period = 288\n",
    "    i_start = (predict_distance + period - 1) // period # 表示距离目标日期 predict_distance 天之前的第几个时间段，为1\n",
    "    period_sale = pd.DataFrame()\n",
    "    for i in range(7): # 用过去7天的数据\n",
    "        cur_day = target_day - (i + i_start) * period\n",
    "        period_sale.loc['p_'+str(i + 1),'flow'] = data.iloc[cur_day,0]\n",
    "    return period_sale\n",
    "\n",
    "get_period_sale(merged_flow,target_day, predict_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后，一样的，我们也使用累计的历史值，来提高稳定性。\n",
    "因此，用cumsum得到累计值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>p_1</th>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_2</th>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_3</th>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_4</th>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_5</th>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_6</th>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_7</th>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     flow\n",
       "p_1  10.0\n",
       "p_2  18.0\n",
       "p_3  27.0\n",
       "p_4  35.0\n",
       "p_5  45.0\n",
       "p_6  49.0\n",
       "p_7  55.0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_period_features(data,target_day, predict_distance):\n",
    "    tx_period = get_period_sale(data,target_day, predict_distance)\n",
    "    tx_period = tx_period.cumsum(axis=0)\n",
    "    return tx_period\n",
    "\n",
    "get_period_features(merged_flow,target_day, predict_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 特征结合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "综上，以下是我们基于历史数据构造出的所有特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>la_1</th>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la_2</th>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la_3</th>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la_4</th>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la_5</th>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la_6</th>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la_7</th>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la_8</th>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la_9</th>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la_10</th>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la_14</th>\n",
       "      <td>133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la_21</th>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la_28</th>\n",
       "      <td>383.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la_42</th>\n",
       "      <td>822.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la_56</th>\n",
       "      <td>1449.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la_63</th>\n",
       "      <td>1788.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la_70</th>\n",
       "      <td>2318.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_1</th>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_2</th>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_3</th>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_4</th>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_5</th>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_6</th>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_7</th>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         flow\n",
       "la_1     11.0\n",
       "la_2     19.0\n",
       "la_3     21.0\n",
       "la_4     27.0\n",
       "la_5     41.0\n",
       "la_6     52.0\n",
       "la_7     64.0\n",
       "la_8     70.0\n",
       "la_9     81.0\n",
       "la_10    91.0\n",
       "la_14   133.0\n",
       "la_21   240.0\n",
       "la_28   383.0\n",
       "la_42   822.0\n",
       "la_56  1449.0\n",
       "la_63  1788.0\n",
       "la_70  2318.0\n",
       "p_1      10.0\n",
       "p_2      18.0\n",
       "p_3      27.0\n",
       "p_4      35.0\n",
       "p_5      45.0\n",
       "p_6      49.0\n",
       "p_7      55.0"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_history_features(data,target_day, predict_distance):\n",
    "    return pd.concat([get_accumulated_features(data,target_day, predict_distance),\n",
    "                      get_period_features(data,target_day, predict_distance)], axis=0)\n",
    "\n",
    "get_history_features(merged_flow,target_day, predict_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构造训练数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练集X：窗口大小+构造的特征\n",
    "训练集y：下一个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = merged_flow.copy()\n",
    "data = data.rename(columns={'VOLUMN_5MIN': 'flow'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 设置时间窗口大小\n",
    "window_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 滑动时间窗口生成样本\n",
    "samples = []\n",
    "for i in range(288*7,len(data) - window_size):\n",
    "    window_data = data.iloc[i:i+window_size] # \n",
    "    feature_iwindow = get_history_features(data,i+window_size-1, 1)\n",
    "    feature = pd.concat([window_data,feature_iwindow], axis=0)\n",
    "    features = feature['flow'].values # 提取特征\n",
    "    \n",
    "    target = data.iloc[i+window_size-1]['flow'] # 提取目标值\n",
    "    samples.append((features, target))\n",
    "\n",
    "# 划分训练集和测试集\n",
    "train_samples = samples[:int(0.8 * len(samples))] # 取80%作为训练集\n",
    "test_samples = samples[int(0.8 * len(samples)):] # 剩余20%作为测试集\n",
    "\n",
    "# 构建特征矩阵和目标向量\n",
    "train_X = [sample[0] for sample in train_samples]\n",
    "train_y = [sample[1] for sample in train_samples]\n",
    "test_X = [sample[0] for sample in test_samples]\n",
    "test_y = [sample[1] for sample in test_samples]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X=pd.DataFrame(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1242.0</td>\n",
       "      <td>1590.0</td>\n",
       "      <td>2229.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1209.0</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>2136.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>1494.0</td>\n",
       "      <td>2044.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1163.0</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>1944.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1145.0</td>\n",
       "      <td>1422.0</td>\n",
       "      <td>1876.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4420</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>317.0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>668.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4421</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>304.0</td>\n",
       "      <td>442.0</td>\n",
       "      <td>634.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4422</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>296.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>603.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4423</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>276.0</td>\n",
       "      <td>408.0</td>\n",
       "      <td>564.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4424</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>271.0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>534.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4425 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2     3     4     5     6     7     8     9   ...      15  \\\n",
       "0      8.0  10.0  19.0  28.0  32.0  38.0  51.0  58.0  68.0  74.0  ...  1242.0   \n",
       "1     14.0   8.0  18.0  27.0  36.0  40.0  46.0  59.0  66.0  76.0  ...  1209.0   \n",
       "2     10.0  14.0  22.0  32.0  41.0  50.0  54.0  60.0  73.0  80.0  ...  1185.0   \n",
       "3     10.0  10.0  24.0  32.0  42.0  51.0  60.0  64.0  70.0  83.0  ...  1163.0   \n",
       "4      8.0  10.0  20.0  34.0  42.0  52.0  61.0  70.0  74.0  80.0  ...  1145.0   \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...     ...   \n",
       "4420   2.0   3.0   6.0   6.0   8.0  10.0  12.0  12.0  13.0  14.0  ...   317.0   \n",
       "4421   3.0   2.0   5.0   8.0   8.0  10.0  12.0  14.0  14.0  15.0  ...   304.0   \n",
       "4422   1.0   3.0   5.0   8.0  11.0  11.0  13.0  15.0  17.0  17.0  ...   296.0   \n",
       "4423   2.0   1.0   4.0   6.0   9.0  12.0  12.0  14.0  16.0  18.0  ...   276.0   \n",
       "4424   0.0   2.0   3.0   6.0   8.0  11.0  14.0  14.0  16.0  18.0  ...   271.0   \n",
       "\n",
       "          16      17    18    19    20    21    22    23    24  \n",
       "0     1590.0  2229.0  13.0  27.0  38.0  50.0  50.0  56.0  63.0  \n",
       "1     1536.0  2136.0   6.0  15.0  21.0  27.0  27.0  35.0  46.0  \n",
       "2     1494.0  2044.0   8.0  22.0  32.0  37.0  37.0  43.0  49.0  \n",
       "3     1460.0  1944.0   7.0  20.0  30.0  37.0  37.0  51.0  60.0  \n",
       "4     1422.0  1876.0   7.0  16.0  25.0  32.0  32.0  38.0  40.0  \n",
       "...      ...     ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "4420   460.0   668.0   0.0   2.0   4.0   4.0   9.0  12.0  18.0  \n",
       "4421   442.0   634.0   3.0   4.0   5.0   8.0  11.0  14.0  20.0  \n",
       "4422   420.0   603.0   1.0   4.0   5.0   7.0   8.0   9.0  11.0  \n",
       "4423   408.0   564.0   1.0   3.0   5.0   8.0  10.0  13.0  17.0  \n",
       "4424   398.0   534.0   0.0   2.0   5.0   8.0   9.0  10.0  12.0  \n",
       "\n",
       "[4425 rows x 25 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y=pd.DataFrame(train_y)\n",
    "test_X =pd.DataFrame(test_X)\n",
    "test_y =pd.DataFrame(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4425 entries, 0 to 4424\n",
      "Data columns (total 25 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       4424 non-null   float64\n",
      " 1   1       4424 non-null   float64\n",
      " 2   2       4424 non-null   float64\n",
      " 3   3       4424 non-null   float64\n",
      " 4   4       4424 non-null   float64\n",
      " 5   5       4424 non-null   float64\n",
      " 6   6       4424 non-null   float64\n",
      " 7   7       4424 non-null   float64\n",
      " 8   8       4424 non-null   float64\n",
      " 9   9       4424 non-null   float64\n",
      " 10  10      4424 non-null   float64\n",
      " 11  11      4424 non-null   float64\n",
      " 12  12      4424 non-null   float64\n",
      " 13  13      4424 non-null   float64\n",
      " 14  14      4424 non-null   float64\n",
      " 15  15      4424 non-null   float64\n",
      " 16  16      4424 non-null   float64\n",
      " 17  17      4424 non-null   float64\n",
      " 18  18      4424 non-null   float64\n",
      " 19  19      4424 non-null   float64\n",
      " 20  20      4424 non-null   float64\n",
      " 21  21      4424 non-null   float64\n",
      " 22  22      4424 non-null   float64\n",
      " 23  23      4424 non-null   float64\n",
      " 24  24      4424 non-null   float64\n",
      "dtypes: float64(25)\n",
      "memory usage: 864.4 KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4425 entries, 0 to 4424\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       4424 non-null   float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 34.7 KB\n"
     ]
    }
   ],
   "source": [
    "train_X.info()\n",
    "train_y.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 调参和训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，导入LightGBM的python包。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接着，创建训练数据和测试数据，代码如下。导入数据集之后，LightGBM会根据超参数，在数据集中加入一些额外的结构信息，例如，哪些特征属于类别特征、特征值离散化的边界等等。创建test_set时，我们需要设置reference=train_set，这使得test_set的结构信息与train_set保持一致。\n",
    "\n",
    "`feature_pre_filter`默认为`True`，lightgbm会根据min_data_in_leaf的值提前把一些不可能找到合法分割的特征过滤。由于后面会调整min_data_in_leaf，我们不希望反复构造数据集，我们将设置`feature_pre_filter=False`，这样`min_data_in_leaf`的选取不会影响到Dataset的构建。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#train_set = lgb.Dataset(train_X, label=train_y)\n",
    "#test_set = lgb.Dataset(test_X, label=test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"feature_pre_filter\": False\n",
    "}\n",
    "\n",
    "train_set = lgb.Dataset(train_X, label=train_y, params=params)\n",
    "test_set = lgb.Dataset(test_X, label=test_y, reference=train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先使用一组默认的超参数训练一下，观察在测试集上的效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000783 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6033\n",
      "[LightGBM] [Info] Number of data points in the train set: 4425, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 47.997740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Development\\anaconda3\\envs\\ml\\lib\\site-packages\\lightgbm\\basic.py:2171: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'objective':'regression' #设置目标函数为regression，将会使用最小均方误差(MSE)作为目标函数。其他超参数保持默认。\n",
    "}\n",
    "model = lgb.train(params=params, train_set=train_set, valid_sets=[test_set], valid_names=[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 手动调参\n",
    "\n",
    "调参时，将train_set中最后一天288个数据作为验证集，其余作为训练集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "num_data_per_day = 288\n",
    "val_train_data = train_X.iloc[: -num_data_per_day]\n",
    "val_test_data = train_X.iloc[-num_data_per_day :]\n",
    "val_train_label = train_y[: -num_data_per_day]\n",
    "val_test_label = test_y[-num_data_per_day :]\n",
    "\n",
    "val_train_set = lgb.Dataset(data=val_train_data, label=val_train_label)\n",
    "val_test_set = lgb.Dataset(data=val_test_data, label=val_test_label, reference=val_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'regression',\n",
    "    'num_trees': 1000\n",
    "}\n",
    "early_stopping_rounds = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为方便测试，先定义一个直接由超参数得到验证集上结果的函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def get_eval_result(params):\n",
    "    evals_result = {}\n",
    "    model = lgb.train(params=params,\n",
    "                      train_set=val_train_set,\n",
    "                      valid_sets=[val_test_set],\n",
    "                      valid_names=[\"val_test\"],\n",
    "                      #verbose_eval=False\n",
    "                      callbacks=[lgb.log_evaluation(period=100), lgb.early_stopping(stopping_rounds=early_stopping_rounds),lgb.record_evaluation(evals_result)]\n",
    "                      )\n",
    "    return evals_result[\"val_test\"][\"l2\"][model.best_iteration - 1], model.best_iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，固定学习率和最大迭代次数，调整其他超参数。为了保证能够得到测试集上最优迭代的结果，一开始固定的迭代次数会比较大，这里选取了num_trees=500。这里为了方便展示，我们仅以grid search的方式调整决策树的规模和叶子上最少允许的数据量。读者可自行加入其他超参数一起搜索。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Development\\anaconda3\\envs\\ml\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000554 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 48.073000\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tval_test's l2: 1288.2\n",
      "best l2 loss 1288.196288 at iteration 3 with num_leaves = 4 and min_data_in_leaf = 20\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000750 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 48.073000\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tval_test's l2: 1288.2\n",
      "best l2 loss 1288.196288 at iteration 3 with num_leaves = 4 and min_data_in_leaf = 50\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000629 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 48.073000\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tval_test's l2: 1288.2\n",
      "best l2 loss 1288.196288 at iteration 3 with num_leaves = 4 and min_data_in_leaf = 100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000579 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 48.073000\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tval_test's l2: 1288.2\n",
      "best l2 loss 1288.196288 at iteration 3 with num_leaves = 4 and min_data_in_leaf = 200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001012 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 48.073000\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tval_test's l2: 1286.94\n",
      "best l2 loss 1286.938488 at iteration 4 with num_leaves = 4 and min_data_in_leaf = 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000798 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 48.073000\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tval_test's l2: 1286.71\n",
      "best l2 loss 1286.708644 at iteration 4 with num_leaves = 4 and min_data_in_leaf = 400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000564 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 48.073000\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tval_test's l2: 1292.75\n",
      "best l2 loss 1292.749354 at iteration 4 with num_leaves = 4 and min_data_in_leaf = 500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000786 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 48.073000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[4]\tval_test's l2: 1342.51\n",
      "best l2 loss 1342.510293 at iteration 4 with num_leaves = 4 and min_data_in_leaf = 1000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000598 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 48.073000\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tval_test's l2: 1294.47\n",
      "best l2 loss 1294.467173 at iteration 3 with num_leaves = 8 and min_data_in_leaf = 20\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000581 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 48.073000\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tval_test's l2: 1294.47\n",
      "best l2 loss 1294.467173 at iteration 3 with num_leaves = 8 and min_data_in_leaf = 50\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000571 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 48.073000\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tval_test's l2: 1294.47\n",
      "best l2 loss 1294.467173 at iteration 3 with num_leaves = 8 and min_data_in_leaf = 100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000565 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 48.073000\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tval_test's l2: 1292.52\n",
      "best l2 loss 1292.522069 at iteration 4 with num_leaves = 8 and min_data_in_leaf = 200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000586 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 48.073000\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tval_test's l2: 1314.02\n",
      "best l2 loss 1314.024817 at iteration 3 with num_leaves = 8 and min_data_in_leaf = 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000591 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 48.073000\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[3]\tval_test's l2: 1314.58\n",
      "best l2 loss 1314.576320 at iteration 3 with num_leaves = 8 and min_data_in_leaf = 400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000571 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 48.073000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[3]\tval_test's l2: 1308.22\n",
      "best l2 loss 1308.215457 at iteration 3 with num_leaves = 8 and min_data_in_leaf = 500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000595 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 48.073000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[4]\tval_test's l2: 1342.51\n",
      "best l2 loss 1342.510293 at iteration 4 with num_leaves = 8 and min_data_in_leaf = 1000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000593 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 48.073000\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tval_test's l2: 1294.47\n",
      "best l2 loss 1294.465034 at iteration 4 with num_leaves = 16 and min_data_in_leaf = 20\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000595 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 48.073000\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tval_test's l2: 1295.74\n",
      "best l2 loss 1295.740415 at iteration 4 with num_leaves = 16 and min_data_in_leaf = 50\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000598 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 48.073000\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tval_test's l2: 1295.9\n",
      "best l2 loss 1295.895360 at iteration 4 with num_leaves = 16 and min_data_in_leaf = 100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000609 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 48.073000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[4]\tval_test's l2: 1294.17\n",
      "best l2 loss 1294.166094 at iteration 4 with num_leaves = 16 and min_data_in_leaf = 200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000622 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 48.073000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[3]\tval_test's l2: 1308.88\n",
      "best l2 loss 1308.881607 at iteration 3 with num_leaves = 16 and min_data_in_leaf = 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000608 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 48.073000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[3]\tval_test's l2: 1313.39\n",
      "best l2 loss 1313.393361 at iteration 3 with num_leaves = 16 and min_data_in_leaf = 400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000870 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 48.073000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[3]\tval_test's l2: 1308.22\n",
      "best l2 loss 1308.215457 at iteration 3 with num_leaves = 16 and min_data_in_leaf = 500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000605 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 48.073000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[4]\tval_test's l2: 1342.51\n",
      "best l2 loss 1342.510293 at iteration 4 with num_leaves = 16 and min_data_in_leaf = 1000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000757 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 48.073000\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tval_test's l2: 1295.44\n",
      "best l2 loss 1295.443404 at iteration 4 with num_leaves = 32 and min_data_in_leaf = 20\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000586 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 48.073000\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tval_test's l2: 1296.52\n",
      "best l2 loss 1296.515366 at iteration 4 with num_leaves = 32 and min_data_in_leaf = 50\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000652 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 48.073000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[3]\tval_test's l2: 1298.66\n",
      "best l2 loss 1298.661524 at iteration 3 with num_leaves = 32 and min_data_in_leaf = 100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000652 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 48.073000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[4]\tval_test's l2: 1294.16\n",
      "best l2 loss 1294.163769 at iteration 4 with num_leaves = 32 and min_data_in_leaf = 200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000724 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 48.073000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[3]\tval_test's l2: 1308.88\n",
      "best l2 loss 1308.881607 at iteration 3 with num_leaves = 32 and min_data_in_leaf = 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000613 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 48.073000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[3]\tval_test's l2: 1313.39\n",
      "best l2 loss 1313.393361 at iteration 3 with num_leaves = 32 and min_data_in_leaf = 400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000679 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 48.073000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[3]\tval_test's l2: 1308.22\n",
      "best l2 loss 1308.215457 at iteration 3 with num_leaves = 32 and min_data_in_leaf = 500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000523 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 48.073000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[4]\tval_test's l2: 1342.51\n",
      "best l2 loss 1342.510293 at iteration 4 with num_leaves = 32 and min_data_in_leaf = 1000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000599 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 48.073000\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tval_test's l2: 1293.65\n",
      "best l2 loss 1293.646032 at iteration 4 with num_leaves = 64 and min_data_in_leaf = 20\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000798 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 48.073000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[4]\tval_test's l2: 1294.78\n",
      "best l2 loss 1294.780765 at iteration 4 with num_leaves = 64 and min_data_in_leaf = 50\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000738 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 48.073000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[3]\tval_test's l2: 1298.66\n",
      "best l2 loss 1298.661524 at iteration 3 with num_leaves = 64 and min_data_in_leaf = 100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000606 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 48.073000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[4]\tval_test's l2: 1294.16\n",
      "best l2 loss 1294.163769 at iteration 4 with num_leaves = 64 and min_data_in_leaf = 200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000603 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 48.073000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[3]\tval_test's l2: 1308.88\n",
      "best l2 loss 1308.881607 at iteration 3 with num_leaves = 64 and min_data_in_leaf = 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000692 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 48.073000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[3]\tval_test's l2: 1313.39\n",
      "best l2 loss 1313.393361 at iteration 3 with num_leaves = 64 and min_data_in_leaf = 400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000584 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 48.073000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[3]\tval_test's l2: 1308.22\n",
      "best l2 loss 1308.215457 at iteration 3 with num_leaves = 64 and min_data_in_leaf = 500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000582 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 48.073000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[4]\tval_test's l2: 1342.51\n",
      "best l2 loss 1342.510293 at iteration 4 with num_leaves = 64 and min_data_in_leaf = 1000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000641 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 48.073000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[4]\tval_test's l2: 1293.73\n",
      "best l2 loss 1293.725350 at iteration 4 with num_leaves = 128 and min_data_in_leaf = 20\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000986 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 48.073000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[4]\tval_test's l2: 1294.78\n",
      "best l2 loss 1294.780765 at iteration 4 with num_leaves = 128 and min_data_in_leaf = 50\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000642 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 48.073000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[3]\tval_test's l2: 1298.66\n",
      "best l2 loss 1298.661524 at iteration 3 with num_leaves = 128 and min_data_in_leaf = 100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000576 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 48.073000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[4]\tval_test's l2: 1294.16\n",
      "best l2 loss 1294.163769 at iteration 4 with num_leaves = 128 and min_data_in_leaf = 200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000633 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 48.073000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[3]\tval_test's l2: 1308.88\n",
      "best l2 loss 1308.881607 at iteration 3 with num_leaves = 128 and min_data_in_leaf = 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000695 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 48.073000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[3]\tval_test's l2: 1313.39\n",
      "best l2 loss 1313.393361 at iteration 3 with num_leaves = 128 and min_data_in_leaf = 400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000647 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 48.073000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[3]\tval_test's l2: 1308.22\n",
      "best l2 loss 1308.215457 at iteration 3 with num_leaves = 128 and min_data_in_leaf = 500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000681 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 48.073000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[4]\tval_test's l2: 1342.51\n",
      "best l2 loss 1342.510293 at iteration 4 with num_leaves = 128 and min_data_in_leaf = 1000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000702 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 48.073000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[4]\tval_test's l2: 1293.73\n",
      "best l2 loss 1293.725350 at iteration 4 with num_leaves = 256 and min_data_in_leaf = 20\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000772 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 48.073000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[4]\tval_test's l2: 1294.78\n",
      "best l2 loss 1294.780765 at iteration 4 with num_leaves = 256 and min_data_in_leaf = 50\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000699 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 48.073000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[3]\tval_test's l2: 1298.66\n",
      "best l2 loss 1298.661524 at iteration 3 with num_leaves = 256 and min_data_in_leaf = 100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000584 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 48.073000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[4]\tval_test's l2: 1294.16\n",
      "best l2 loss 1294.163769 at iteration 4 with num_leaves = 256 and min_data_in_leaf = 200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001268 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 48.073000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[3]\tval_test's l2: 1308.88\n",
      "best l2 loss 1308.881607 at iteration 3 with num_leaves = 256 and min_data_in_leaf = 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000792 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 48.073000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[3]\tval_test's l2: 1313.39\n",
      "best l2 loss 1313.393361 at iteration 3 with num_leaves = 256 and min_data_in_leaf = 400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000569 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 48.073000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[3]\tval_test's l2: 1308.22\n",
      "best l2 loss 1308.215457 at iteration 3 with num_leaves = 256 and min_data_in_leaf = 500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000597 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 48.073000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[4]\tval_test's l2: 1342.51\n",
      "best l2 loss 1342.510293 at iteration 4 with num_leaves = 256 and min_data_in_leaf = 1000\n"
     ]
    }
   ],
   "source": [
    "num_leaves_options = [4, 8, 16, 32, 64, 128, 256]\n",
    "min_data_in_leaf_options = [20, 50, 100, 200, 300, 400, 500, 1000]\n",
    "for num_leaves in num_leaves_options:\n",
    "    for min_data_in_leaf in min_data_in_leaf_options:\n",
    "        try_params = params.copy()\n",
    "        try_params.update({'num_leaves': num_leaves, 'min_data_in_leaf': min_data_in_leaf})\n",
    "        l2, best_iteration = get_eval_result(try_params)\n",
    "        print(\"best l2 loss %.6f at iteration %d with num_leaves = %d and min_data_in_leaf = %d\" % \n",
    "              (l2, best_iteration, num_leaves, min_data_in_leaf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们发现，num_leaves=4并且min_data_in_leaf=20的时候结果是最好的。接下来我们调整学习率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000897 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 48.073000\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[37]\tval_test's l2: 1289.6\n",
      "best l2 loss 1289.601534 at iteration 37 with learning_rate = 0.010000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000606 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 48.073000\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\tval_test's l2: 1288.93\n",
      "best l2 loss 1288.925424 at iteration 19 with learning_rate = 0.020000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000636 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 48.073000\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\tval_test's l2: 1289.97\n",
      "best l2 loss 1289.967629 at iteration 13 with learning_rate = 0.030000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000612 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 48.073000\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tval_test's l2: 1290.32\n",
      "best l2 loss 1290.317775 at iteration 8 with learning_rate = 0.050000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000618 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6032\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 48.073000\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tval_test's l2: 1286.71\n",
      "best l2 loss 1286.708644 at iteration 4 with learning_rate = 0.100000\n"
     ]
    }
   ],
   "source": [
    "params.update({'num_leaves': 4, 'min_data_in_leaf':400})\n",
    "learning_rate_options = [0.01, 0.02, 0.03, 0.05, 0.1]\n",
    "for learning_rate in learning_rate_options:\n",
    "    try_params = params.copy()\n",
    "    try_params.update({'learning_rate': learning_rate})\n",
    "    l2, best_iteration = get_eval_result(try_params)\n",
    "    print(\"best l2 loss %.6f at iteration %d with learning_rate = %f\" % (l2, best_iteration, learning_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可见learning_rate=0.1且迭代次数为4是最好的。我们使用搜索出的最优超参，在全部训练集上进行训练，并观察测试集的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义评价指标 SMAPE 函数\n",
    "ep = 0.0000000001\n",
    "def smape(y_pred, y_true):\n",
    "    return np.mean(np.abs(y_pred - y_true) / (  ( np.abs(y_pred) + np.abs(y_true) ) / 2  ) + ep )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000677 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6033\n",
      "[LightGBM] [Info] Number of data points in the train set: 4425, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 47.997740\n"
     ]
    }
   ],
   "source": [
    "params.update({'learning_rate':0.1, 'num_trees':3})\n",
    "model = lgb.train(params=params,\n",
    "                      train_set=train_set)\n",
    "score = model.predict(test_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([36.89403073, 36.89403073, 36.89403073, ..., 36.89403073,\n",
       "       36.89403073, 36.89403073])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102</th>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1107 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0\n",
       "0      2.0\n",
       "1      3.0\n",
       "2      2.0\n",
       "3      3.0\n",
       "4      2.0\n",
       "...    ...\n",
       "1102  11.0\n",
       "1103  14.0\n",
       "1104   6.0\n",
       "1105   2.0\n",
       "1106   8.0\n",
       "\n",
       "[1107 rows x 1 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = pd.Series(test_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_loss = np.mean((score - test_y) ** 2)\n",
    "l2_smape_loss = smape(score,test_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l2_loss: 727.0448864096091\n",
      "l2_smape_loss: 0.6389564749310152\n"
     ]
    }
   ],
   "source": [
    "print(\"l2_loss:\",l2_loss)\n",
    "print(\"l2_smape_loss:\",l2_smape_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
