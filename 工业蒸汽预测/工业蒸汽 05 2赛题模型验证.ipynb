{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 1 模型过拟合与欠拟合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 基础代码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入工具包，用于模型验证和数据处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns # 可视化 用于创建各种类型的统计图形\n",
    "\n",
    "from scipy import stats # 用于统计分析\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.linear_model import LinearRegression  #线性回归\n",
    "from sklearn.neighbors import KNeighborsRegressor  #K近邻回归\n",
    "from sklearn.tree import DecisionTreeRegressor     #决策树回归\n",
    "from sklearn.ensemble import RandomForestRegressor #随机森林回归\n",
    "from sklearn.svm import SVR  #支持向量回归\n",
    "import lightgbm as lgb #lightGbm模型\n",
    "\n",
    "from sklearn.model_selection import train_test_split # 切分数据\n",
    "from sklearn.metrics import mean_squared_error #评价指标\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor # 随机梯度下降线性回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_file = \"./data/zhengqi_train.txt\"\n",
    "test_data_file =  \"./data/zhengqi_test.txt\"\n",
    "\n",
    "train_data = pd.read_csv(train_data_file, sep='\\t', encoding='utf-8')\n",
    "test_data = pd.read_csv(test_data_file, sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V0</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V29</th>\n",
       "      <th>V30</th>\n",
       "      <th>V31</th>\n",
       "      <th>V32</th>\n",
       "      <th>V33</th>\n",
       "      <th>V34</th>\n",
       "      <th>V35</th>\n",
       "      <th>V36</th>\n",
       "      <th>V37</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.566</td>\n",
       "      <td>0.016</td>\n",
       "      <td>-0.143</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.452</td>\n",
       "      <td>-0.901</td>\n",
       "      <td>-1.812</td>\n",
       "      <td>-2.360</td>\n",
       "      <td>-0.436</td>\n",
       "      <td>-2.114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.109</td>\n",
       "      <td>-0.615</td>\n",
       "      <td>0.327</td>\n",
       "      <td>-4.627</td>\n",
       "      <td>-4.789</td>\n",
       "      <td>-5.101</td>\n",
       "      <td>-2.608</td>\n",
       "      <td>-3.508</td>\n",
       "      <td>0.175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.968</td>\n",
       "      <td>0.437</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.194</td>\n",
       "      <td>-0.893</td>\n",
       "      <td>-1.566</td>\n",
       "      <td>-2.360</td>\n",
       "      <td>0.332</td>\n",
       "      <td>-2.114</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.128</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.600</td>\n",
       "      <td>-0.843</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.364</td>\n",
       "      <td>-0.335</td>\n",
       "      <td>-0.730</td>\n",
       "      <td>0.676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.013</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.112</td>\n",
       "      <td>-0.797</td>\n",
       "      <td>-1.367</td>\n",
       "      <td>-2.360</td>\n",
       "      <td>0.396</td>\n",
       "      <td>-2.114</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.277</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>-0.843</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.765</td>\n",
       "      <td>-0.589</td>\n",
       "      <td>0.633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.733</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.283</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.599</td>\n",
       "      <td>-0.679</td>\n",
       "      <td>-1.200</td>\n",
       "      <td>-2.086</td>\n",
       "      <td>0.403</td>\n",
       "      <td>-2.114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.603</td>\n",
       "      <td>-0.843</td>\n",
       "      <td>-0.065</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.333</td>\n",
       "      <td>-0.112</td>\n",
       "      <td>0.206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.684</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.337</td>\n",
       "      <td>-0.454</td>\n",
       "      <td>-1.073</td>\n",
       "      <td>-2.086</td>\n",
       "      <td>0.314</td>\n",
       "      <td>-2.114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.183</td>\n",
       "      <td>1.078</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.418</td>\n",
       "      <td>-0.843</td>\n",
       "      <td>-0.215</td>\n",
       "      <td>0.364</td>\n",
       "      <td>-0.280</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>0.384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      V0     V1     V2     V3     V4     V5     V6     V7     V8     V9  ...  \\\n",
       "0  0.566  0.016 -0.143  0.407  0.452 -0.901 -1.812 -2.360 -0.436 -2.114  ...   \n",
       "1  0.968  0.437  0.066  0.566  0.194 -0.893 -1.566 -2.360  0.332 -2.114  ...   \n",
       "2  1.013  0.568  0.235  0.370  0.112 -0.797 -1.367 -2.360  0.396 -2.114  ...   \n",
       "3  0.733  0.368  0.283  0.165  0.599 -0.679 -1.200 -2.086  0.403 -2.114  ...   \n",
       "4  0.684  0.638  0.260  0.209  0.337 -0.454 -1.073 -2.086  0.314 -2.114  ...   \n",
       "\n",
       "     V29    V30    V31    V32    V33    V34    V35    V36    V37  target  \n",
       "0  0.136  0.109 -0.615  0.327 -4.627 -4.789 -5.101 -2.608 -3.508   0.175  \n",
       "1 -0.128  0.124  0.032  0.600 -0.843  0.160  0.364 -0.335 -0.730   0.676  \n",
       "2 -0.009  0.361  0.277 -0.116 -0.843  0.160  0.364  0.765 -0.589   0.633  \n",
       "3  0.015  0.417  0.279  0.603 -0.843 -0.065  0.364  0.333 -0.112   0.206  \n",
       "4  0.183  1.078  0.328  0.418 -0.843 -0.215  0.364 -0.280 -0.028   0.384  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "归一化处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing \n",
    "# 1读取特征名\n",
    "features_columns = [col for col in train_data.columns if col not in ['target']]\n",
    "# 2实例化\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "# 3训练集fit拟合\n",
    "min_max_scaler = min_max_scaler.fit(train_data[features_columns])\n",
    "# 4transform\n",
    "train_data_scaler = min_max_scaler.transform(train_data[features_columns])\n",
    "test_data_scaler = min_max_scaler.transform(test_data[features_columns])\n",
    "# 5转dataframe-设特征列名\n",
    "train_data_scaler = pd.DataFrame(train_data_scaler)\n",
    "train_data_scaler.columns = features_columns\n",
    "\n",
    "test_data_scaler = pd.DataFrame(test_data_scaler)\n",
    "test_data_scaler.columns = features_columns\n",
    "# 6添回target列\n",
    "train_data_scaler['target'] = train_data['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA处理，特征降维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA   #主成分分析法\n",
    "\n",
    "#PCA方法降维\n",
    "#保留16个主成分\n",
    "pca = PCA(n_components=16)\n",
    "new_train_pca_16 = pca.fit_transform(train_data_scaler.iloc[:,0:-1])\n",
    "new_test_pca_16 = pca.transform(test_data_scaler)\n",
    "new_train_pca_16 = pd.DataFrame(new_train_pca_16)\n",
    "new_test_pca_16 = pd.DataFrame(new_test_pca_16)\n",
    "new_train_pca_16['target'] = train_data_scaler['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#采用 pca 保留16维特征的数据\n",
    "new_train_pca_16 = new_train_pca_16.fillna(0)\n",
    "train = new_train_pca_16[new_test_pca_16.columns]\n",
    "target = new_train_pca_16['target']\n",
    "\n",
    "# 切分数据 训练数据80% 验证数据20%\n",
    "train_data,test_data,train_target,test_target=train_test_split(train,target,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 欠拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDRegressor train MSE:    0.15120805945139779\n",
      "SGDRegressor test MSE:    0.15557353657705472\n"
     ]
    }
   ],
   "source": [
    "clf = SGDRegressor(max_iter=500, tol=1e-2) \n",
    "clf.fit(train_data, train_target)\n",
    "score_train = mean_squared_error(train_target, clf.predict(train_data))\n",
    "score_test = mean_squared_error(test_target, clf.predict(test_data))\n",
    "print(\"SGDRegressor train MSE:   \", score_train)\n",
    "print(\"SGDRegressor test MSE:   \", score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 代码解释\n",
    "SGDRegressor 是一种基于梯度下降的线性回归模型，使用随机梯度下降算法进行参数估计适用于大规模数据集和高维特征。\n",
    "与传统的批量梯度下降不同，随机梯度下降每次迭代只使用一个样本或一小批样本来更新模型参数，从而减少了内存消耗和计算复杂度。\n",
    "\n",
    "主要参数：\n",
    "- loss: 损失函数的类型。可选参数有 'squared_loss'（平方损失，默认）、'huber'（Huber 损失）、'epsilon_insensitive'（ϵ-insensitive 损失）等。\n",
    "- penalty: 正则化项的类型。可选参数有 'l2'（L2 正则化，默认）、'l1'（L1 正则化）、'elasticnet'（弹性网正则化）等。\n",
    "- alpha: 正则化项的惩罚力度。默认为0.0001。\n",
    "- max_iter: 最大迭代次数。默认为1000。\n",
    "- learning_rate: 学习率的类型或大小。可选参数有 'constant'（恒定学习率）、'optimal'（最优学习率）、'invscaling'（逆标度学习率）等。\n",
    "- eta0: 初始学习率。默认为0.01。\n",
    "\n",
    "主要方法：\n",
    "- fit(X, y): 使用训练数据训练模型。\n",
    "- predict(X): 对新的输入数据进行预测。\n",
    "- score(X, y): 返回模型在给定测试数据上的 R^2 分数。\n",
    "\n",
    "\n",
    "在 SGDRegressor 中，`tol` 是用来控制迭代的停止条件的参数。tol（tolerance）表示容忍度，即当损失函数的变化小于 tol 时，算法会停止迭代。`tol=1e-2` 表示容忍度为 0.01。也就是说，当连续两次迭代的损失函数值之差小于 0.01 时，算法会认为模型已经收敛，并且提前结束迭代，不再继续优化。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 过拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDRegressor train MSE:    0.1331534338938716\n",
      "SGDRegressor test MSE:    0.14569967267109368\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures # 用于进行多项式特征转换。\n",
    "poly = PolynomialFeatures(5)\n",
    "train_data_poly = poly.fit_transform(train_data)\n",
    "test_data_poly = poly.transform(test_data)\n",
    "clf = SGDRegressor(max_iter=1000, tol=1e-3) \n",
    "clf.fit(train_data_poly, train_target)\n",
    "score_train = mean_squared_error(train_target, clf.predict(train_data_poly))\n",
    "score_test = mean_squared_error(test_target, clf.predict(test_data_poly))\n",
    "print(\"SGDRegressor train MSE:   \", score_train)\n",
    "print(\"SGDRegressor test MSE:   \", score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4正常拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDRegressor train MSE:    0.13411423459723712\n",
      "SGDRegressor test MSE:    0.14259016962618046\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(3)\n",
    "train_data_poly = poly.fit_transform(train_data)\n",
    "test_data_poly = poly.transform(test_data)\n",
    "clf = SGDRegressor(max_iter=1000, tol=1e-3) \n",
    "clf.fit(train_data_poly, train_target)\n",
    "score_train = mean_squared_error(train_target, clf.predict(train_data_poly))\n",
    "score_test = mean_squared_error(test_target, clf.predict(test_data_poly))\n",
    "print(\"SGDRegressor train MSE:   \", score_train)\n",
    "print(\"SGDRegressor test MSE:   \", score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 代码解释\n",
    "`PolynomialFeatures` 是 scikit-learn（sklearn）库中的一个预处理类，用于生成多项式特征。它可以将原始特征转换为高阶多项式特征，从而扩展特征空间，使模型能够更好地拟合非线性关系。\n",
    "\n",
    "`PolynomialFeatures` 的主要作用是通过对原始特征进行多项式扩展，引入多项式交互项，从而增加模型的表示能力。对于给定的一组原始特征 x1, x2, ..., xn，`PolynomialFeatures` 将创建由这些特征的所有可能的多项式组合组成的新特征矩阵。\n",
    "\n",
    "`PolynomialFeatures` 可以生成包括以下几种特征的多项式：\n",
    "\n",
    "- 指数项：x^d （d 为指定的度数）\n",
    "- 交叉项：x1^i * x2^j * ... * xn^k （i + j + ... + k 不大于指定的度数）\n",
    "\n",
    "使用 `PolynomialFeatures` 的步骤如下：\n",
    "\n",
    "1. 创建 `PolynomialFeatures` 实例，并指定所需的度数。\n",
    "2. 使用 `fit_transform` 方法将原始特征数据集转换为多项式特征数据集。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 模型正则化\n",
    "\n",
    "正则化(Regularization)是给需要训练的目标函数加上一些规则（限制），目的是为了防止过拟合。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 L2范数正则化\n",
    "$$\n",
    "\\parallel x\\parallel_2=\\left(\\sum_{i=1}^n\\mid x_i\\mid^2\\right)^{\\frac{1}{2}}\n",
    "$$\n",
    "又叫欧几里得(Euclid)范数，即向量元素绝对值平方和再进行开方\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDRegressor train MSE:    0.13405366167472654\n",
      "SGDRegressor test MSE:    0.1425968901276022\n"
     ]
    }
   ],
   "source": [
    "poly = PolynomialFeatures(3)\n",
    "train_data_poly = poly.fit_transform(train_data)\n",
    "test_data_poly = poly.transform(test_data)\n",
    "clf = SGDRegressor(max_iter=1000, tol=1e-3, penalty= 'L2', alpha=0.0001) \n",
    "clf.fit(train_data_poly, train_target)\n",
    "score_train = mean_squared_error(train_target, clf.predict(train_data_poly))\n",
    "score_test = mean_squared_error(test_target, clf.predict(test_data_poly))\n",
    "print(\"SGDRegressor train MSE:   \", score_train)\n",
    "print(\"SGDRegressor test MSE:   \", score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 L1范数正则化\n",
    "$$\n",
    "\\parallel x\\parallel_1=\\sum_{i=1}^N\\mid x_i\\mid \n",
    "$$\n",
    "即向量元素绝对值之和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDRegressor train MSE:    0.1341760756452732\n",
      "SGDRegressor test MSE:    0.14289689287669896\n"
     ]
    }
   ],
   "source": [
    "poly = PolynomialFeatures(3)\n",
    "train_data_poly = poly.fit_transform(train_data)\n",
    "test_data_poly = poly.transform(test_data)\n",
    "clf = SGDRegressor(max_iter=1000, tol=1e-3, penalty= 'L1', alpha=0.00001) \n",
    "clf.fit(train_data_poly, train_target)\n",
    "score_train = mean_squared_error(train_target, clf.predict(train_data_poly))\n",
    "score_test = mean_squared_error(test_target, clf.predict(test_data_poly))\n",
    "print(\"SGDRegressor train MSE:   \", score_train)\n",
    "print(\"SGDRegressor test MSE:   \", score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 ElasticNet 联合 L1和L2范数加权正则化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDRegressor train MSE:    0.13411468070761007\n",
      "SGDRegressor test MSE:    0.14267147152205584\n"
     ]
    }
   ],
   "source": [
    "poly = PolynomialFeatures(3)\n",
    "train_data_poly = poly.fit_transform(train_data)\n",
    "test_data_poly = poly.transform(test_data)\n",
    "clf = SGDRegressor(max_iter=1000, tol=1e-3, penalty= 'elasticnet', l1_ratio=0.9, alpha=0.00001) \n",
    "clf.fit(train_data_poly, train_target)\n",
    "score_train = mean_squared_error(train_target, clf.predict(train_data_poly))\n",
    "score_test = mean_squared_error(test_target, clf.predict(test_data_poly))\n",
    "print(\"SGDRegressor train MSE:   \", score_train)\n",
    "print(\"SGDRegressor test MSE:   \", score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 代码解释\n",
    "\n",
    "1. `elasticnet`：是 `SGDRegressor` 的正则化方法之一。Elastic Net 是一种结合了 L1 正则化（Lasso）和 L2 正则化（Ridge）的线性回归模型正则化方法。通过引入两种正则化项，Elastic Net 可以在处理高维数据时具有特征选择的能力，并且可以克服 Lasso 存在的某些限制。默认情况下，`penalty` 参数被设置为 `'l2'`，即使用 L2 正则化；而设置为 `'elasticnet'` 则表示同时使用 L1 和 L2 正则化。\n",
    "\n",
    "2. `l1_ratio`：这是 Elastic Net 的混合参数，取值范围为 0 到 1 之间。它控制着 L1 正则化在 Elastic Net 中的比例。当 `l1_ratio` 为 0 时，相当于只使用 L2 正则化，而当 `l1_ratio` 为 1 时，相当于只使用 L1 正则化。在 0 和 1 之间的值表示混合使用两种正则化方法。在给定的示例中，`l1_ratio=0.9` 表示 Elastic Net 正则化主要使用 L1 正则化，较少使用 L2 正则化。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 模型交叉验证\n",
    "\n",
    "## 3.1 简单交叉验证 Hold-out-menthod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDRegressor train MSE:    0.14153466248845575\n",
      "SGDRegressor test MSE:    0.14704739394570965\n"
     ]
    }
   ],
   "source": [
    "# 简单交叉验证\n",
    "from sklearn.model_selection import train_test_split # 切分数据\n",
    "# 切分数据 训练数据80% 验证数据20%\n",
    "train_data,test_data,train_target,test_target=train_test_split(train,target,test_size=0.2,random_state=0)\n",
    "\n",
    "clf = SGDRegressor(max_iter=1000, tol=1e-3) \n",
    "clf.fit(train_data, train_target)\n",
    "score_train = mean_squared_error(train_target, clf.predict(train_data))\n",
    "score_test = mean_squared_error(test_target, clf.predict(test_data))\n",
    "print(\"SGDRegressor train MSE:   \", score_train)\n",
    "print(\"SGDRegressor test MSE:   \", score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 K折交叉验证 K-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  折 SGDRegressor train MSE:    0.14981785673534742\n",
      "0  折 SGDRegressor test MSE:    0.10625916839199373 \n",
      "\n",
      "1  折 SGDRegressor train MSE:    0.133562712911519\n",
      "1  折 SGDRegressor test MSE:    0.18214523287043694 \n",
      "\n",
      "2  折 SGDRegressor train MSE:    0.14710883577575967\n",
      "2  折 SGDRegressor test MSE:    0.13333375076428863 \n",
      "\n",
      "3  折 SGDRegressor train MSE:    0.1407417857258413\n",
      "3  折 SGDRegressor test MSE:    0.16241235381679514 \n",
      "\n",
      "4  折 SGDRegressor train MSE:    0.13808450887575016\n",
      "4  折 SGDRegressor test MSE:    0.1648578202917906 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5折交叉验证\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "for k, (train_index, test_index) in enumerate(kf.split(train)):\n",
    "    train_data,test_data,train_target,test_target = train.values[train_index],train.values[test_index],target[train_index],target[test_index]\n",
    "    clf = SGDRegressor(max_iter=1000, tol=1e-3) \n",
    "    clf.fit(train_data, train_target)\n",
    "    score_train = mean_squared_error(train_target, clf.predict(train_data))\n",
    "    score_test = mean_squared_error(test_target, clf.predict(test_data))\n",
    "    print(k, \" 折\", \"SGDRegressor train MSE:   \", score_train)\n",
    "    print(k, \" 折\", \"SGDRegressor test MSE:   \", score_test, '\\n')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 代码详解 -`KFold`函数\n",
    "`KFold` 是 scikit-learn 库中的一个交叉验证方法，用于划分数据集为 k 折，并生成相应的训练集和测试集索引。\n",
    "\n",
    "语法如下：\n",
    "\n",
    "```python\n",
    "sklearn.model_selection.KFold(n_splits, shuffle=False, random_state=None)\n",
    "```\n",
    "\n",
    "参数说明：\n",
    "- `n_splits`：表示将数据集划分为几个折（即 k 值），默认为 5。\n",
    "- `shuffle`（可选）：表示是否在划分之前对数据进行洗牌，默认为 False。如果设置为 True，则会在划分之前对数据进行洗牌以打乱顺序。\n",
    "- `random_state`（可选）：表示随机数种子，用于指定洗牌时的随机性。设置相同的随机数种子可以保证每次划分的结果一致。\n",
    "\n",
    "常用方法和属性：\n",
    "\n",
    "- `split(X[, y, groups])`：返回一个生成器对象，用于生成每个折的训练集和测试集索引。\n",
    "- `get_n_splits([X, y, groups])`：返回划分的折数（即 k 值）。\n",
    "\n",
    "例子：\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# 创建一个 KFold 对象\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "# 模拟一个数据集\n",
    "data = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "\n",
    "# 使用 KFold 进行划分\n",
    "for train_index, test_index in kf.split(data):\n",
    "    print(\"Train:\", train_index, \"Test:\", test_index)\n",
    "    \n",
    "for train_i,test_i in kf.split(data):\n",
    "    print(data[train_i],data[test_i])\n",
    "    print(\"---------\")\n",
    "```\n",
    "\n",
    "输出结果：\n",
    "```\n",
    "Train: [2 3 4 5 6 7 8 9] Test: [0 1]\n",
    "Train: [0 1 4 5 6 7 8 9] Test: [2 3]\n",
    "Train: [0 1 2 3 6 7 8 9] Test: [4 5]\n",
    "Train: [0 1 2 3 4 5 8 9] Test: [6 7]\n",
    "Train: [0 1 2 3 4 5 6 7] Test: [8 9]\n",
    "\n",
    "[3  4  5  6  7  8  9 10] [1 2]\n",
    "---------\n",
    "[1  2  5  6  7  8  9 10] [3 4]\n",
    "---------\n",
    "[1  2  3  4  7  8  9 10] [5 6]\n",
    "---------\n",
    "[1  2  3  4  5  6  9 10] [7 8]\n",
    "---------\n",
    "[1  2  3  4  5  6  7  8] [9 10]\n",
    "---------\n",
    "```\n",
    "\n",
    "在这个例子中，我们先创建了一个 `KFold` 对象 `kf`，将数据集 `data` 划分为 5 折交叉验证。然后，在循环中，我们使用 `kf.split(data)` 生成了每个折的训练集索引 `train_index` 和测试集索引 `test_index`。通过打印这些索引，我们可以看到每个折的训练集和测试集索引。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 代码详解 -`enumerate`函数\n",
    "用于将一个可迭代对象转换为一个枚举对象。它返回一个包含索引和元素的元组的迭代器。\n",
    "\n",
    "语法如下：\n",
    "\n",
    "```python\n",
    "enumerate(iterable, start=0)\n",
    "```\n",
    "\n",
    "- `iterable`：表示要进行枚举的可迭代对象，可以是列表、元组、字符串、集合等。\n",
    "- `start`（可选）：表示索引的起始值，默认为 0。\n",
    "\n",
    "当对一个可迭代对象使用 `enumerate` 函数时，它会返回一个生成器对象，每次迭代都会产生一个元组 `(index, element)`，其中 `index` 是当前元素的索引，从 `start` 开始递增，`element` 是对应的元素。\n",
    "\n",
    "例子：\n",
    "\n",
    "```python\n",
    "fruits = ['apple', 'banana', 'orange']\n",
    "\n",
    "for index, fruit in enumerate(fruits):\n",
    "    print(index, fruit)\n",
    "```\n",
    "\n",
    "输出结果：\n",
    "```\n",
    "0 apple\n",
    "1 banana\n",
    "2 orange\n",
    "```\n",
    "\n",
    "在例子中，我们使用 `enumerate` 对列表 `fruits` 进行枚举。在每次迭代中，`index` 表示元素的索引，`fruit` 表示对应的水果名称。通过打印 `index` 和 `fruit`，我们可以看到每个元素的索引和对应的水果名称。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 留一法 LOO CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  个 SGDRegressor train MSE:    0.1416580179524758\n",
      "0  个 SGDRegressor test MSE:    0.010223999832396254 \n",
      "\n",
      "1  个 SGDRegressor train MSE:    0.14163634051720275\n",
      "1  个 SGDRegressor test MSE:    0.11740687467896349 \n",
      "\n",
      "2  个 SGDRegressor train MSE:    0.14160255971754088\n",
      "2  个 SGDRegressor test MSE:    0.038511164208972805 \n",
      "\n",
      "3  个 SGDRegressor train MSE:    0.14171424665066576\n",
      "3  个 SGDRegressor test MSE:    0.0032671144219933086 \n",
      "\n",
      "4  个 SGDRegressor train MSE:    0.1415871206184853\n",
      "4  个 SGDRegressor test MSE:    0.011626980208807725 \n",
      "\n",
      "5  个 SGDRegressor train MSE:    0.1415859083059502\n",
      "5  个 SGDRegressor test MSE:    0.13684250563109712 \n",
      "\n",
      "6  个 SGDRegressor train MSE:    0.14146539859028415\n",
      "6  个 SGDRegressor test MSE:    0.02520351588864328 \n",
      "\n",
      "7  个 SGDRegressor train MSE:    0.1416141346350202\n",
      "7  个 SGDRegressor test MSE:    0.0010761193833298227 \n",
      "\n",
      "8  个 SGDRegressor train MSE:    0.1410039783015725\n",
      "8  个 SGDRegressor test MSE:    0.08343181857185722 \n",
      "\n",
      "9  个 SGDRegressor train MSE:    0.14153627511981529\n",
      "9  个 SGDRegressor test MSE:    0.05251253583018223 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "loo = LeaveOneOut()\n",
    "# num = 100\n",
    "for k, (train_index, test_index) in enumerate(loo.split(train)):\n",
    "    train_data,test_data,train_target,test_target = train.values[train_index],train.values[test_index],target[train_index],target[test_index]\n",
    "    clf = SGDRegressor(max_iter=1000, tol=1e-3) \n",
    "    clf.fit(train_data, train_target)\n",
    "    score_train = mean_squared_error(train_target, clf.predict(train_data))\n",
    "    score_test = mean_squared_error(test_target, clf.predict(test_data))\n",
    "    print(k, \" 个\", \"SGDRegressor train MSE:   \", score_train)\n",
    "    print(k, \" 个\", \"SGDRegressor test MSE:   \", score_test, '\\n') \n",
    "    if k >= 9: # k 大于等于 9时停止迭代\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 留P法 LPO CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  10个 SGDRegressor train MSE:    0.14202520800291124\n",
      "0  10个 SGDRegressor test MSE:    0.04886498124378371 \n",
      "\n",
      "1  10个 SGDRegressor train MSE:    0.14203752041349277\n",
      "1  10个 SGDRegressor test MSE:    0.045521294440001324 \n",
      "\n",
      "2  10个 SGDRegressor train MSE:    0.14198180297296764\n",
      "2  10个 SGDRegressor test MSE:    0.047209109806969386 \n",
      "\n",
      "3  10个 SGDRegressor train MSE:    0.14195569188036283\n",
      "3  10个 SGDRegressor test MSE:    0.05423002521313495 \n",
      "\n",
      "4  10个 SGDRegressor train MSE:    0.14185028991845955\n",
      "4  10个 SGDRegressor test MSE:    0.06901799971546987 \n",
      "\n",
      "5  10个 SGDRegressor train MSE:    0.14201273518218\n",
      "5  10个 SGDRegressor test MSE:    0.0447478630166654 \n",
      "\n",
      "6  10个 SGDRegressor train MSE:    0.1419891732237632\n",
      "6  10个 SGDRegressor test MSE:    0.04953265833338921 \n",
      "\n",
      "7  10个 SGDRegressor train MSE:    0.14193217655848653\n",
      "7  10个 SGDRegressor test MSE:    0.05323042636859763 \n",
      "\n",
      "8  10个 SGDRegressor train MSE:    0.1420557933128271\n",
      "8  10个 SGDRegressor test MSE:    0.04742538062352217 \n",
      "\n",
      "9  10个 SGDRegressor train MSE:    0.14201483242149396\n",
      "9  10个 SGDRegressor test MSE:    0.045352746805337234 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeavePOut\n",
    "lpo = LeavePOut(p=10)\n",
    "# num = 100\n",
    "for k, (train_index, test_index) in enumerate(lpo.split(train)):\n",
    "    train_data,test_data,train_target,test_target = train.values[train_index],train.values[test_index],target[train_index],target[test_index]\n",
    "    clf = SGDRegressor(max_iter=1000, tol=1e-3) \n",
    "    clf.fit(train_data, train_target)\n",
    "    score_train = mean_squared_error(train_target, clf.predict(train_data))\n",
    "    score_test = mean_squared_error(test_target, clf.predict(test_data))\n",
    "    print(k, \" 10个\", \"SGDRegressor train MSE:   \", score_train)\n",
    "    print(k, \" 10个\", \"SGDRegressor test MSE:   \", score_test, '\\n') \n",
    "    if k >= 9: # k 大于等于 9时停止迭代。\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 留P交叉验证 和 K折交叉验证\n",
    "区别和特点如下：\n",
    "\n",
    "- 样本划分：留 P 交叉验证按照固定数量 P 的样本划分为测试集，剩余的样本为训练集；K 折交叉验证按照 K 个折的划分将数据集划分为测试集和训练集。\n",
    "- 迭代次数：留 P 交叉验证的迭代次数取决于样本组合的可能性，通常较大；K 折交叉验证的迭代次数为 K，通常较小。\n",
    "- 样本重复：留 P 交叉验证每个样本只出现一次作为测试集，可能会有样本重复出现在训练集中；K 折交叉验证每个样本会被分到不同的训练集和测试集中，避免了样本的重复。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4模型超参空间及调参\n",
    "\n",
    "## 4.1穷举网格搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split # 切分数据\n",
    "# 切分数据 训练数据80% 验证数据20%\n",
    "train_data,test_data,train_target,test_target=train_test_split(train,target,test_size=0.2,random_state=0)\n",
    "\n",
    "randomForestRegressor = RandomForestRegressor()\n",
    "parameters = {\n",
    "              'n_estimators':[50, 100, 200],\n",
    "              'max_depth':[1, 2, 3]\n",
    "        }\n",
    "\n",
    "\n",
    "clf = GridSearchCV(randomForestRegressor, parameters, cv=5)\n",
    "clf.fit(train_data, train_target)\n",
    "\n",
    "score_test = mean_squared_error(test_target, clf.predict(test_data))\n",
    "\n",
    "print(\"RandomForestRegressor GridSearchCV test MSE:   \", score_test)\n",
    "sorted(clf.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 随机参数优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split # 切分数据\n",
    "# 切分数据 训练数据80% 验证数据20%\n",
    "train_data,test_data,train_target,test_target=train_test_split(train,target,test_size=0.2,random_state=0)\n",
    "\n",
    "randomForestRegressor = RandomForestRegressor()\n",
    "parameters = {\n",
    "              'n_estimators':[50, 100, 200, 300],\n",
    "              'max_depth':[1, 2, 3, 4, 5]\n",
    "        }\n",
    "\n",
    "\n",
    "clf = RandomizedSearchCV(randomForestRegressor, parameters, cv=5)\n",
    "clf.fit(train_data, train_target)\n",
    "\n",
    "score_test = mean_squared_error(test_target, clf.predict(test_data))\n",
    "\n",
    "print(\"RandomForestRegressor RandomizedSearchCV test MSE:   \", score_test)\n",
    "sorted(clf.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Lgb 调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = lgb.LGBMRegressor(num_leaves=31)\n",
    "\n",
    "parameters = {\n",
    "    'learning_rate': [0.01, 0.1, 1],\n",
    "    'n_estimators': [20, 40]\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(clf, parameters, cv=5)\n",
    "clf.fit(train_data, train_target)\n",
    "\n",
    "print('Best parameters found by grid search are:', clf.best_params_)\n",
    "score_test = mean_squared_error(test_target, clf.predict(test_data))\n",
    "print(\"LGBMRegressor RandomizedSearchCV test MSE:   \", score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Lgb 线下验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data2 = pd.read_csv('./zhengqi_train.txt',sep='\\t')\n",
    "test_data2 = pd.read_csv('./zhengqi_test.txt',sep='\\t')\n",
    "\n",
    "train_data2_f = train_data2[test_data2.columns].values\n",
    "train_data2_target = train_data2['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lgb 模型\n",
    "from sklearn.model_selection  import KFold\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 5折交叉验证\n",
    "Folds=5\n",
    "kf = KFold(len(train_data2_f), n_splits=Folds, random_state=100, shuffle=True)\n",
    "# 记录训练和预测MSE\n",
    "MSE_DICT = {\n",
    "    'train_mse':[],\n",
    "    'test_mse':[]\n",
    "}\n",
    "\n",
    "# 线下训练预测\n",
    "for i, (train_index, test_index) in enumerate(kf.split(train_data2_f)):\n",
    "    # lgb树模型\n",
    "    lgb_reg = lgb.LGBMRegressor(\n",
    "        learning_rate=0.01,\n",
    "        max_depth=-1,\n",
    "        n_estimators=100,\n",
    "        boosting_type='gbdt',\n",
    "        random_state=100,\n",
    "        objective='regression',\n",
    "    )\n",
    "   \n",
    "    # 切分训练集和预测集\n",
    "    X_train_KFold, X_test_KFold = train_data2_f[train_index], train_data2_f[test_index]\n",
    "    y_train_KFold, y_test_KFold = train_data2_target[train_index], train_data2_target[test_index]\n",
    "    \n",
    "    # 训练模型\n",
    "#     reg.fit(X_train_KFold, y_train_KFold)\n",
    "    lgb_reg.fit(\n",
    "            X=X_train_KFold,y=y_train_KFold,\n",
    "            eval_set=[(X_train_KFold, y_train_KFold),(X_test_KFold, y_test_KFold)],\n",
    "            eval_names=['Train','Test'],\n",
    "            early_stopping_rounds=100,\n",
    "            eval_metric='MSE',\n",
    "            verbose=50\n",
    "        )\n",
    "\n",
    "\n",
    "    # 训练集预测 测试集预测\n",
    "    y_train_KFold_predict = lgb_reg.predict(X_train_KFold,num_iteration=lgb_reg.best_iteration_)\n",
    "    y_test_KFold_predict = lgb_reg.predict(X_test_KFold,num_iteration=lgb_reg.best_iteration_) \n",
    "    \n",
    "    print('第{}折 训练和预测 训练MSE 预测MSE'.format(i))\n",
    "    train_mse = mean_squared_error(y_train_KFold_predict, y_train_KFold)\n",
    "    print('------\\n', '训练MSE\\n', train_mse, '\\n------')\n",
    "    test_mse = mean_squared_error(y_test_KFold_predict, y_test_KFold)\n",
    "    print('------\\n', '预测MSE\\n', test_mse, '\\n------\\n')\n",
    "    \n",
    "    MSE_DICT['train_mse'].append(train_mse)\n",
    "    MSE_DICT['test_mse'].append(test_mse)\n",
    "print('------\\n', '训练MSE\\n', MSE_DICT['train_mse'], '\\n', np.mean(MSE_DICT['train_mse']), '\\n------')\n",
    "print('------\\n', '预测MSE\\n', MSE_DICT['test_mse'], '\\n', np.mean(MSE_DICT['test_mse']), '\\n------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 学习曲线和验证曲线\n",
    "\n",
    "## 5.1 学习曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(__doc__)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection \n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "\n",
    "X = train_data2[test_data2.columns].values\n",
    "y = train_data2['target'].values\n",
    "\n",
    "\n",
    "title = \"LinearRegression\"\n",
    "# Cross validation with 100 iterations to get smoother mean test and train\n",
    "# score curves, each time with 20% data randomly selected as a validation set.\n",
    "cv = model_selection.ShuffleSplit(X.shape[0], n_splits=100,\n",
    "                                   test_size=0.2, random_state=0)\n",
    "\n",
    "estimator = SGDRegressor()\n",
    "plot_learning_curve(estimator, title, X, y, ylim=(0.7, 1.01), cv=cv, n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 验证曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "X = train_data2[test_data2.columns].values\n",
    "y = train_data2['target'].values\n",
    "# max_iter=1000, tol=1e-3, penalty= 'L1', alpha=0.00001\n",
    "\n",
    "param_range = [0.1, 0.01, 0.001, 0.0001, 0.00001, 0.000001]\n",
    "train_scores, test_scores = validation_curve(\n",
    "    SGDRegressor(max_iter=1000, tol=1e-3, penalty= 'L1'), X, y, param_name=\"alpha\", param_range=param_range,\n",
    "    cv=10, scoring='r2', n_jobs=1)\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.title(\"Validation Curve with SGDRegressor\")\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0.0, 1.1)\n",
    "plt.semilogx(param_range, train_scores_mean, label=\"Training score\", color=\"r\")\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.2, color=\"r\")\n",
    "plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "             color=\"g\")\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.2, color=\"g\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
