{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 导包读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "import seaborn as sns\n",
    "\n",
    "# modelling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedKFold, cross_val_score,cross_val_predict,KFold\n",
    "from sklearn.metrics import make_scorer,mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.svm import LinearSVR, SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor,AdaBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures,MinMaxScaler,StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Default</th>\n",
       "      <th>age</th>\n",
       "      <th>card_age</th>\n",
       "      <th>cashAmt_mean</th>\n",
       "      <th>cashAmt_non_null_months</th>\n",
       "      <th>cashCnt_mean</th>\n",
       "      <th>cashCnt_non_null_months</th>\n",
       "      <th>cashTotalAmt</th>\n",
       "      <th>cashTotalCnt</th>\n",
       "      <th>inCourt</th>\n",
       "      <th>...</th>\n",
       "      <th>sex_2</th>\n",
       "      <th>CityId_1</th>\n",
       "      <th>CityId_2</th>\n",
       "      <th>CityId_3</th>\n",
       "      <th>trans_total</th>\n",
       "      <th>total_withdraw</th>\n",
       "      <th>avg_per_withdraw</th>\n",
       "      <th>avg_per_online_spend</th>\n",
       "      <th>avg_per_public_spend</th>\n",
       "      <th>bad_record</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3855.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>19</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>233.333333</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>792.962962</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4219.487179</td>\n",
       "      <td>385.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>13</td>\n",
       "      <td>22000.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>22000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42012.000000</td>\n",
       "      <td>132000.000000</td>\n",
       "      <td>3666.666667</td>\n",
       "      <td>1808.571429</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1515.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-350.666667</td>\n",
       "      <td>521.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7340.937500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1639.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>47</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>70</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>69</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>59</td>\n",
       "      <td>366.666667</td>\n",
       "      <td>3</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>3</td>\n",
       "      <td>1100</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32971.735540</td>\n",
       "      <td>611.111111</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>3028.611111</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>425 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Default  age  card_age  cashAmt_mean  cashAmt_non_null_months  \\\n",
       "0          0   38         2      0.000000                        0   \n",
       "1          0   39        19      0.000000                        0   \n",
       "2          0   40        16      0.000000                        0   \n",
       "3          0   38        13  22000.000000                        1   \n",
       "4          0   24         8      0.000000                        0   \n",
       "..       ...  ...       ...           ...                      ...   \n",
       "420        0   30        12      0.000000                        0   \n",
       "421        0   40        47      0.000000                        0   \n",
       "422        0   30        70    100.000000                        1   \n",
       "423        0   28        69      0.000000                        0   \n",
       "424        0   24        59    366.666667                        3   \n",
       "\n",
       "     cashCnt_mean  cashCnt_non_null_months  cashTotalAmt  cashTotalCnt  \\\n",
       "0        0.000000                        0             0             0   \n",
       "1        0.000000                        0             0             0   \n",
       "2        0.000000                        0             0             0   \n",
       "3        6.000000                        1         22000             6   \n",
       "4        0.000000                        0             0             0   \n",
       "..            ...                      ...           ...           ...   \n",
       "420      0.000000                        0             0             0   \n",
       "421      0.000000                        0             0             0   \n",
       "422      1.000000                        1           100             1   \n",
       "423      0.000000                        0             0             0   \n",
       "424      1.666667                        3          1100             5   \n",
       "\n",
       "     inCourt  ...  sex_2  CityId_1  CityId_2  CityId_3   trans_total  \\\n",
       "0          0  ...      1         1         0         0      0.000000   \n",
       "1          0  ...      0         1         0         0    180.000000   \n",
       "2          0  ...      1         0         1         0    792.962962   \n",
       "3          0  ...      0         0         0         1  42012.000000   \n",
       "4          0  ...      0         0         1         0   1515.600000   \n",
       "..       ...  ...    ...       ...       ...       ...           ...   \n",
       "420        0  ...      0         1         0         0   7340.937500   \n",
       "421        0  ...      1         0         1         0      0.000000   \n",
       "422        0  ...      0         0         0         1      0.000000   \n",
       "423        0  ...      0         0         0         1      0.000000   \n",
       "424        0  ...      0         0         1         0  32971.735540   \n",
       "\n",
       "     total_withdraw  avg_per_withdraw  avg_per_online_spend  \\\n",
       "0          0.000000          0.000000          -3855.000000   \n",
       "1          0.000000          0.000000            233.333333   \n",
       "2          0.000000          0.000000          -4219.487179   \n",
       "3     132000.000000       3666.666667           1808.571429   \n",
       "4          0.000000          0.000000           -350.666667   \n",
       "..              ...               ...                   ...   \n",
       "420        0.000000          0.000000           1639.000000   \n",
       "421        0.000000          0.000000              0.000000   \n",
       "422      100.000000        100.000000              0.000000   \n",
       "423        0.000000          0.000000              0.000000   \n",
       "424      611.111111        220.000000           3028.611111   \n",
       "\n",
       "     avg_per_public_spend  bad_record  \n",
       "0                    0.00           0  \n",
       "1                    0.00           0  \n",
       "2                  385.00           0  \n",
       "3                    0.00           0  \n",
       "4                  521.25           0  \n",
       "..                    ...         ...  \n",
       "420                  0.00           0  \n",
       "421                  0.00           0  \n",
       "422                  0.00           0  \n",
       "423                  0.00           0  \n",
       "424                  0.00           0  \n",
       "\n",
       "[425 rows x 59 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/datapandaszhibiao.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 划分训练集测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the dataset\n",
    "def Split_data(df):\n",
    "    training_size = int(len(df)*0.90)\n",
    "    data_len = len(df)\n",
    "    train, test = df[0:training_size],df[training_size:data_len] \n",
    "    return train, test\n",
    "#Splitting the training and test datasets \n",
    "df_train, df_test = Split_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 训练模型 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "# metric for evaluation\n",
    "def rmse(y_true, y_pred):\n",
    "    diff = y_pred - y_true\n",
    "    sum_sq = sum(diff**2)    \n",
    "    n = len(y_pred)   \n",
    "    return np.sqrt(sum_sq/n)\n",
    "\n",
    "def mse(y_ture,y_pred):\n",
    "    return mean_squared_error(y_ture,y_pred)\n",
    "\n",
    "# scorer to be used in sklearn model fitting\n",
    "rmse_scorer = make_scorer(rmse, greater_is_better=False)\n",
    "mse_scorer = make_scorer(mse, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_columns = [col for col in df.columns if col not in ['Default']]\n",
    "df_train_X = df_train[features_columns].values\n",
    "df_train_y =df_train['Default'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_train_X, df_train_y, test_size=0.7, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the train data\n",
    "def copy_trainning_data():\n",
    "    X1=X_train.copy()\n",
    "    y1=y_train.copy()\n",
    "    return X1,y1\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# function to  train the model\n",
    "def train_model(model, param_grid=[], X=[], y=[], \n",
    "                splits=5, repeats=5):\n",
    "\n",
    "    # get unmodified training data, unless data to use already specified\n",
    "    if len(y)==0:\n",
    "        X,y = copy_trainning_data()\n",
    "        #poly_trans=PolynomialFeatures(degree=2)\n",
    "        #X=poly_trans.fit_transform(X)\n",
    "        #X=MinMaxScaler().fit_transform(X)\n",
    "    \n",
    "    # create cross-validation method\n",
    "    rkfold = RepeatedKFold(n_splits=splits, n_repeats=repeats)\n",
    "    \n",
    "    # perform a grid search if param_grid given\n",
    "    if len(param_grid)>0:\n",
    "        # setup grid search parameters\n",
    "        gsearch = GridSearchCV(model, param_grid, cv=rkfold,\n",
    "                               scoring=\"neg_mean_squared_error\",\n",
    "                               verbose=1, return_train_score=True)\n",
    "\n",
    "        # search the grid\n",
    "        gsearch.fit(X,y)\n",
    "\n",
    "        # extract best model from the grid\n",
    "        model = gsearch.best_estimator_  # 最优模型      \n",
    "        best_idx = gsearch.best_index_ # 最优超参数组合的索引值\n",
    "\n",
    "        # get cv-scores for best model\n",
    "        grid_results = pd.DataFrame(gsearch.cv_results_) # 网格搜索过程中每个超参数组合的详细统计数据，例如训练时间、验证得分等。      \n",
    "        cv_mean = abs(grid_results.loc[best_idx,'mean_test_score']) # 平均测试得分\n",
    "        cv_std = grid_results.loc[best_idx,'std_test_score'] # 测试得分标准差\n",
    "\n",
    "    # no grid search, just cross-val score for given model    \n",
    "    else:\n",
    "        grid_results = []\n",
    "        cv_results = cross_val_score(model, X, y, scoring=\"neg_mean_squared_error\", cv=rkfold)\n",
    "        cv_mean = abs(np.mean(cv_results))\n",
    "        cv_std = np.std(cv_results)\n",
    "    \n",
    "    # combine mean and std cv-score in to a pandas series\n",
    "    cv_score = pd.Series({'mean':cv_mean,'std':cv_std}) # return cv_score\n",
    "\n",
    "    # predict y using the fitted model\n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "    # print stats on model performance         \n",
    "    print('----------------------')\n",
    "    print(model)\n",
    "    print('----------------------')\n",
    "    print('score=',model.score(X,y))\n",
    "    print('rmse=',rmse(y, y_pred))\n",
    "    print('mse=',mse(y, y_pred))\n",
    "    print('cross_val: mean=',cv_mean,', std=',cv_std)\n",
    "    \n",
    "    '''  \n",
    "    # 误差\n",
    "    # residual plots\n",
    "    y_pred = pd.Series(y_pred,index=y.index)\n",
    "    resid = y - y_pred\n",
    "    mean_resid = resid.mean()\n",
    "    std_resid = resid.std()\n",
    "    z = (resid - mean_resid)/std_resid    \n",
    "    n_outliers = sum(abs(z)>3)\n",
    "    \n",
    "       \n",
    "    plt.figure(figsize=(15,5))\n",
    "    ax_131 = plt.subplot(1,3,1)\n",
    "    plt.plot(y,y_pred,'.')\n",
    "    plt.xlabel('y')\n",
    "    plt.ylabel('y_pred');\n",
    "    plt.title('corr = {:.3f}'.format(np.corrcoef(y,y_pred)[0][1]))\n",
    "    ax_132=plt.subplot(1,3,2)\n",
    "    plt.plot(y,y-y_pred,'.')\n",
    "    plt.xlabel('y')\n",
    "    plt.ylabel('y - y_pred');\n",
    "    plt.title('std resid = {:.3f}'.format(std_resid))\n",
    "    \n",
    "    ax_133=plt.subplot(1,3,3)\n",
    "    z.plot.hist(bins=50,ax=ax_133)\n",
    "    plt.xlabel('z')\n",
    "    plt.title('{:.0f} samples with z>3'.format(n_outliers))\n",
    "'''\n",
    "\n",
    "    return model, cv_score, grid_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# places to store optimal models and scores\n",
    "opt_models = dict()\n",
    "score_models = pd.DataFrame(columns=['mean','std'])\n",
    "\n",
    "# no. k-fold splits\n",
    "splits=5\n",
    "# no. k-fold iterations\n",
    "repeats=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 25 folds for each of 23 candidates, totalling 575 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------\n",
      "Ridge()\n",
      "----------------------\n",
      "score= 0.9400849157433285\n",
      "rmse= 0.09309838784104316\n",
      "mse= 0.008667309818601296\n",
      "cross_val: mean= 0.0857424560908498 , std= 0.08626728022588105\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n# 用于表现有一定置信区间的带误差数据\\nplt.figure() \\nplt.errorbar(alph_range, abs(grid_results['mean_test_score']),\\n             abs(grid_results['std_test_score'])/np.sqrt(splits*repeats))\\nplt.xlabel('alpha')\\nplt.ylabel('score')\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = 'Ridge'\n",
    "\n",
    "opt_models[model] = Ridge()\n",
    "alph_range = np.arange(0.25,6,0.25) # arange生成0.25到6之间以0.25为步长的值\n",
    "param_grid = {'alpha': alph_range}\n",
    "\n",
    "opt_models[model],cv_score,grid_results = train_model(opt_models[model], param_grid=param_grid, \n",
    "                                              splits=splits, repeats=repeats)\n",
    "\n",
    "cv_score.name = model\n",
    "score_models = score_models.append(cv_score)\n",
    "\n",
    "'''\n",
    "# 用于表现有一定置信区间的带误差数据\n",
    "plt.figure() \n",
    "plt.errorbar(alph_range, abs(grid_results['mean_test_score']),\n",
    "             abs(grid_results['std_test_score'])/np.sqrt(splits*repeats))\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('score')\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 25 folds for each of 23 candidates, totalling 575 fits\n",
      "----------------------\n",
      "Lasso(alpha=0.0009800000000000002)\n",
      "----------------------\n",
      "score= 0.9422180303504408\n",
      "rmse= 0.09142611050876945\n",
      "mse= 0.008358733682761722\n",
      "cross_val: mean= 0.05352218983974719 , std= 0.04974022262207061\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nplt.figure()\\nplt.errorbar(alph_range, abs(grid_results['mean_test_score']),abs(grid_results['std_test_score'])/np.sqrt(splits*repeats))\\nplt.xlabel('alpha')\\nplt.ylabel('score')\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = 'Lasso'\n",
    "\n",
    "opt_models[model] = Lasso()\n",
    "alph_range = np.arange(1e-4,1e-3,4e-5)\n",
    "param_grid = {'alpha': alph_range}\n",
    "\n",
    "opt_models[model], cv_score, grid_results = train_model(opt_models[model], param_grid=param_grid, \n",
    "                                              splits=splits, repeats=repeats)\n",
    "\n",
    "cv_score.name = model\n",
    "score_models = score_models.append(cv_score)\n",
    "'''\n",
    "plt.figure()\n",
    "plt.errorbar(alph_range, abs(grid_results['mean_test_score']),abs(grid_results['std_test_score'])/np.sqrt(splits*repeats))\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('score')\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "----------------------\n",
      "ElasticNet(alpha=0.0009000000000000001, l1_ratio=0.9, max_iter=100000)\n",
      "----------------------\n",
      "score= 0.9426598311836597\n",
      "rmse= 0.09107591789524638\n",
      "mse= 0.00829482282046166\n",
      "cross_val: mean= 0.038553304586297424 , std= 0.02616136394906859\n"
     ]
    }
   ],
   "source": [
    "model ='ElasticNet'\n",
    "opt_models[model] = ElasticNet()\n",
    "\n",
    "param_grid = {'alpha': np.arange(1e-4,1e-3,1e-4),\n",
    "              'l1_ratio': np.arange(0.1,1.0,0.1),\n",
    "              'max_iter':[100000]}\n",
    "\n",
    "opt_models[model], cv_score, grid_results = train_model(opt_models[model], param_grid=param_grid, \n",
    "                                              splits=splits, repeats=1)\n",
    "\n",
    "cv_score.name = model\n",
    "score_models = score_models.append(cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nmodel='LinearSVR'\\nopt_models[model] = LinearSVR()\\n\\ncrange = np.arange(0.1,1.0,0.1)\\nparam_grid = {'C':crange,\\n             'max_iter':[1000]}\\n\\nopt_models[model], cv_score, grid_results = train_model(opt_models[model], param_grid=param_grid, \\n                                              splits=splits, repeats=repeats)\\n\\n\\ncv_score.name = model\\nscore_models = score_models.append(cv_score)\\n\\n\\nplt.figure()\\nplt.errorbar(crange, abs(grid_results['mean_test_score']),abs(grid_results['std_test_score'])/np.sqrt(splits*repeats))\\nplt.xlabel('C')\\nplt.ylabel('score')\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "model='LinearSVR'\n",
    "opt_models[model] = LinearSVR()\n",
    "\n",
    "crange = np.arange(0.1,1.0,0.1)\n",
    "param_grid = {'C':crange,\n",
    "             'max_iter':[1000]}\n",
    "\n",
    "opt_models[model], cv_score, grid_results = train_model(opt_models[model], param_grid=param_grid, \n",
    "                                              splits=splits, repeats=repeats)\n",
    "\n",
    "cv_score.name = model\n",
    "score_models = score_models.append(cv_score)\n",
    "\n",
    "plt.figure()\n",
    "plt.errorbar(crange, abs(grid_results['mean_test_score']),abs(grid_results['std_test_score'])/np.sqrt(splits*repeats))\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('score')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "----------------------\n",
      "KNeighborsRegressor(n_neighbors=8)\n",
      "----------------------\n",
      "score= 0.10463763297872342\n",
      "rmse= 0.3598930762265224\n",
      "mse= 0.12952302631578946\n",
      "cross_val: mean= 0.15515069169960474 , std= 0.06684715280664362\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" \\nplt.figure()\\nplt.errorbar(np.arange(3,11,1), abs(grid_results['mean_test_score']),abs(grid_results['std_test_score'])/np.sqrt(splits*1))\\nplt.xlabel('n_neighbors')\\nplt.ylabel('score')\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = 'KNeighbors'\n",
    "opt_models[model] = KNeighborsRegressor()\n",
    "\n",
    "param_grid = {'n_neighbors':np.arange(3,11,1)}\n",
    "\n",
    "opt_models[model], cv_score, grid_results = train_model(opt_models[model], param_grid=param_grid, \n",
    "                                              splits=splits, repeats=1)\n",
    "\n",
    "cv_score.name = model\n",
    "score_models = score_models.append(cv_score)\n",
    "''' \n",
    "plt.figure()\n",
    "plt.errorbar(np.arange(3,11,1), abs(grid_results['mean_test_score']),abs(grid_results['std_test_score'])/np.sqrt(splits*1))\n",
    "plt.xlabel('n_neighbors')\n",
    "plt.ylabel('score')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "----------------------\n",
      "GradientBoostingRegressor(max_depth=1, min_samples_split=6, n_estimators=150)\n",
      "----------------------\n",
      "score= 0.945909218569796\n",
      "rmse= 0.08845771182448547\n",
      "mse= 0.007824766781223721\n",
      "cross_val: mean= 0.026355373216338802 , std= 0.018521933458605495\n"
     ]
    }
   ],
   "source": [
    "model = 'GradientBoosting'\n",
    "opt_models[model] = GradientBoostingRegressor()\n",
    "\n",
    "param_grid = {'n_estimators':[150,250,350],\n",
    "              'max_depth':[1,2,3],\n",
    "              'min_samples_split':[5,6,7]}\n",
    "\n",
    "opt_models[model], cv_score, grid_results = train_model(opt_models[model], param_grid=param_grid, \n",
    "                                              splits=splits, repeats=1)\n",
    "\n",
    "cv_score.name = model\n",
    "score_models = score_models.append(cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "----------------------\n",
      "XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "             importance_type=None, interaction_constraints='',\n",
      "             learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
      "             max_delta_step=0, max_depth=1, max_leaves=0, min_child_weight=1,\n",
      "             missing=nan, monotone_constraints='()', n_estimators=100, n_jobs=0,\n",
      "             num_parallel_tree=1, predictor='auto', random_state=0, reg_alpha=0,\n",
      "             reg_lambda=1, ...)\n",
      "----------------------\n",
      "score= 0.9579453169921438\n",
      "rmse= 0.07799760280287793\n",
      "mse= 0.006083626042995508\n",
      "cross_val: mean= 0.0274748581137714 , std= 0.017328297778460715\n"
     ]
    }
   ],
   "source": [
    "model = 'XGB'\n",
    "opt_models[model] = XGBRegressor()\n",
    "\n",
    "param_grid = {'n_estimators':[100,200,300,400,500],\n",
    "              'max_depth':[1,2,3],\n",
    "             }\n",
    "\n",
    "opt_models[model], cv_score,grid_results = train_model(opt_models[model], param_grid=param_grid, \n",
    "                                              splits=splits, repeats=1)\n",
    "\n",
    "cv_score.name = model\n",
    "score_models = score_models.append(cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n",
      "----------------------\n",
      "RandomForestRegressor(max_features=24, min_samples_split=6, n_estimators=200)\n",
      "----------------------\n",
      "score= 0.9388747568728546\n",
      "rmse= 0.09403388364926685\n",
      "mse= 0.008842371274163853\n",
      "cross_val: mean= 0.02617793846808731 , std= 0.014079154261490636\n"
     ]
    }
   ],
   "source": [
    "model = 'RandomForest'\n",
    "opt_models[model] = RandomForestRegressor()\n",
    "\n",
    "param_grid = {'n_estimators':[100,150,200],\n",
    "              'max_features':[8,12,16,20,24],\n",
    "              'min_samples_split':[2,4,6]}\n",
    "\n",
    "opt_models[model], cv_score, grid_results = train_model(opt_models[model], param_grid=param_grid, \n",
    "                                              splits=5, repeats=1)\n",
    "\n",
    "cv_score.name = model\n",
    "score_models = score_models.append(cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(test_data,test_y=[],stack=False):\n",
    "    #poly_trans=PolynomialFeatures(degree=2)\n",
    "    #test_data1=poly_trans.fit_transform(test_data)\n",
    "    #test_data=MinMaxScaler().fit_transform(test_data)\n",
    "    i=0\n",
    "    y_predict_total=np.zeros((test_data.shape[0],))\n",
    "    if stack:\n",
    "        for model in opt_models.keys():\n",
    "            y_predict=opt_models[model].predict(test_data)\n",
    "            y_predict_total+=y_predict\n",
    "            i+=1\n",
    "            if len(test_y)>0:\n",
    "                print(\"{}_mse:\".format(model),mean_squared_error(y_predict,test_y)) # 每个基模型的均方误差\n",
    "        y_predict_mean=np.round(y_predict_total/i,3) # 所有模型预测结果的平均值\n",
    "        if len(test_y)>0:\n",
    "            print(\"mean_mse:\",mean_squared_error(y_predict_mean,test_y))\n",
    "        else:\n",
    "            y_metal_mean=pd.Series(y_predict_mean)\n",
    "            return y_metal_mean \n",
    "    else:\n",
    "        for model in opt_models.keys():\n",
    "            if model!=\"LinearSVR\" and model!=\"KNeighbors\":\n",
    "                y_predict=opt_models[model].predict(test_data)\n",
    "                y_predict_total+=y_predict\n",
    "                i+=1\n",
    "            if len(test_y)>0:\n",
    "                print(\"{}_mse:\".format(model),mean_squared_error(y_predict,test_y))\n",
    "        y_predict_mean=np.round(y_predict_total/i,3)\n",
    "        if len(test_y)>0:\n",
    "            print(\"mean_mse:\",mean_squared_error(y_predict_mean,test_y))\n",
    "        else:\n",
    "            y_predict_mean=pd.Series(y_predict_mean)\n",
    "            return y_predict_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge_mse: 0.029472253778305948\n",
      "Lasso_mse: 0.024796127390697847\n",
      "ElasticNet_mse: 0.025058909048249357\n",
      "KNeighbors_mse: 0.025058909048249357\n",
      "GradientBoosting_mse: 0.021194475645041948\n",
      "XGB_mse: 0.021220163054524014\n",
      "RandomForest_mse: 0.021479575532643493\n",
      "mean_mse: 0.020518070895522385\n"
     ]
    }
   ],
   "source": [
    "model_predict(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 测试集测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_X = df_test[features_columns].values\n",
    "df_test_y =df_test['Default'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge_mse: 0.2790389516694681\n",
      "Lasso_mse: 0.2958808398941324\n",
      "ElasticNet_mse: 0.29536873008424697\n",
      "KNeighbors_mse: 0.24781976744186046\n",
      "GradientBoosting_mse: 0.2989346256279501\n",
      "XGB_mse: 0.2995590910073359\n",
      "RandomForest_mse: 0.24958923121747642\n",
      "mean_mse: 0.26023758139534886\n"
     ]
    }
   ],
   "source": [
    "result = model_predict(df_test_X,df_test_y,stack=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
